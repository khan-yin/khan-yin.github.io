<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ykhblog 一路向北</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://yoursite.com/"/>
  <updated>2021-04-12T00:50:31.139Z</updated>
  <id>https://yoursite.com/</id>
  
  <author>
    <name>whut ykh</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MTCNN论文和pytorch代码解读</title>
    <link href="https://yoursite.com/2021/04/12/MTCNN%E8%AE%BA%E6%96%87%E5%92%8Cpytorch%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
    <id>https://yoursite.com/2021/04/12/MTCNN%E8%AE%BA%E6%96%87%E5%92%8Cpytorch%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/</id>
    <published>2021-04-12T00:39:42.000Z</published>
    <updated>2021-04-12T00:50:31.139Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MTCNN人脸检测和pytorch代码实现解读"><a href="#MTCNN人脸检测和pytorch代码实现解读" class="headerlink" title="MTCNN人脸检测和pytorch代码实现解读"></a>MTCNN人脸检测和pytorch代码实现解读</h1><h2 id="传送门"><a href="#传送门" class="headerlink" title="传送门"></a>传送门</h2><blockquote><p>论文地址：<a href="https://arxiv.org/ftp/arxiv/papers/1604/1604.02878.pdf" target="_blank" rel="noopener">https://arxiv.org/ftp/arxiv/papers/1604/1604.02878.pdf</a><br>我的论文笔记：<a href="https://khany.top/file/paper/mtcnn.pdf" target="_blank" rel="noopener">https://khany.top/file/paper/mtcnn.pdf</a><br>github参考：<a href="https://github.com/Sierkinhane/mtcnn-pytorch" target="_blank" rel="noopener">https://github.com/Sierkinhane/mtcnn-pytorch</a><br>github参考：<a href="https://github.com/GitHberChen/MTCNN_Pytorch" target="_blank" rel="noopener">https://github.com/GitHberChen/MTCNN_Pytorch</a></p></blockquote><p>@[toc]</p><h2 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h2><blockquote><p>abstract—Face detection and alignment in unconstrained environment are challenging due to various poses, illuminations and occlusions. Recent studies show that deep learning approaches can achieve impressive performance on these two tasks. In this paper, we propose a deep cascaded multi-task framework which exploits the inherent correlation between detection and alignment<br>to boost up their performance. In particular, our framework leverages a cascaded architecture with three stages of carefully designed deep convolutional networks to predict face and landmark location in a coarse-to-fine manner. In addition, we propose a new online hard sample mining strategy that further improves the performance in practice. Our method achieves superior accuracy over the state-of-the-art techniques on the challenging FDDB and WIDER FACE benchmarks for face detection, and AFLW benchmark for face alignment, while keeps real time performance. </p></blockquote><p>在无约束条件的环境下进行人脸检测和校准人脸检测和校准是非常具挑战性的，因为你要考虑复杂的姿势，光照因素以及面部遮挡问题的影响，最近的研究表明，使用深度学习的方法能够在这两项任务上有不错的效果。本文作者探索和研究了人脸检测和校准之间的内在联系，提出了一个深层级的多任务框架有效提升了网络的性能。我们的深层级联合架构包含三个阶段的卷积神经网络从粗略到细致逐步实现人脸检测和面部特征点标记。此外，我们还提出了一种新的线上进行困难样本的预测的策略可以在实际使用过程中有效提升网络的性能。我们的方法目前在FDDB和WIDER FACE人脸检测任务和AFLW面部对准任务上超越了最佳模型方法的性能标准，同时该模型具有不错的实时检测效果。</p><blockquote><p>my English is not so well，if there are some mistakes in translations, please contact me in blog comments.</p></blockquote><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>人脸检测和脸部校准任务对于很多面部任务和应用来说都是十分重要的，比如说人脸识别，人脸表情分析。不过在现实生活当中，面部特征时常会因为一些遮挡物，强烈的光照对比，复杂的姿势发生很大的变化，这使得这些任务变得具有很大挑战性。Viola和Jones 提出的级联人脸检测器利用<a href="https://www.cnblogs.com/zyly/p/9410563.html" target="_blank" rel="noopener">Haar特征和AdaBoost训练级联分类器</a>，实现了具有实时效率的良好性能。 然而，也有相当一部分的工作表明，这种分类器可能在现实生活的应用中效果显着降低，即使具有更高级的特征和分类器。，之后人们又提出了<a href="https://blog.csdn.net/weixin_41798111/article/details/79989794" target="_blank" rel="noopener">DPM</a>的方式，这些年来基于CNN的一些解决方案也层出不穷，基于CNN的方案主要是为了识别出面部的一些特征来实现。<strong>作者认为这种方式其实是需要花费更多的时间来对面部进行校准来训练同时还忽略了面部的重要特征点位置和边框问题。</strong><br>对于人脸校准的话目前也有大致的两个方向：一个是基于回归的方法还有一个就是基于模板拟合的方式进行，主要是对特征识别起到一个辅助的工作。<br>作者认为关于人脸识别和面部对准这两个任务其实是有内在关联的，而目前大多数的方法则忽略了这一点，所以本文所提出的方案就是将这两者都结合起来，构建出一个三阶段的模型实现一个端到端的人脸检测并校准面部特征点的过程。<br><strong>第一阶段：通过浅层CNN快速生成候选窗口。</strong><br><strong>第二阶段：通过more complex的CNN拒绝大量非面部窗口来细化窗口。</strong><br><strong>第三阶段：使用more powerful的CNN再次细化结果并输出五个面部标志位置。</strong></p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h4 id="Image-pyramid图像金字塔"><a href="#Image-pyramid图像金字塔" class="headerlink" title="Image pyramid图像金字塔"></a>Image pyramid图像金字塔</h4><p>在进入stage-1之前，作者先构建了一组多尺度的图像金字塔缩放，这一块要理解起来还是有一点费力的，这里我们需要了解的是在训练网络的过程当中，作者都是把WIDER FACE的图片随机剪切成12x12size的大小进行单尺度训练的，不能满足任意大小的人脸检测，所以为了检测到不同尺寸的人脸，所以在推理时需要先生成图像金字塔生成一组不同scale的图像输入P-net进行来实现人脸的检测，同时也这是为什么P-net要使用FCN的原因。<br><img src="https://img-blog.csdnimg.cn/2021041118210630.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">calculateScales</span><span class="hljs-params">(img)</span>:</span><br>min_face_size = <span class="hljs-number">20</span> <span class="hljs-comment"># 最小的人脸尺寸</span><br>width, height = img.size<br>min_length = min(height, width)<br>min_detection_size = <span class="hljs-number">12</span><br>factor = <span class="hljs-number">0.707</span>  <span class="hljs-comment"># sqrt(0.5)</span><br>scales = []<br>m = min_detection_size / min_face_size<br>min_length *= m<br>factor_count = <span class="hljs-number">0</span><br><span class="hljs-comment"># 图像尺寸缩小到不大于min_detection_size</span><br><span class="hljs-keyword">while</span> min_length &gt; min_detection_size:<br>    scales.append(m * factor ** factor_count)<br>    min_length *= factor<br>    factor_count += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>$$\text{length} =\text{length} \times (\frac{\text{min detection size}}{\text{min face size}} )\times factor^{count} $$<br>$\text{here  we define in our code:} factor=\frac{1}{\sqrt{2}}, \text{min face size}=20,\text{min detection size}=12$</p><p><strong>min_face_size和factor对推理过程会产生什么样的影响？</strong><br><code>min_face_size</code>越大，<code>factor</code>越小，图像最短边就越快缩放到接近<code>min_detect_size</code>,从而生成图像金字塔的耗时就越短，同时各尺度的跨度也更大。因此，加大<code>min_face_size</code>、减小<code>factor</code>能加速图像金字塔的生成，但同时也更易造成漏检。</p><h4 id="Stage-1-P-Net-Proposal-Network"><a href="#Stage-1-P-Net-Proposal-Network" class="headerlink" title="Stage 1-P-Net(Proposal Network)"></a>Stage 1-P-Net(Proposal Network)</h4><p>这是一个全卷积网络，也就是说这个网络可以兼容任意大小的输入，他的整个网络其实十分简单，该层的作用主要是为了获得人脸检测的大量候选框，这一层我们最大的作用就是要尽可能的提升recall，然后在获得许多候选框后再使用非极大抑制的方法合并高度重叠的候选区域。<br><img src="https://img-blog.csdnimg.cn/20210411181845202.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>P-Net的示意图当中我们也可以看到的是作者输入12x12大小最终的output为一个1x1x2的face label classification概率和一个1x1x4的boudingbox(左上角和右下角的坐标)以及一个1x1x10的landmark(双眼，鼻子，左右嘴角的坐标)<br><strong>注意虽然这里作者举例是12x12的图片大小，但是他的意思并不是说这个P-Net的图片输入大小必须是12，我们可以知道这个网络是FCN，这就意味着不同输入的大小都是可以输入其中的，最后我们所得到的featuremap$[m \times n \times (2+4+10) ]$每一个小像素点映射到输入图像所在的12x12区域是否包含人脸的分类结果,候选框左上和右下基准点以及landmark，然后根据图像金字塔的我们再根据scale和resize的逆过程将其映射到原图像上</strong></p><p><strong>P-net structure</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">P_Net</span><span class="hljs-params">(nn.Module)</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span><br>        super(P_Net, self).__init__()<br>        self.pre_layer = nn.Sequential(<br>            <span class="hljs-comment"># 12x12x3</span><br>            nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>),  <span class="hljs-comment"># conv1</span><br>            nn.PReLU(),  <span class="hljs-comment"># PReLU1</span><br>            <span class="hljs-comment"># 10x10x10</span><br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),  <span class="hljs-comment"># pool1</span><br>            <span class="hljs-comment"># 5x5x10</span><br>            nn.Conv2d(<span class="hljs-number">10</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>),  <span class="hljs-comment"># conv2</span><br>            <span class="hljs-comment"># 3x3x16</span><br>            nn.PReLU(),  <span class="hljs-comment"># PReLU2</span><br>            nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>),  <span class="hljs-comment"># conv3</span><br>            <span class="hljs-comment"># 1x1x32</span><br>            nn.PReLU()  <span class="hljs-comment"># PReLU3</span><br>        )<br>        <span class="hljs-comment"># detection</span><br>        self.conv4_1 = nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">1</span>, kernel_size=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># bounding box regresion</span><br>        self.conv4_2 = nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># landmark localization</span><br>        self.conv4_3 = nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># weight initiation with xavier</span><br>        self.apply(weights_init)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span><br>        x = self.pre_layer(x)<br>        det = torch.sigmoid(self.conv4_1(x))<br>        box = self.conv4_2(x)<br>        landmark = self.conv4_3(x)<br>        <span class="hljs-comment"># det:[,2,1,1], box:[,4,1,1], landmark:[,10,1,1]</span><br>        <span class="hljs-keyword">return</span> det, box, landmark<br></code></pre></td></tr></table></figure><p>这里要提一下<code>nn.PReLU()</code>，有点类似Leaky ReLU，可以看下面的博客深入了解一下<br><img src="https://img-blog.csdnimg.cn/20210411201535463.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><blockquote><p><a href="https://blog.csdn.net/qq_23304241/article/details/80300149" target="_blank" rel="noopener">https://blog.csdn.net/qq_23304241/article/details/80300149</a><br><a href="https://blog.csdn.net/shuzfan/article/details/51345832" target="_blank" rel="noopener">https://blog.csdn.net/shuzfan/article/details/51345832</a></p></blockquote><p>然后在P-Net之后我们通过<strong>非极大抑制</strong>的方法和将<strong>所有的boudingbox都修正为框的最长边为边长的正方形框</strong>，<strong>主要是避免后面的Rnet在resize的时候因为尺寸原因出现信息的损失。</strong><br><img src="https://img-blog.csdnimg.cn/20210411201152243.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h4 id="Non-Maximum-Suppression非极大抑制"><a href="#Non-Maximum-Suppression非极大抑制" class="headerlink" title="Non-Maximum Suppression非极大抑制"></a>Non-Maximum Suppression非极大抑制</h4><p>其实关于非极大抑制这个trick最初是在目标检测任务当中提出的来的，其思想是搜素局部最大值，抑制极大值，主要用在目标检测当中，最传统的非极大抑制所采用的评价指标就是<strong>交并比IoU</strong>(intersection-over-union)即两个groud truth和bounding box的交集部分除以它们的并集.<br><img src="https://img-blog.csdnimg.cn/20210412002012403.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>$$IoU = \frac{area(C) \cap area(G)}{area(C) \cup area(G)}$$</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">IoU</span><span class="hljs-params">(box, boxes)</span>:</span><br>    <span class="hljs-string">"""Compute IoU between detect box and gt boxes</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Parameters:</span><br><span class="hljs-string">    ----------</span><br><span class="hljs-string">    box: numpy array , shape (5, ): x1, y1, x2, y2, score</span><br><span class="hljs-string">        input box</span><br><span class="hljs-string">    boxes: numpy array, shape (n, 4): x1, y1, x2, y2</span><br><span class="hljs-string">        input ground truth boxes</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">    -------</span><br><span class="hljs-string">    ovr: numpy.array, shape (n, )</span><br><span class="hljs-string">        IoU</span><br><span class="hljs-string">    """</span><br>    box_area = (box[<span class="hljs-number">2</span>] - box[<span class="hljs-number">0</span>] + <span class="hljs-number">1</span>) * (box[<span class="hljs-number">3</span>] - box[<span class="hljs-number">1</span>] + <span class="hljs-number">1</span>)<br>    area = (boxes[:, <span class="hljs-number">2</span>] - boxes[:, <span class="hljs-number">0</span>] + <span class="hljs-number">1</span>) * (boxes[:, <span class="hljs-number">3</span>] - boxes[:, <span class="hljs-number">1</span>] + <span class="hljs-number">1</span>)<br>    xx1 = np.maximum(box[<span class="hljs-number">0</span>], boxes[:, <span class="hljs-number">0</span>])<br>    xx2 = np.minimum(box[<span class="hljs-number">2</span>], boxes[:, <span class="hljs-number">2</span>])<br>    yy1 = np.maximum(box[<span class="hljs-number">1</span>], boxes[:, <span class="hljs-number">1</span>])<br>    yy2 = np.minimum(box[<span class="hljs-number">3</span>], boxes[:, <span class="hljs-number">3</span>])<br><br>    <span class="hljs-comment"># compute the width and height of the bounding box</span><br>    w = np.maximum(<span class="hljs-number">0</span>, xx2 - xx1 + <span class="hljs-number">1</span>)<br>    h = np.maximum(<span class="hljs-number">0</span>, yy2 - yy1 + <span class="hljs-number">1</span>)<br><br>    inter = w * h<br>    ovr = np.true_divide(inter,(box_area + area - inter))<br>    <span class="hljs-comment">#ovr = inter / (box_area + area - inter)</span><br>    <span class="hljs-keyword">return</span> ovr<br></code></pre></td></tr></table></figure><p><strong>使用非极大抑制的前提是，我们已经得到了一组候选框和对应label的置信分数，以及groud truth的信息，通过设定阈值来删除重合度较高的候选框。</strong><br>算法流程如下：</p><ul><li>根据置信度得分进行排序</li><li>选择置信度最高的比边界框添加到最终输出列表中，将其从边界框列表中删除</li><li>计算所有边界框的面积</li><li>计算置信度最高的边界框与其它候选框的IoU。</li><li>删除IoU大于阈值的边界框</li><li>重复上述过程，直至边界框列表为空。</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">nms</span><span class="hljs-params">(dets,threshod,mode=<span class="hljs-string">"Union"</span>)</span>:</span><br>    <span class="hljs-string">"""</span><br><span class="hljs-string">    greedily select boxes with high confidence</span><br><span class="hljs-string">    keep boxes overlap &lt;= thresh</span><br><span class="hljs-string">    rule out overlap &gt; thresh</span><br><span class="hljs-string">    :param dets: [[x1, y1, x2, y2 score]]</span><br><span class="hljs-string">    :param threshod: retain overlap &lt;= thresh</span><br><span class="hljs-string">    :return: indexes to keep</span><br><span class="hljs-string">    """</span><br>    x1 = dets[:,<span class="hljs-number">0</span>]<br>    y1 = dets[;,<span class="hljs-number">1</span>]<br>    x2 = dets[:,<span class="hljs-number">2</span>]<br>    y2 = dets[:,<span class="hljs-number">3</span>]<br><br>    scores = dets[:,<span class="hljs-number">4</span>]<br><br>    areas = (x2 - x1 + <span class="hljs-number">1</span>) * (y2 - y1 + <span class="hljs-number">1</span>)<br>    order = areas.argsort()[::<span class="hljs-number">-1</span>] <span class="hljs-comment"># reverse</span><br><br>    keep=[]<br><br>    <span class="hljs-keyword">while</span> order.size()&gt;<span class="hljs-number">0</span>:<br>        i = order[<span class="hljs-number">0</span>]<br>        keep.append(i)<br>        <span class="hljs-comment"># A &amp; B left top position </span><br>        xx1 = np.maximun(x1[i],x1[order[<span class="hljs-number">1</span>,:]])<br>        yy1 = np.maximun(y1[i],y1[order[<span class="hljs-number">1</span>,:]])<br>        <span class="hljs-comment"># A &amp; B right down position</span><br>        xx2 = np.minimum(x2[i],x2[order[<span class="hljs-number">1</span>,:]])<br>        yy2 = np.minimum(y2[i], y2[order[<span class="hljs-number">1</span>:]])<br><br>        w = np.maximum(<span class="hljs-number">0.0</span>, xx2 - xx1 + <span class="hljs-number">1</span>)<br>        h = np.maximum(<span class="hljs-number">0.0</span>, yy2 - yy1 + <span class="hljs-number">1</span>)<br><br>        inter = w * h<br><br>        <span class="hljs-comment"># cacaulate the IOU between box which have largest score with other boxes</span><br>        <span class="hljs-keyword">if</span> mode == <span class="hljs-string">"Union"</span>:<br>            <span class="hljs-comment"># area[i]: the area of largest score</span><br>            ovr = inter / (areas[i] + areas[order[<span class="hljs-number">1</span>:]] - inter)<br>        <span class="hljs-keyword">elif</span> mode == <span class="hljs-string">"Minimum"</span>:<br>            ovr = inter / np.minimum(areas[i], areas[order[<span class="hljs-number">1</span>:]])<br>        <span class="hljs-comment"># delete the IoU that higher than threshod </span><br>        inds = np.where(ovr &lt;= threshod)[<span class="hljs-number">0</span>]<br>        order = order[inds + <span class="hljs-number">1</span>] <span class="hljs-comment"># +1: eliminates the first element in order</span><br>    <br>    <span class="hljs-keyword">return</span> keep<br></code></pre></td></tr></table></figure><h4 id="边框修正"><a href="#边框修正" class="headerlink" title="边框修正"></a>边框修正</h4><p>以最大边作为边长将矩形修正为正方形，同时包含的信息也更多，以免在后面resize输入下一个网络时减少信息的损失。</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">convert_to_square</span><span class="hljs-params">(bboxes)</span>:</span><br>    <span class="hljs-string">"""</span><br><span class="hljs-string">    Convert bounding boxes to a square form.</span><br><span class="hljs-string">    """</span><br>    <span class="hljs-comment"># 将矩形对称扩大为正方形</span><br>    square_bboxes = np.zeros_like(bboxes)<br>    x1, y1, x2, y2 = [bboxes[:, i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">4</span>)]<br>    h = y2 - y1 + <span class="hljs-number">1.0</span><br>    w = x2 - x1 + <span class="hljs-number">1.0</span><br>    max_side = np.maximum(h, w)<br>    square_bboxes[:, <span class="hljs-number">0</span>] = x1 + w * <span class="hljs-number">0.5</span> - max_side * <span class="hljs-number">0.5</span><br>    square_bboxes[:, <span class="hljs-number">1</span>] = y1 + h * <span class="hljs-number">0.5</span> - max_side * <span class="hljs-number">0.5</span><br>    square_bboxes[:, <span class="hljs-number">2</span>] = square_bboxes[:, <span class="hljs-number">0</span>] + max_side - <span class="hljs-number">1.0</span><br>    square_bboxes[:, <span class="hljs-number">3</span>] = square_bboxes[:, <span class="hljs-number">1</span>] + max_side - <span class="hljs-number">1.0</span><br>    <span class="hljs-keyword">return</span> square_bboxes<br></code></pre></td></tr></table></figure><h4 id="Stage-2-R-Net-Refine-Network"><a href="#Stage-2-R-Net-Refine-Network" class="headerlink" title="Stage 2-R-Net(Refine Network)"></a>Stage 2-R-Net(Refine Network)</h4><p>R-net的输入是固定的，必须是24x24，所以对于P-net产生的大量boundingbox我们需要先进行resize然后再输入R-Net，<strong>在论文中我们了解到该网络层的作用主要是对大量的boundingbox进行有效过滤，获得更加精细的候选框。</strong><br><img src="https://img-blog.csdnimg.cn/20210411203248732.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>R-net structure</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">R_Net</span><span class="hljs-params">(nn.Module)</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span><br>        super(R_Net, self).__init__()<br>        self.pre_layer = nn.Sequential(<br>            <span class="hljs-comment"># 24x24x3</span><br>            nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">28</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>),  <span class="hljs-comment"># conv1</span><br>            nn.PReLU(),  <span class="hljs-comment"># prelu1</span><br>            <span class="hljs-comment"># 22x22x28</span><br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),  <span class="hljs-comment"># pool1</span><br>            <span class="hljs-comment"># 10x10x28</span><br>            nn.Conv2d(<span class="hljs-number">28</span>, <span class="hljs-number">48</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>),  <span class="hljs-comment"># conv2</span><br>            nn.PReLU(),  <span class="hljs-comment"># prelu2</span><br>            <span class="hljs-comment"># 8x8x48</span><br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),  <span class="hljs-comment"># pool2</span><br>            <span class="hljs-comment"># 3x3x48</span><br>            nn.Conv2d(<span class="hljs-number">48</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">1</span>),  <span class="hljs-comment"># conv3</span><br>            <span class="hljs-comment"># 2x2x64</span><br>            nn.PReLU()  <span class="hljs-comment"># prelu3</span><br>        )<br>        <span class="hljs-comment"># 2x2x64</span><br>        self.conv4 = nn.Linear(<span class="hljs-number">64</span> * <span class="hljs-number">2</span> * <span class="hljs-number">2</span>, <span class="hljs-number">128</span>)  <span class="hljs-comment"># conv4</span><br>        <span class="hljs-comment"># 128</span><br>        self.prelu4 = nn.PReLU()  <span class="hljs-comment"># prelu4</span><br>        <span class="hljs-comment"># detection</span><br>        self.conv5_1 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># bounding box regression</span><br>        self.conv5_2 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">4</span>)<br>        <span class="hljs-comment"># lanbmark localization</span><br>        self.conv5_3 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">10</span>)<br>        <span class="hljs-comment"># weight initiation weih xavier</span><br>        self.apply(weights_init)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span><br>        x = self.pre_layer(x)<br>        x = x.view(x.size(<span class="hljs-number">0</span>), <span class="hljs-number">-1</span>)<br>        x = self.conv4(x)<br>        x = self.prelu4(x)<br>        det = torch.sigmoid(self.conv5_1(x))<br>        box = self.conv5_2(x)<br>        landmark = self.conv5_3(x)<br>        <span class="hljs-keyword">return</span> det, box, landmark<br></code></pre></td></tr></table></figure><p>然后在P-Net之后我们通过<strong>非极大抑制</strong>的方法和将<strong>所有的boudingbox都修正为框的最长边为边长的正方形框</strong>，<strong>也是避免后面的Onet在resize的时候出现因为尺寸原因出现信息的损失。</strong><br><img src="https://img-blog.csdnimg.cn/20210411202906999.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h4 id="Stage-3-O-Net-Output-作者未指出命名-Network"><a href="#Stage-3-O-Net-Output-作者未指出命名-Network" class="headerlink" title="Stage 3-O-Net(Output?[作者未指出命名] Network)"></a>Stage 3-O-Net(Output?[作者未指出命名] Network)</h4><p><img src="https://img-blog.csdnimg.cn/20210411203345893.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>Onet与Rnet工作流程类似。只不过输入的尺寸变成了48x48，对于R-net当中的框再次进行处理，得到的网络结构的输出则是最终的label classfication，boundingbox，landmark。<br><strong>O-net structure</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">O_Net</span><span class="hljs-params">(nn.Module)</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span><br>        super(O_Net, self).__init__()<br>        self.pre_layer = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>),  <span class="hljs-comment"># conv1</span><br>            nn.PReLU(),  <span class="hljs-comment"># prelu1</span><br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),  <span class="hljs-comment"># pool1</span><br>            nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>),  <span class="hljs-comment"># conv2</span><br>            nn.PReLU(),  <span class="hljs-comment"># prelu2</span><br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),  <span class="hljs-comment"># pool2</span><br>            nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>),  <span class="hljs-comment"># conv3</span><br>            nn.PReLU(),  <span class="hljs-comment"># prelu3</span><br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),  <span class="hljs-comment"># pool3</span><br>            nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">1</span>),  <span class="hljs-comment"># conv4</span><br>            nn.PReLU()  <span class="hljs-comment"># prelu4</span><br>        )<br>        self.conv5 = nn.Linear(<span class="hljs-number">128</span> * <span class="hljs-number">2</span> * <span class="hljs-number">2</span>, <span class="hljs-number">256</span>)  <span class="hljs-comment"># conv5</span><br>        self.prelu5 = nn.PReLU()  <span class="hljs-comment"># prelu5</span><br>        <span class="hljs-comment"># detection</span><br>        self.conv6_1 = nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># bounding box regression</span><br>        self.conv6_2 = nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">4</span>)<br>        <span class="hljs-comment"># lanbmark localization</span><br>        self.conv6_3 = nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">10</span>)<br>        <span class="hljs-comment"># weight initiation weih xavier</span><br>        self.apply(weights_init)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span><br>        x = self.pre_layer(x)<br>        x = x.view(x.size(<span class="hljs-number">0</span>), <span class="hljs-number">-1</span>)<br>        x = self.conv5(x)<br>        x = self.prelu5(x)<br>        <span class="hljs-comment"># detection</span><br>        det = torch.sigmoid(self.conv6_1(x))<br>        box = self.conv6_2(x)<br>        landmark = self.conv6_3(x)<br>        <span class="hljs-keyword">return</span> det, box, landmark<br></code></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210411204039760.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>注意，其实在之前的两个网络当中我们也预测了landmark的位置，只是在论文的图示当中没有展示而已，从作者描述的网络结构图的输出当中是详细指出了landmarkposition的卷积块的</strong></p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>在研究完网络结构以后我们可以来看看这个mtcnn模型的一个损失函数，作者将损失函数分为了3个部分：Face classification、Bounding box regression、Facial landmark localization。</p><h4 id="Face-classification"><a href="#Face-classification" class="headerlink" title="Face classification"></a>Face classification</h4><p>对于第一部分的损失就是用的是最常用的交叉熵损失函数，就本质上来说人脸识别还是一个二分类问题，这里就使用Cross Entropy是最简单也是最合适的选择。<br>$$L_i^{det} = -(y_i^{det} \log(p_i) + (1-y_i^det)(1-\log(p_i)))$$<br>$p_i$是预测为face的可能性，$y_i^{det}$指的是真实标签也就是groud truth label </p><h4 id="Bounding-box-regression"><a href="#Bounding-box-regression" class="headerlink" title="Bounding box regression"></a>Bounding box regression</h4><p>对于目标边界框的损失来说，对于每一个候选框我们都需要对与他最接近的真实目标边界框进行比较，the bounding box$（left, top, height, and width）$<br>$$L_i^{box} = ||y_j^{box}-y_i^{box} ||_2^2$$</p><h4 id="Facial-landmark-localization"><a href="#Facial-landmark-localization" class="headerlink" title="Facial landmark localization"></a>Facial landmark localization</h4><p>而对于boundingbox和landmark来说整个框的调整过程其实可以看作是一个连续的变化过程，固使用的是欧氏距离回归损失计算方法。比较的是各个点的坐标与真实面部关键点坐标的差异。<br>$$L_i^{landmark} = ||y_j^{landmark}-y_i^{landmark} ||_2^2$$</p><h4 id="total-loss"><a href="#total-loss" class="headerlink" title="total loss"></a>total loss</h4><p>最终我们得到的损失函数是有上述这三部分加权而成<br>$$\min{\sum_{i=1}^{N}{\sum_{j \in {det,box,landmark}} \alpha_j \beta_i^j L_i^j}}$$<br>其中$\alpha_j$表示权重，$\beta_i^j$表示第i个样本的类型，也可以说是第i个样本在任务j中是否需要贡献loss，如果不存在人脸即label为0时则无需计算loss。<br>对于不同的网络我们所设置的权重是不一样的<br><strong>in P-net &amp; R-net(在这两层我们更注重classification的识别)</strong><br>$$alpha_{det}=1, alpha_{box}=0.5,alpha_{landmark}=0.5$$<br><strong>in O-net(在这层我们提高了对于注意关键点的预测精度)</strong><br>$$alpha_{det}=1, alpha_{box}=0.5,alpha_{landmark}=1 $$<br>文中也有提到，采用的是随机梯度下降优化器进行的训练。</p><h2 id="OHEM（Online-Hard-Example-Mining）"><a href="#OHEM（Online-Hard-Example-Mining）" class="headerlink" title="OHEM（Online Hard Example Mining）"></a>OHEM（Online Hard Example Mining）</h2><p>作者对于困难样本的在线预测所做的trick也比较简单，就是挑选损失最大的前70%作为困难样本，在反向传播时仅使用这70%困难样本产生的损失，这样就剔除了很容易预测的easy sample对训练结果的影响，不过在我参考的这两个版本的代码里面似乎没有这么做。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>实验这块的话也比较充分，验证了每个修改部分对于实验结果的有效性验证，主要是讲述了实验过程对于训练数据集的处理和划分，验证了在线硬样本挖掘的有效性，联合检测和校准的有效性，分别评估了face detection和lanmark的贡献，面部检测评估，面部校准评估以及与SOTA的对比，这一块的话就没有细看了，分享的网站也有详细解释，论文原文也写了。<br><img src="https://img-blog.csdnimg.cn/20210411214338982.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210411214409844.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇论文是中科院深圳先进技术研究院的乔宇老师团队所作，2016ECCV，看完这篇文章的话给我的感觉的话就是idea和实现过程包括实验都是很充分的，创新点这块的话主要是挖掘了人脸特征关键点和目标检测的一些联系，结合了人脸检测和对准两个任务来进行人脸检测，相比其他经典的目标检测网络如yolov3,R-CNN系列，在网络和损失函数上的创新确实略有不足，但是也让我收到了一些启发，看似几个简单的model和常见的loss联合，在对数据进行有效处理的基础上也是可以实现达到十分不错的效果的，不过这个方案的话在训练的时候其实是很花费时间的，毕竟需要对于不同scale的图片都进行输入训练，然后就是这种输入输出的结构其实还是存在一些局限性的，对于图像检测框和关键点的映射我个人觉得也比较繁杂或者说浪费了一些时间，毕竟是一篇2016年的论文之后应该会有更好的实现方式这个过程。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><p>参考链接： <a href="https://zhuanlan.zhihu.com/p/337690783" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/337690783</a><br>参考链接：<a href="https://zhuanlan.zhihu.com/p/60199964?utm_source=qq&utm_medium=social&utm_oi=1221207556791963648" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/60199964?utm_source=qq&amp;utm_medium=social&amp;utm_oi=1221207556791963648</a><br>参考链接： <a href="https://blog.csdn.net/weixin_44791964/article/details/103530206" target="_blank" rel="noopener">https://blog.csdn.net/weixin_44791964/article/details/103530206</a><br>参考链接：<a href="https://blog.csdn.net/qq_34714751/article/details/85536669" target="_blank" rel="noopener">https://blog.csdn.net/qq_34714751/article/details/85536669</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;MTCNN人脸检测和pytorch代码实现解读&quot;&gt;&lt;a href=&quot;#MTCNN人脸检测和pytorch代码实现解读&quot; class=&quot;headerlink&quot; title=&quot;MTCNN人脸检测和pytorch代码实现解读&quot;&gt;&lt;/a&gt;MTCNN人脸检测和pytorch
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>docker镜像操作</title>
    <link href="https://yoursite.com/2021/02/25/docker%E9%95%9C%E5%83%8F%E6%93%8D%E4%BD%9C/"/>
    <id>https://yoursite.com/2021/02/25/docker%E9%95%9C%E5%83%8F%E6%93%8D%E4%BD%9C/</id>
    <published>2021-02-24T16:03:00.000Z</published>
    <updated>2021-02-25T03:39:24.785Z</updated>
    
    <content type="html"><![CDATA[<h2 id="commit镜像"><a href="#commit镜像" class="headerlink" title="commit镜像"></a>commit镜像</h2><p><img src="https://img-blog.csdnimg.cn/20210224162521454.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="数据卷操作实战：mysql同步"><a href="#数据卷操作实战：mysql同步" class="headerlink" title="数据卷操作实战：mysql同步"></a>数据卷操作实战：mysql同步</h2><p><strong>mysql运行容器，需要做数据挂载，安装启动mysql是需要配置密码的这一点要注意，所以要去docker hub官方文档上面去看官方配置</strong></p><figure class="highlight powershell"><table><tr><td class="code"><pre><code class="hljs powershell">docker pull mysql:<span class="hljs-number">5.7</span><br></code></pre></td></tr></table></figure><p>docker运行，docker run的常用参数这里我们再次回顾一下</p><figure class="highlight powershell"><table><tr><td class="code"><pre><code class="hljs powershell"><span class="hljs-literal">-d</span> 后台运行<br><span class="hljs-literal">-p</span> 端口映射<br><span class="hljs-literal">-v</span> 卷挂载<br><span class="hljs-literal">-e</span> 环境配置<br>-<span class="hljs-literal">-name</span> 环境名字<br></code></pre></td></tr></table></figure><a id="more"></a><p>通过docker hub我们找到了官方的命令：<code>docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag</code>，在修改一下得到我们最终的输入命令</p><figure class="highlight powershell"><table><tr><td class="code"><pre><code class="hljs powershell">docker run <span class="hljs-literal">-d</span> <span class="hljs-literal">-p</span> <span class="hljs-number">3310</span>:<span class="hljs-number">3306</span> <span class="hljs-literal">-v</span> /home/mysql/conf:/etc/mysql/conf.d <span class="hljs-literal">-v</span> /home/mysql/<span class="hljs-keyword">data</span>:/var/lib/mysql <span class="hljs-literal">-e</span> MYSQL_ROOT_PASSWORD=<span class="hljs-number">12345678</span> -<span class="hljs-literal">-name</span> mysql01 mysql:<span class="hljs-number">5.7</span><br></code></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">DATABASE</span> test_db;<br></code></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210224233439169.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><img src="https://img-blog.csdnimg.cn/20210224171410273.png" alt="在这里插入图片描述"><br>删除这个镜像后数据则依旧保存下来了<br><img src="https://img-blog.csdnimg.cn/20210224171612792.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="具名-匿名挂载"><a href="#具名-匿名挂载" class="headerlink" title="具名/匿名挂载"></a>具名/匿名挂载</h2><p><img src="https://img-blog.csdnimg.cn/20210224172157943.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210224172227379.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210224172304119.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>大多数情况下，为了方便，我们会使用具名挂载<br><img src="https://img-blog.csdnimg.cn/20210224172628376.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h2><p>Dockerfile就是用来构建docker镜像的文件，命令脚本，通过这个脚本可以生成镜像。<br>构建步骤</p><ol><li><p>编写一个Dockerfile</p></li><li><p>docker build 构建成为一个镜像</p></li><li><p>docker run 运行镜像</p></li><li><p>docker push 发布镜像(DockerHub，阿里云镜像)</p><p>这里我们可以先看看Docker Hub官方是怎么做的<br><img src="https://img-blog.csdnimg.cn/20210224203344446.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210224203405252.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>官方镜像是比较基础的，有很多命令和功能都省去了，所以我们通常需要在基础的镜像上来构建我们自己的镜像<br><img src="https://img-blog.csdnimg.cn/20210224203837702.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p></li></ol><h2 id="Dockerfile命令"><a href="#Dockerfile命令" class="headerlink" title="Dockerfile命令"></a>Dockerfile命令</h2><table><thead><tr><th>常用命令</th><th>用法</th></tr></thead><tbody><tr><td>FROM</td><td>基础镜像，一切从这开始构建</td></tr><tr><td>MAINTAINER</td><td>镜像是谁写的，姓名+邮箱</td></tr><tr><td>RUN</td><td>镜像构建的时候需要运行的命令</td></tr><tr><td>ADD</td><td>添加内容，如tomcat压缩包</td></tr><tr><td>WORKDIR</td><td>镜像的工作目录</td></tr><tr><td>VOLUME</td><td>挂载的目录</td></tr><tr><td>CMD</td><td>指定这个容器启动时要运行的命令，只有最后一个会生效，可被替代</td></tr><tr><td>ENTRYPOINT</td><td>指定这个容器启动时要运行的命令，可以追加命令</td></tr><tr><td>ONBUILD</td><td>当构建一个被继承DockerFile这个时候就会执行ONBUILD命令</td></tr><tr><td>COPY</td><td>类似ADD将文件拷贝到镜像当中</td></tr><tr><td>ENV</td><td>构建的时候设置环境变量</td></tr></tbody></table><p><img src="https://img-blog.csdnimg.cn/20210224204049431.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="创建一个自己的centos"><a href="#创建一个自己的centos" class="headerlink" title="创建一个自己的centos"></a>创建一个自己的centos</h2><p>Dockerfile中99%的镜像都来自于这个scratch镜像，然后配置需要的软件和配置来进行构建。</p><figure class="highlight powershell"><table><tr><td class="code"><pre><code class="hljs powershell">mkdir dockerfile<br>cd dockerfile<br>vim mydockerfile<span class="hljs-literal">-centos</span><br></code></pre></td></tr></table></figure><p>编写mydockerfile-centos</p><figure class="highlight powershell"><table><tr><td class="code"><pre><code class="hljs powershell">FROM centos<br>MAINTAINER khan&lt;khany@foxmail.com&gt;<br>ENV MYPATH /usr/local<br>WORKDIR <span class="hljs-variable">$MYPATH</span><br>RUN yum <span class="hljs-literal">-y</span> install vim<br>RUN yum <span class="hljs-literal">-y</span> install net<span class="hljs-literal">-tools</span><br>EXPOSE <span class="hljs-number">80</span><br>CMD echo <span class="hljs-variable">$MYPATH</span><br>CMD echo <span class="hljs-string">"---end---"</span><br>CMD /bin/bash<br></code></pre></td></tr></table></figure><p>然后我们进入<code>docker build</code>,<strong>注意后面一定要有一个.号</strong></p><figure class="highlight powershell"><table><tr><td class="code"><pre><code class="hljs powershell">docker build <span class="hljs-operator">-f</span> mydockerfile<span class="hljs-literal">-centos</span>  <span class="hljs-literal">-t</span> mycentos:<span class="hljs-number">1.0</span> .<br></code></pre></td></tr></table></figure><p>然后我们通过<code>docker run -it mycentos:1.0 </code>命令进入我们自己创建的镜像测试运行我们新安装的包和命令是否能正常运行。<br><img src="https://img-blog.csdnimg.cn/20210224220131565.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我们可以通过 <code>docker history +容器名称/容器id</code>看到这个容器的构建过程。<br><img src="https://img-blog.csdnimg.cn/20210224220552645.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="CMD和ENTRYPOINT区别"><a href="#CMD和ENTRYPOINT区别" class="headerlink" title="CMD和ENTRYPOINT区别"></a>CMD和ENTRYPOINT区别</h2><p><img src="https://img-blog.csdnimg.cn/20210224222435489.png" alt="在这里插入图片描述"></p><p>dockerfile-cmd-test：</p><figure class="highlight powershell"><table><tr><td class="code"><pre><code class="hljs powershell">FROM centos<br>CMD [<span class="hljs-string">"ls"</span>,<span class="hljs-string">"-a"</span>]<br></code></pre></td></tr></table></figure><p>dockerfile-entrypoint-test：</p><figure class="highlight powershell"><table><tr><td class="code"><pre><code class="hljs powershell">FROM centos<br>ENTRYPOINT [<span class="hljs-string">"ls"</span>,<span class="hljs-string">"-a"</span>]<br></code></pre></td></tr></table></figure><p>执行命令<code> docker run 容器名称 -l</code>在CMD下会报错，命令会被后面追加的<code>-l</code>替代，而<code>-l</code>并不是有效的linux命令，所以报错，而ENTRYPOINT则是可以追加的则该命令会变为<code>ls -al</code><br><img src="https://img-blog.csdnimg.cn/20210224222324355.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="发布镜像"><a href="#发布镜像" class="headerlink" title="发布镜像"></a>发布镜像</h2><blockquote><p>发布到Docker Hub</p></blockquote><ol><li>地址 <a href="https://hub.docker.com/" target="_blank" rel="noopener">https://hub.docker.com/</a> 注册自己的账号</li><li>确定这个账号可以登录</li><li>在我们服务器上提交自己的镜像</li><li>登录成功，通过<code>push</code>命令提交镜像,<strong>记得注意添加版本号</strong><br><img src="https://img-blog.csdnimg.cn/20210224223425131.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>这里出了一点小问题：</li></ol><p><strong>在build自己的镜像的时候添加tag时必须在前面加上自己的dockerhub的username，然后再push就可以了</strong><br><img src="https://img-blog.csdnimg.cn/20210224230121332.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><figure class="highlight powershell"><table><tr><td class="code"><pre><code class="hljs powershell">docker tag 镜像id YOUR_DOCKERHUB_NAME/firstimage<br>docker push YOUR_DOCKERHUB_NAME/firstimage<br></code></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210224231803691.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>提交成功，可以在docker hub上找到你提交的镜像<br><img src="https://img-blog.csdnimg.cn/20210224232108402.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><blockquote><p>阿里云镜像提交</p></blockquote><p>在阿里云的容器镜像服务里面，创建一个新的镜像仓库，然后就会有详细的教学，做法与docker hub基本一致，提交成功能在镜像版本当中查看到，这里就不再重复讲解了。<br><img src="https://img-blog.csdnimg.cn/202102242325274.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="Docker镜像操作过程总结"><a href="#Docker镜像操作过程总结" class="headerlink" title="Docker镜像操作过程总结"></a>Docker镜像操作过程总结</h2><p><img src="https://img-blog.csdnimg.cn/20210224232749397.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210224232831852.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><blockquote><p>参考链接：<a href="https://www.bilibili.com/video/BV1og4y1q7M4?t=201&p=33" target="_blank" rel="noopener">【狂神说Java】Docker最新超详细版教程通俗易懂</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;commit镜像&quot;&gt;&lt;a href=&quot;#commit镜像&quot; class=&quot;headerlink&quot; title=&quot;commit镜像&quot;&gt;&lt;/a&gt;commit镜像&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20210224162521454.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;数据卷操作实战：mysql同步&quot;&gt;&lt;a href=&quot;#数据卷操作实战：mysql同步&quot; class=&quot;headerlink&quot; title=&quot;数据卷操作实战：mysql同步&quot;&gt;&lt;/a&gt;数据卷操作实战：mysql同步&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;mysql运行容器，需要做数据挂载，安装启动mysql是需要配置密码的这一点要注意，所以要去docker hub官方文档上面去看官方配置&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight powershell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;code class=&quot;hljs powershell&quot;&gt;docker pull mysql:&lt;span class=&quot;hljs-number&quot;&gt;5.7&lt;/span&gt;&lt;br&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;docker运行，docker run的常用参数这里我们再次回顾一下&lt;/p&gt;
&lt;figure class=&quot;highlight powershell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;code class=&quot;hljs powershell&quot;&gt;&lt;span class=&quot;hljs-literal&quot;&gt;-d&lt;/span&gt; 后台运行&lt;br&gt;&lt;span class=&quot;hljs-literal&quot;&gt;-p&lt;/span&gt; 端口映射&lt;br&gt;&lt;span class=&quot;hljs-literal&quot;&gt;-v&lt;/span&gt; 卷挂载&lt;br&gt;&lt;span class=&quot;hljs-literal&quot;&gt;-e&lt;/span&gt; 环境配置&lt;br&gt;-&lt;span class=&quot;hljs-literal&quot;&gt;-name&lt;/span&gt; 环境名字&lt;br&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
    
      <category term="docker" scheme="https://yoursite.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>docker常用命令</title>
    <link href="https://yoursite.com/2021/02/24/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>https://yoursite.com/2021/02/24/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</id>
    <published>2021-02-24T07:30:00.000Z</published>
    <updated>2021-02-24T16:06:28.459Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Docker-常用命令"><a href="#Docker-常用命令" class="headerlink" title="Docker 常用命令"></a>Docker 常用命令</h1><h2 id="帮助命令"><a href="#帮助命令" class="headerlink" title="帮助命令"></a>帮助命令</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker version <span class="hljs-comment">#显示docker版本信息</span><br>docker info <span class="hljs-comment">#显示docker的系统信息，包括镜像和容器的数量</span><br>docker 命令 --<span class="hljs-built_in">help</span> <span class="hljs-comment"># 帮助命令</span><br></code></pre></td></tr></table></figure><h2 id="镜像命令"><a href="#镜像命令" class="headerlink" title="镜像命令"></a>镜像命令</h2><p><strong>1.<code>docker images</code>查看所有本地的主机镜像</strong></p><table><thead><tr><th align="left">docker images显示字段</th><th align="left">解释</th></tr></thead><tbody><tr><td align="left">REPOSITORY</td><td align="left">镜像的仓库源</td></tr><tr><td align="left">TAG</td><td align="left">镜像的标签</td></tr><tr><td align="left">IMAGE ID</td><td align="left">镜像的id</td></tr><tr><td align="left">CREATED</td><td align="left">镜像的创建时间</td></tr><tr><td align="left">SIZE</td><td align="left">镜像的大小</td></tr></tbody></table><a id="more"></a><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">(base) [root@iZuf69rye0flkbn4kbxrobZ ~]<span class="hljs-comment"># docker images</span><br>REPOSITORY    TAG       IMAGE ID       CREATED         SIZE<br>hello-world   latest    bf756fb1ae65   13 months ago   13.3kB<br>(base) [root@iZuf69rye0flkbn4kbxrobZ ~]<span class="hljs-comment"># docker images --help</span><br><br>Usage:  docker images [OPTIONS] [REPOSITORY[:TAG]]<br><br>List images<br><br>Options:<br>  -a, --all             Show all images <br>  -q, --quiet           Only show image IDs<br></code></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210224130929333.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>2.<code>docker search</code>命令搜索镜像</strong><br>搜索镜像可以去docker hub网站上直接搜索，也可以通过命令行来搜索，通过万能帮助命令能更快的看到他的一些用法，这两种方法结果是一样的<br><img src="https://img-blog.csdnimg.cn/20210224131759589.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210224131506578.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>我们也可以通过<code>--filter</code>来进行条件筛选<br>比如<code>docker search mysql --filter=STARS=3000</code></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">(base) [root@iZuf69rye0flkbn4kbxrobZ ~]<span class="hljs-comment"># docker search mysql --filter=STARS=3000</span><br>NAME      DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED<br>mysql     MySQL is a widely used, open-source relation…   10538     [OK]       <br>mariadb   MariaDB is a community-developed fork of MyS…   3935      [OK]<br></code></pre></td></tr></table></figure><p><strong>3.<code>docker pull</code>下载镜像</strong><br><strong>这个命令其实信息量很大，这也是docker高明的地方，关于指定版本下载一定要是docker hub官网上面支持和提供的版本</strong><br><img src="https://img-blog.csdnimg.cn/2021022413252511.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>我这里使用了</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker pull mysql<br>docker pull mysql:5.7<br></code></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210224132844566.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>4.<code>docker rmi</code>删除镜像</strong><br>删除可以通过<code>REPOSITORY</code>来删，也可以通过<code>IMAGE ID</code>来删除<br><img src="https://img-blog.csdnimg.cn/20210224133232500.png" alt="在这里插入图片描述"></p><h2 id="容器命令"><a href="#容器命令" class="headerlink" title="容器命令"></a>容器命令</h2><p><strong>说明：我们有了镜像才可以创建容器，linux，下载一个centos镜像来测试学习</strong></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">docker pull centos<br></code></pre></td></tr></table></figure><p><strong>1.新建容器并启动</strong><br>通过<code>docker run</code>命令进入下载的centos容器里面后我们可以发现的是，我们的rootname不一样了<br><img src="https://img-blog.csdnimg.cn/20210224134041815.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20210224134219210.png" alt="在这里插入图片描述"></p><p><strong>2.列出所有运行的容器</strong><br><code>docker ps</code>命令<br><img src="https://img-blog.csdnimg.cn/2021022413511697.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>3.<code>exit</code>退出命令</strong></p><figure class="highlight powershell"><table><tr><td class="code"><pre><code class="hljs powershell"><span class="hljs-keyword">exit</span> <span class="hljs-comment">#直接容器停止并退出</span><br>Ctrl + P + Q  <span class="hljs-comment">#容器不停止并退出</span><br></code></pre></td></tr></table></figure><p>在执行exit命令后，我们看到rootname又变回来了<br><img src="https://img-blog.csdnimg.cn/20210224134531160.png" alt="在这里插入图片描述"></p><p><strong>4.删除容器</strong></p><figure class="highlight powershell"><table><tr><td class="code"><pre><code class="hljs powershell">docker rm 容器id <span class="hljs-comment">#删除指定的容器，不能删除正在运行的容器，如果要强制删除，需要使用 rm -f</span><br>docker rm <span class="hljs-variable">$</span>(docker ps <span class="hljs-literal">-aq</span>) <span class="hljs-comment">#删除全部的容器</span><br>docker ps <span class="hljs-literal">-a</span> <span class="hljs-literal">-q</span>|xargs docker rm <span class="hljs-comment">#删除全部容器</span><br></code></pre></td></tr></table></figure><p><strong>5.启动和停止容器</strong><br><img src="https://img-blog.csdnimg.cn/20210224135856699.png" alt="在这里插入图片描述"></p><h2 id="日志元数据进程查看"><a href="#日志元数据进程查看" class="headerlink" title="日志元数据进程查看"></a>日志元数据进程查看</h2><p><img src="https://img-blog.csdnimg.cn/20210224141011643.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70"><br><img src="https://img-blog.csdnimg.cn/20210224141603263.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>1.<code>docker top 容器id</code>查看容器中的进程</strong></p><p><img src="https://img-blog.csdnimg.cn/20210224141846922.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>2.<code>docker inspect 容器id</code>查看元数据</strong></p><p><strong>3.进入当前正在运行的容器</strong></p><p>方式1： <code>docker exec -it 容器id bashshell</code>并可通过<code>ps -ef</code>查看容器当中的进程<br><img src="https://img-blog.csdnimg.cn/20210224143749283.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70"></p><p>方式2：<code>docker attach 容器id</code>进入容器，如果当前有正在执行的容器则会直接进入到当前正在执行的进程当中</p><p><img src="https://img-blog.csdnimg.cn/20210224142610940.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="从容器内拷贝到主机上"><a href="#从容器内拷贝到主机上" class="headerlink" title="从容器内拷贝到主机上"></a>从容器内拷贝到主机上</h2><p>即使容器已经停止也是可以进行拷贝的</p><figure class="highlight powershell"><table><tr><td class="code"><pre><code class="hljs powershell">docker cp 容器id:容器内路径 目的主机路径<br></code></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210224144038919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="docker部署nginx"><a href="#docker部署nginx" class="headerlink" title="docker部署nginx"></a>docker部署nginx</h2><figure class="highlight powershell"><table><tr><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$</span> docker search nginx<br><span class="hljs-variable">$</span> docker pull nginx<br><span class="hljs-variable">$</span> docker run <span class="hljs-literal">-d</span> -<span class="hljs-literal">-name</span> nginx01 <span class="hljs-literal">-p</span> <span class="hljs-number">8083</span>:<span class="hljs-number">80</span> nginx<br><span class="hljs-variable">$</span> docker ps<br><span class="hljs-variable">$</span> curl localhost:<span class="hljs-number">8083</span><br></code></pre></td></tr></table></figure><p><code>docker stop</code> 后则无法再访问<br><img src="https://img-blog.csdnimg.cn/20210224145948506.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210224150019256.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210224144959653.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="portainer可视化管理"><a href="#portainer可视化管理" class="headerlink" title="portainer可视化管理"></a>portainer可视化管理</h2><figure class="highlight powershell"><table><tr><td class="code"><pre><code class="hljs powershell">docker run <span class="hljs-literal">-d</span> <span class="hljs-literal">-p</span> <span class="hljs-number">8088</span>:<span class="hljs-number">9000</span> -<span class="hljs-literal">-restart</span>=always <span class="hljs-literal">-v</span> /var/run/docker.sock:/var/run/docker.sock -<span class="hljs-literal">-privileged</span>=true portainer/portainer<br></code></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210224152421776.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>进入后选择<strong>local模式</strong>，然后就能看到这个版面了<br><img src="https://img-blog.csdnimg.cn/20210224152631399.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>参考链接：<br><a href="https://www.bilibili.com/video/BV1og4y1q7M4?p=9" target="_blank" rel="noopener">【狂神说Java】Docker最新超详细版教程通俗易懂</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Docker-常用命令&quot;&gt;&lt;a href=&quot;#Docker-常用命令&quot; class=&quot;headerlink&quot; title=&quot;Docker 常用命令&quot;&gt;&lt;/a&gt;Docker 常用命令&lt;/h1&gt;&lt;h2 id=&quot;帮助命令&quot;&gt;&lt;a href=&quot;#帮助命令&quot; class=&quot;headerlink&quot; title=&quot;帮助命令&quot;&gt;&lt;/a&gt;帮助命令&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;code class=&quot;hljs bash&quot;&gt;docker version &lt;span class=&quot;hljs-comment&quot;&gt;#显示docker版本信息&lt;/span&gt;&lt;br&gt;docker info &lt;span class=&quot;hljs-comment&quot;&gt;#显示docker的系统信息，包括镜像和容器的数量&lt;/span&gt;&lt;br&gt;docker 命令 --&lt;span class=&quot;hljs-built_in&quot;&gt;help&lt;/span&gt; &lt;span class=&quot;hljs-comment&quot;&gt;# 帮助命令&lt;/span&gt;&lt;br&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;h2 id=&quot;镜像命令&quot;&gt;&lt;a href=&quot;#镜像命令&quot; class=&quot;headerlink&quot; title=&quot;镜像命令&quot;&gt;&lt;/a&gt;镜像命令&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;1.&lt;code&gt;docker images&lt;/code&gt;查看所有本地的主机镜像&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;left&quot;&gt;docker images显示字段&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;解释&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;REPOSITORY&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;镜像的仓库源&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;TAG&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;镜像的标签&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;IMAGE ID&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;镜像的id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;CREATED&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;镜像的创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;left&quot;&gt;SIZE&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;镜像的大小&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
    
    </summary>
    
    
    
      <category term="docker" scheme="https://yoursite.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>docker安装和简易原理</title>
    <link href="https://yoursite.com/2021/02/24/docker%E5%AE%89%E8%A3%85%E5%92%8C%E7%AE%80%E6%98%93%E5%8E%9F%E7%90%86/"/>
    <id>https://yoursite.com/2021/02/24/docker%E5%AE%89%E8%A3%85%E5%92%8C%E7%AE%80%E6%98%93%E5%8E%9F%E7%90%86/</id>
    <published>2021-02-24T04:53:00.000Z</published>
    <updated>2021-02-24T04:57:02.012Z</updated>
    
    <content type="html"><![CDATA[<h2 id="docker安装和简易原理"><a href="#docker安装和简易原理" class="headerlink" title="docker安装和简易原理"></a>docker安装和简易原理</h2><p>最近参加了阿里云datawhale天池的一个比赛里面需要用docker进行提交，所以借此机会学习了一下docker，b站上有个很好的视频<a href="https://www.bilibili.com/video/BV1og4y1q7M4?p=6" target="_blank" rel="noopener">【狂神说Java】Docker最新超详细版教程通俗易懂</a></p><h2 id="docker基本组成"><a href="#docker基本组成" class="headerlink" title="docker基本组成"></a>docker基本组成</h2><p><img src="https://img-blog.csdnimg.cn/20210224124633537.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><a id="more"></a><p><img src="https://img-blog.csdnimg.cn/20210224124854806.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="docker安装"><a href="#docker安装" class="headerlink" title="docker安装"></a>docker安装</h2><p>centos7安装<br>先查看centos版本，新版本的docker都只支持centos7以上</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">(base) [root@iZuf69rye0flkbn4kbxrobZ ~]<span class="hljs-comment"># cat /etc/os-release</span><br>NAME=<span class="hljs-string">"CentOS Linux"</span><br>VERSION=<span class="hljs-string">"7 (Core)"</span><br>ID=<span class="hljs-string">"centos"</span><br>ID_LIKE=<span class="hljs-string">"rhel fedora"</span><br>VERSION_ID=<span class="hljs-string">"7"</span><br>PRETTY_NAME=<span class="hljs-string">"CentOS Linux 7 (Core)"</span><br>ANSI_COLOR=<span class="hljs-string">"0;31"</span><br>CPE_NAME=<span class="hljs-string">"cpe:/o:centos:centos:7"</span><br>HOME_URL=<span class="hljs-string">"https://www.centos.org/"</span><br>BUG_REPORT_URL=<span class="hljs-string">"https://bugs.centos.org/"</span><br><br>CENTOS_MANTISBT_PROJECT=<span class="hljs-string">"CentOS-7"</span><br>CENTOS_MANTISBT_PROJECT_VERSION=<span class="hljs-string">"7"</span><br>REDHAT_SUPPORT_PRODUCT=<span class="hljs-string">"centos"</span><br>REDHAT_SUPPORT_PRODUCT_VERSION=<span class="hljs-string">"7"</span><br></code></pre></td></tr></table></figure><p>然后我们的操作均按照帮助文档进行操作即可<br><a href="https://docs.docker.com/engine/install/centos/" target="_blank" rel="noopener">dockerCentos安装</a></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 卸载旧版本</span><br>sudo yum remove docker \<br>                  docker-client \<br>                  docker-client-latest \<br>                  docker-common \<br>                  docker-latest \<br>                  docker-latest-logrotate \<br>                  docker-logrotate \<br>                  docker-engine<br><br><span class="hljs-comment"># 安装</span><br>sudo yum install -y yum-utils<br><br><span class="hljs-comment">#配置镜像，官方是国外的很慢，这里我们使用阿里云镜像</span><br>sudo yum-config-manager \<br>    --add-repo \<br>    https://download.docker.com/linux/centos/docker-ce.repo<br><br><span class="hljs-comment"># 推荐使用这个</span><br>sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo<br><br><span class="hljs-comment">#更新yum</span><br>yum makecache fast<br><br><span class="hljs-comment"># 安装相关的包</span><br> sudo yum install docker-ce docker-ce-cli containerd.io<br></code></pre></td></tr></table></figure><h2 id="Start-Docker"><a href="#Start-Docker" class="headerlink" title="Start Docker"></a>Start Docker</h2><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo systemctl start docker<br></code></pre></td></tr></table></figure><p>使用<code>docker version</code>查看是否安装成功<br><img src="https://img-blog.csdnimg.cn/2021022412185923.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><code>sudo docker run hello-world</code><img src="https://img-blog.csdnimg.cn/20210224122343176.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>使用<code>docker images</code> 查看所安装的所有镜像<br><img src="https://img-blog.csdnimg.cn/20210224122509960.png" alt="在这里插入图片描述"></p><h2 id="Uninstall-Docker-Engine"><a href="#Uninstall-Docker-Engine" class="headerlink" title="Uninstall Docker Engine"></a>Uninstall Docker Engine</h2><p>1.Uninstall the Docker Engine, CLI, and Containerd packages:</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo yum remove docker-ce docker-ce-cli containerd.io<br></code></pre></td></tr></table></figure><p>2.删除默认工作目录和资源</p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ sudo rm -rf /var/lib/docker<br></code></pre></td></tr></table></figure><h2 id="阿里云镜像加速器"><a href="#阿里云镜像加速器" class="headerlink" title="阿里云镜像加速器"></a>阿里云镜像加速器</h2><p>这一块的话推荐天池的一个<a href="https://tianchi.aliyun.com/competition/entrance/231759/tab/226" target="_blank" rel="noopener">docker学习赛</a><br>登录阿里云找到容器服务，并创建新容器,然后找到里面的镜像加速器对centos进行配置。<br><img src="https://img-blog.csdnimg.cn/20210224123245412.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">sudo mkdir -p /etc/docker<br><br>sudo tee /etc/docker/daemon.json &lt;&lt;-<span class="hljs-string">'EOF'</span><br>&#123;<br>  <span class="hljs-string">"registry-mirrors"</span>: [<span class="hljs-string">"https://fdm7vcvf.mirror.aliyuncs.com"</span>]<br>&#125;<br>EOF<br><br>sudo systemctl daemon-reload<br><br>sudo systemctl restart docker<br></code></pre></td></tr></table></figure><h2 id="回归Hello-World镜像的运行过程"><a href="#回归Hello-World镜像的运行过程" class="headerlink" title="回归Hello World镜像的运行过程"></a>回归Hello World镜像的运行过程</h2><p><img src="https://img-blog.csdnimg.cn/20210224123453853.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="底层原理"><a href="#底层原理" class="headerlink" title="底层原理"></a>底层原理</h2><p>Docker是什么工作的?<br>Docker是一个Client - Server结构的系统，Docker的守护进行运行在主机上。通过Socket从客户端访问!DockerServer接收到Docker-Client的指令，就会执行这个命令!<br><img src="https://img-blog.csdnimg.cn/20210224124010560.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>docker为什么比虚拟机快？<br><a href="https://www.cnblogs.com/fanqisoft/p/10440220.html" target="_blank" rel="noopener">参考链接</a></p><p><img src="https://img-blog.csdnimg.cn/20210224124320560.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210224124350819.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;docker安装和简易原理&quot;&gt;&lt;a href=&quot;#docker安装和简易原理&quot; class=&quot;headerlink&quot; title=&quot;docker安装和简易原理&quot;&gt;&lt;/a&gt;docker安装和简易原理&lt;/h2&gt;&lt;p&gt;最近参加了阿里云datawhale天池的一个比赛里面需要用docker进行提交，所以借此机会学习了一下docker，b站上有个很好的视频&lt;a href=&quot;https://www.bilibili.com/video/BV1og4y1q7M4?p=6&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;【狂神说Java】Docker最新超详细版教程通俗易懂&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;docker基本组成&quot;&gt;&lt;a href=&quot;#docker基本组成&quot; class=&quot;headerlink&quot; title=&quot;docker基本组成&quot;&gt;&lt;/a&gt;docker基本组成&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20210224124633537.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70&quot; alt=&quot;在这里插入图片描述&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="docker" scheme="https://yoursite.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>datawhale语义分割-Task4 评价函数与损失函数</title>
    <link href="https://yoursite.com/2021/02/23/datawhale%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2-Task4-%E8%AF%84%E4%BB%B7%E5%87%BD%E6%95%B0%E4%B8%8E%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    <id>https://yoursite.com/2021/02/23/datawhale%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2-Task4-%E8%AF%84%E4%BB%B7%E5%87%BD%E6%95%B0%E4%B8%8E%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</id>
    <published>2021-02-23T06:55:04.000Z</published>
    <updated>2021-02-23T07:12:11.530Z</updated>
    
    <content type="html"><![CDATA[<h1 id="零基础入门语义分割-Task4-评价函数与损失函数"><a href="#零基础入门语义分割-Task4-评价函数与损失函数" class="headerlink" title="零基础入门语义分割-Task4 评价函数与损失函数"></a>零基础入门语义分割-Task4 评价函数与损失函数</h1><p>本章主要介绍语义分割的评价函数和各类损失函数。</p><h2 id="4-评价函数与损失函数"><a href="#4-评价函数与损失函数" class="headerlink" title="4 评价函数与损失函数"></a>4 评价函数与损失函数</h2><h3 id="4-1-学习目标"><a href="#4-1-学习目标" class="headerlink" title="4.1 学习目标"></a>4.1 学习目标</h3><ul><li>掌握常见的评价函数和损失函数Dice、IoU、BCE、Focal Loss、Lovász-Softmax；</li><li>掌握评价/损失函数的实践；</li></ul><a id="more"></a><h3 id="4-2-TP-TN-FP-FN"><a href="#4-2-TP-TN-FP-FN" class="headerlink" title="4.2 TP TN FP FN"></a>4.2 TP TN FP FN</h3><p>在讲解语义分割中常用的评价函数和损失函数之前，先补充一**TP(真正例 true positive) TN(真反例 true negative) FP(假正例 false positive) FN(假反例 false negative)**的知识。在分类问题中，我们经常看到上述的表述方式，以二分类为例，我们可以将所有的样本预测结果分成TP、TN、 FP、FN四类，并且每一类含有的样本数量之和为总样本数量，即TP+FP+FN+TN=总样本数量。其混淆矩阵如下：</p><p><img src="https://img-blog.csdnimg.cn/20210223144602309.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>上述的概念都是通过以预测结果的视角定义的，可以依据下面方式理解：</p><ul><li><p>预测结果中的正例 → 在实际中是正例 → 的所有样本被称为真正例（TP）&lt;预测正确&gt;</p></li><li><p>预测结果中的正例 → 在实际中是反例 → 的所有样本被称为假正例（FP）&lt;预测错误&gt;</p></li><li><p>预测结果中的反例 → 在实际中是正例 → 的所有样本被称为假反例（FN）&lt;预测错误&gt;</p></li><li><p>预测结果中的反例 → 在实际中是反例 → 的所有样本被称为真反例（TN）&lt;预测正确&gt;</p></li></ul><p>这里就不得不提及精确率（precision）和召回率（recall）：<br>$$<br>Precision=\frac{TP}{TP+FP} \<br>Recall=\frac{TP}{TP+FN}<br>$$<br>$Precision$代表了预测的正例中真正的正例所占比例；$Recall$代表了真正的正例中被正确预测出来的比例。</p><p>转移到语义分割任务中来，我们可以将语义分割看作是对每一个图像像素的的分类问题。根据混淆矩阵中的定义，我们亦可以将特定像素所属的集合或区域划分成TP、TN、 FP、FN四类。</p><p><img src="https://img-blog.csdnimg.cn/20210223144629443.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>以上面的图片为例，图中左子图中的人物区域（黄色像素集合）是我们<strong>真实标注的前景信息（target）</strong>，其他区域（紫色像素集合）为背景信息。当经过预测之后，我们会得到的一张预测结果，图中右子图中的黄色像素为<strong>预测的前景（prediction）</strong>，紫色像素为预测的背景区域。此时，我们便能够将预测结果分成4个部分：</p><ul><li><p>预测结果中的黄色无线区域 → 真实的前景 → 的所有像素集合被称为真正例（TP）&lt;预测正确&gt;</p></li><li><p>预测结果中的蓝色斜线区域 → 真实的背景 → 的所有像素集合被称为假正例（FP）&lt;预测错误&gt;</p></li><li><p>预测结果中的红色斜线区域 → 真实的前景 → 的所有像素集合被称为假反例（FN）&lt;预测错误&gt;</p></li><li><p>预测结果中的白色斜线区域 → 真实的背景 → 的所有像素集合被称为真反例（TN）&lt;预测正确&gt;</p></li></ul><h3 id="4-3-Dice评价指标"><a href="#4-3-Dice评价指标" class="headerlink" title="4.3 Dice评价指标"></a>4.3 Dice评价指标</h3><p><strong>Dice系数</strong></p><p>Dice系数（Dice coefficient）是常见的评价分割效果的方法之一，同样也可以改写成损失函数用来度量prediction和target之间的距离。Dice系数定义如下：</p><p>$$<br>Dice (T, P) = \frac{2 |T \cap P|}{|T| \cup |P|} = \frac{2TP}{FP+2TP+FN}<br>$$<br>式中：$T$表示真实前景（target），$P$表示预测前景（prediction）。Dice系数取值范围为$[0,1]$，其中值为1时代表预测与真实完全一致。仔细观察，Dice系数与分类评价指标中的F1 score很相似：</p><p>$$<br>\frac{1}{F1} = \frac{1}{Precision} + \frac{1}{Recall}<br>$$</p><p>$$<br>F1 = \frac{2TP}{FP+2TP+FN}<br>$$</p><p>所以，Dice系数不仅在直观上体现了target与prediction的相似程度，同时其本质上还隐含了精确率和召回率两个重要指标。</p><p>计算Dice时，将$|T \cap P|$近似为prediction与target对应元素相乘再相加的结果。$|T|$ 和$|P|$的计算直接进行简单的元素求和（也有一些做法是取平方求和），如下示例：<br>$$<br>|T \cap P| =<br>\begin{bmatrix}<br>0.01 &amp; 0.03 &amp; 0.02 &amp; 0.02 \<br>0.05 &amp; 0.12 &amp; 0.09 &amp; 0.07 \<br>0.89 &amp; 0.85 &amp; 0.88 &amp; 0.91 \<br>0.99 &amp; 0.97 &amp; 0.95 &amp; 0.97 \<br>\end{bmatrix} *<br>\begin{bmatrix}<br>0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 \<br>1 &amp; 1 &amp; 1 &amp; 1 \<br>1 &amp; 1 &amp; 1 &amp; 1 \<br>\end{bmatrix} \stackrel{}{\rightarrow}<br>\begin{bmatrix}<br>0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 \<br>0.89 &amp; 0.85 &amp; 0.88 &amp; 0.91 \<br>0.99 &amp; 0.97 &amp; 0.95 &amp; 0.97 \<br>\end{bmatrix} \stackrel{sum}{\rightarrow} 7.41<br>$$</p><p>$$<br>|T| =<br>\begin{bmatrix}<br>0.01 &amp; 0.03 &amp; 0.02 &amp; 0.02 \<br>0.05 &amp; 0.12 &amp; 0.09 &amp; 0.07 \<br>0.89 &amp; 0.85 &amp; 0.88 &amp; 0.91 \<br>0.99 &amp; 0.97 &amp; 0.95 &amp; 0.97 \<br>\end{bmatrix} \stackrel{sum}{\rightarrow} 7.82<br>$$</p><p>$$<br>|P| =<br>\begin{bmatrix}<br>0 &amp; 0 &amp; 0 &amp; 0 \<br>0 &amp; 0 &amp; 0 &amp; 0 \<br>1 &amp; 1 &amp; 1 &amp; 1 \<br>1 &amp; 1 &amp; 1 &amp; 1 \<br>\end{bmatrix}  \stackrel{sum}{\rightarrow} 8<br>$$</p><p><strong>Dice Loss</strong></p><p>Dice Loss是在<a href="https://arxiv.org/abs/1606.04797" target="_blank" rel="noopener">V-net</a>模型中被提出应用的，是通过Dice系数转变而来，其实为了能够实现最小化的损失函数，以方便模型训练，以$1 - Dice$的形式作为损失函数：<br>$$<br>L = 1-\frac{2 |T \cap P|}{|T| \cup |P|}<br>$$<br>在一些场合还可以添加上<strong>Laplace smoothing</strong>减少过拟合：<br>$$<br>L = 1-\frac{2 |T \cap P| + 1}{|T| \cup |P|+1}<br>$$</p><p><strong>代码实现</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dice</span><span class="hljs-params">(output, target)</span>:</span><br>    <span class="hljs-string">'''计算Dice系数'''</span><br>    smooth = <span class="hljs-number">1e-6</span> <span class="hljs-comment"># 避免0为除数</span><br>    intersection = (output * target).sum()<br>    <span class="hljs-keyword">return</span> (<span class="hljs-number">2.</span> * intersection + smooth) / (output.sum() + target.sum() + smooth)<br><br><span class="hljs-comment"># 生成随机两个矩阵测试</span><br>target = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br>output = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br><br>d = dice(output, target)<br><span class="hljs-comment"># ----------------------------</span><br>target = array([[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>       [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]])<br>output = array([[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br>       [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br>       [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])<br>d = <span class="hljs-number">0.5714286326530524</span><br></code></pre></td></tr></table></figure><h3 id="4-4-IoU评价指标"><a href="#4-4-IoU评价指标" class="headerlink" title="4.4 IoU评价指标"></a>4.4 IoU评价指标</h3><p>IoU（intersection over union）指标就是常说的交并比，不仅在语义分割评价中经常被使用，在目标检测中也是常用的评价指标。顾名思义，交并比就是指target与prediction两者之间交集与并集的比值：<br>$$<br>IoU=\frac{T \cap P}{T \cup P}=\frac{TP}{FP+TP+FN}<br>$$<br>仍然以人物前景分割为例，如下图，其IoU的计算就是使用$intersection / union$。</p><table><thead><tr><th align="center">target</th><th align="center">prediction</th></tr></thead><tbody><tr><td align="center"><img src="https://img-blog.csdnimg.cn/20210223144740581.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></td><td align="center"><img src="https://img-blog.csdnimg.cn/20210223144755503.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></td></tr><tr><td align="center">Intersection( $T \cap P$)</td><td align="center">union($T \cup P$)</td></tr><tr><td align="center"><img src="https://img-blog.csdnimg.cn/20210223144825627.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></td><td align="center"><img src="https://img-blog.csdnimg.cn/20210223144847490.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></td></tr></tbody></table><p><strong>代码实现</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">iou_score</span><span class="hljs-params">(output, target)</span>:</span><br>    <span class="hljs-string">'''计算IoU指标'''</span><br>intersection = np.logical_and(target, output) <br>    union = np.logical_or(target, output) <br>    <span class="hljs-keyword">return</span> np.sum(intersection) / np.sum(union)<br><br><span class="hljs-comment"># 生成随机两个矩阵测试</span><br>target = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br>output = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br><br>d = iou_score(output, target)<br><span class="hljs-comment"># ----------------------------</span><br>target = array([[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>       [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]])<br>output = array([[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br>       [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br>       [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])<br>d = <span class="hljs-number">0.4</span><br></code></pre></td></tr></table></figure><h3 id="4-5-BCE损失函数"><a href="#4-5-BCE损失函数" class="headerlink" title="4.5 BCE损失函数"></a>4.5 BCE损失函数</h3><p>BCE损失函数（Binary Cross-Entropy Loss）是交叉熵损失函数（Cross-Entropy Loss）的一种特例，BCE Loss只应用在二分类任务中。针对分类问题，单样本的交叉熵损失为：<br>$$<br>l(\pmb y, \pmb{\hat y})=- \sum_{i=1}^{c}y_i \cdot log\hat y_i<br>$$<br>式中，$\pmb{y}={y_1,y_2,…,y_c,}$，其中$y_i$是非0即1的数字，代表了是否属于第$i$类，为真实值；$\hat y_i$代表属于第i类的概率，为预测值。可以看出，交叉熵损失考虑了多类别情况，针对每一种类别都求了损失。针对二分类问题，上述公式可以改写为：<br>$$<br>l(y,\hat y)=-[y \cdot log\hat y +(1-y)\cdot log (1-\hat y)]<br>$$<br>式中,$y$为真实值，非1即0；$\hat y$为所属此类的概率值，为预测值。这个公式也就是BCE损失函数，即二分类任务时的交叉熵损失。值得强调的是，公式中的$\hat y$为概率分布形式，因此在使用BCE损失前，<strong>都应该将预测出来的结果转变成概率值</strong>，一般为sigmoid激活之后的输出。</p><p><strong>代码实现</strong></p><p>在pytorch中，官方已经给出了BCE损失函数的API，免去了自己编写函数的痛苦：</p><blockquote><p><code>torch.nn.BCELoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = &#39;mean&#39;)</code><br>$$<br>ℓ(y,\hat y)=L={l_1,…,l_N }^⊤,\ \ \  l_n=-w_n[y_n \cdot log\hat y_n +(1-y_n)\cdot log (1-\hat y_n)]<br>$$<br>参数：<br>weight(Tensor)- 为每一批量下的loss添加一个权重，很少使用<br>size_average(bool)- 弃用中<br>reduce(bool)- 弃用中<br>reduction(str) - ‘none’ | ‘mean’ | ‘sum’：为代替上面的size_average和reduce而生。——为mean时返回的该批量样本loss的平均值；为sum时，返回的该批量样本loss之和</p></blockquote><p><strong>同时，pytorch还提供了已经结合了Sigmoid函数的BCE损失：<code>torch.nn.BCEWithLogitsLoss()</code>，相当于免去了实现进行Sigmoid激活的操作。</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br>bce = nn.BCELoss()<br>bce_sig = nn.BCEWithLogitsLoss()<br><br>input = torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">1</span>, requires_grad=<span class="hljs-literal">True</span>)<br>target = torch.empty(<span class="hljs-number">5</span>, <span class="hljs-number">1</span>).random_(<span class="hljs-number">2</span>)<br>pre = nn.Sigmoid()(input)<br><br>loss_bce = bce(pre, target)<br>loss_bce_sig = bce_sig(input, target)<br><br><span class="hljs-comment"># ------------------------</span><br>input = tensor([[<span class="hljs-number">-0.2296</span>],<br>        [<span class="hljs-number">-0.6389</span>],<br>        [<span class="hljs-number">-0.2405</span>],<br>        [ <span class="hljs-number">1.3451</span>],<br>        [ <span class="hljs-number">0.7580</span>]], requires_grad=<span class="hljs-literal">True</span>)<br>output = tensor([[<span class="hljs-number">1.</span>],<br>         [<span class="hljs-number">0.</span>],<br>         [<span class="hljs-number">0.</span>],<br>         [<span class="hljs-number">1.</span>],<br>         [<span class="hljs-number">1.</span>]])<br>pre = tensor([[<span class="hljs-number">0.4428</span>],<br>          [<span class="hljs-number">0.3455</span>],<br>          [<span class="hljs-number">0.4402</span>],<br>          [<span class="hljs-number">0.7933</span>],<br>          [<span class="hljs-number">0.6809</span>]], grad_fn=&lt;SigmoidBackward&gt;)<br><br>print(loss_bce)<br>tensor(<span class="hljs-number">0.4869</span>, grad_fn=&lt;BinaryCrossEntropyBackward&gt;)<br><br>print(loss_bce_sig)<br>tensor(<span class="hljs-number">0.4869</span>, grad_fn=&lt;BinaryCrossEntropyWithLogitsBackward&gt;)<br></code></pre></td></tr></table></figure><h3 id="4-6-Focal-Loss"><a href="#4-6-Focal-Loss" class="headerlink" title="4.6 Focal Loss"></a>4.6 Focal Loss</h3><p>Focal loss最初是出现在目标检测领域，主要是为了解决正负样本比例失调的问题。那么对于分割任务来说，如果存在数据不均衡的情况，也可以借用focal loss来进行缓解。Focal loss函数公式如下所示：</p><p>$$<br>loss = -\frac{1}{N} \sum_{i=1}^{N}\left(\alpha y_{i}\left(1-p_{i}\right)^{\gamma} \log p_{i}+(1-\alpha)\left(1-y_{i}\right) p_{i}^{\gamma} \log \left(1-p_{i}\right)\right)<br>$$<br>仔细观察就不难发现，它其实是BCE扩展而来，对比BCE其实就多了个<br>$$<br>\alpha(1-p_{i})^{\gamma}和(1-\alpha)p_{i}^{\gamma}<br>$$<br>为什么多了这个就能缓解正负样本不均衡的问题呢？见下图：</p><p><img src="https://img-blog.csdnimg.cn/20210223144942139.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>简单来说：$α$解决样本不平衡问题，$γ$解决样本难易问题。</p><p>也就是说，当数据不均衡时，可以根据比例设置合适的$α$，这个很好理解，为了能够使得正负样本得到的损失能够均衡，因此对loss前面加上一定的权重，其中负样本数量多，因此占用的权重可以设置的小一点；正样本数量少，就对正样本产生的损失的权重设的高一点。</p><p>那γ具体怎么起作用呢？以图中$γ=5$曲线为例，假设$gt$类别为1，当模型预测结果为1的概率$p_t$比较大时，我们认为模型预测的比较准确，也就是说这个样本比较简单。而对于比较简单的样本，我们希望提供的loss小一些而让模型主要学习难一些的样本，也就是$p_t→ 1$则loss接近于0，既不用再特别学习；当分类错误时，$p_t → 0$则loss正常产生，继续学习。对比图中蓝色和绿色曲线，可以看到，γ值越大，当模型预测结果比较准确的时候能提供更小的loss，符合我们为简单样本降低loss的预期。</p><p><strong>代码实现：</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FocalLoss</span><span class="hljs-params">(nn.Module)</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, alpha=<span class="hljs-number">1</span>, gamma=<span class="hljs-number">2</span>, logits=False, reduce=True)</span>:</span><br>        super(FocalLoss, self).__init__()<br>        self.alpha = alpha<br>        self.gamma = gamma<br>        self.logits = logits<span class="hljs-comment"># 如果BEC带logits则损失函数在计算BECloss之前会自动计算softmax/sigmoid将其映射到[0,1]</span><br>        self.reduce = reduce<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, inputs, targets)</span>:</span><br>        <span class="hljs-keyword">if</span> self.logits:<br>            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">else</span>:<br>            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=<span class="hljs-literal">False</span>)<br>        pt = torch.exp(-BCE_loss)<br>        F_loss = self.alpha * (<span class="hljs-number">1</span>-pt)**self.gamma * BCE_loss<br><br>        <span class="hljs-keyword">if</span> self.reduce:<br>            <span class="hljs-keyword">return</span> torch.mean(F_loss)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> F_loss<br><br><span class="hljs-comment"># ------------------------</span><br><br>FL1 = FocalLoss(logits=<span class="hljs-literal">False</span>)<br>FL2 = FocalLoss(logits=<span class="hljs-literal">True</span>)<br><br>inputs = torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">1</span>, requires_grad=<span class="hljs-literal">True</span>)<br>targets = torch.empty(<span class="hljs-number">5</span>, <span class="hljs-number">1</span>).random_(<span class="hljs-number">2</span>)<br>pre = nn.Sigmoid()(inputs)<br><br>f_loss_1 = FL1(pre, targets)<br>f_loss_2 = FL2(inputs, targets)<br><br><span class="hljs-comment"># ------------------------</span><br><br>print(<span class="hljs-string">'inputs:'</span>, inputs)<br>inputs: tensor([[<span class="hljs-number">-1.3521</span>],<br>        [ <span class="hljs-number">0.4975</span>],<br>        [<span class="hljs-number">-1.0178</span>],<br>        [<span class="hljs-number">-0.3859</span>],<br>        [<span class="hljs-number">-0.2923</span>]], requires_grad=<span class="hljs-literal">True</span>)<br>    <br>print(<span class="hljs-string">'targets:'</span>, targets)<br>targets: tensor([[<span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">0.</span>],<br>        [<span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>]])<br>    <br>print(<span class="hljs-string">'pre:'</span>, pre)<br>pre: tensor([[<span class="hljs-number">0.2055</span>],<br>        [<span class="hljs-number">0.6219</span>],<br>        [<span class="hljs-number">0.2655</span>],<br>        [<span class="hljs-number">0.4047</span>],<br>        [<span class="hljs-number">0.4274</span>]], grad_fn=&lt;SigmoidBackward&gt;)<br>    <br>print(<span class="hljs-string">'f_loss_1:'</span>, f_loss_1)<br>f_loss_1: tensor(<span class="hljs-number">0.3375</span>, grad_fn=&lt;MeanBackward0&gt;)<br>    <br>print(<span class="hljs-string">'f_loss_2'</span>, f_loss_2)<br>f_loss_2 tensor(<span class="hljs-number">0.3375</span>, grad_fn=&lt;MeanBackward0&gt;)<br></code></pre></td></tr></table></figure><h3 id="4-7-Lovasz-Softmax"><a href="#4-7-Lovasz-Softmax" class="headerlink" title="4.7 Lovász-Softmax"></a>4.7 Lovász-Softmax</h3><p>IoU是评价分割模型分割结果质量的重要指标，因此很自然想到能否用$1-IoU$（即Jaccard loss）来做损失函数，但是它是一个离散的loss，不能直接求导，所以无法直接用来作为损失函数。为了克服这个离散的问题，可以采用lLovász extension将离散的Jaccard loss 变得连续，从而可以直接求导，使得其作为分割网络的loss function。Lovász-Softmax相比于交叉熵函数具有更好的效果。</p><p>论文地址：<br><a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Berman_The_LovaSz-Softmax_Loss_CVPR_2018_paper.html" target="_blank" rel="noopener">paper on CVF open access</a><br><a href="https://arxiv.org/abs/1705.08790" target="_blank" rel="noopener">arxiv paper</a></p><p>首先明确定义，在语义分割任务中，给定真实像素标签向量$\pmb{y^*}$和预测像素标签$\pmb{\hat{y} }$，则所属类别$c$的IoU（也称为Jaccard index）如下，其取值范围为$[0,1]$，并规定$0/0=1$：</p><p>$$J_c(\pmb{y^*},\pmb{\hat{y} })=\frac{|{\pmb{y^*}=c} \cap {\pmb{\hat{y} }=c}|}{|{\pmb{y^*}=c} \cup {\pmb{\hat{y} }=c}|}<br>$$</p><p>则Jaccard loss为：<br>$$\Delta_{J_c}(\pmb{y^*},\pmb{\hat{y} }) =1-J_c(\pmb{y^*},\pmb{\hat{y} })<br>$$</p><p>针对类别$c$，所有未被正确预测的像素集合定义为：</p><p>$$<br>M_c(\pmb{y^*},\pmb{\hat{y} })={ \pmb{y^*}=c, \pmb{\hat{y} } \neq c} \cup {  \pmb{y^*}\neq c, \pmb{\hat{y} } = c  }<br>$$</p><p>则可将Jaccard loss改写为关于$M_c$的子模集合函数（submodular set functions）：<br>$$\Delta_{J_c}:M_c \in {0,1}^{p} \mapsto \frac{|M_c|}{|{\pmb{y^*}=c}\cup M_c|}<br>$$</p><p>方便理解，此处可以把${0,1}^p$理解成如图像mask展开成离散一维向量的形式。</p><p>Lovász extension可以求解子模最小化问题，并且子模的Lovász extension是凸函数，可以高效实现最小化。在论文中作者对$\Delta$（集合函数）和$\overline{\Delta}$（集合函数的Lovász extension）进行了定义，为不涉及过多概念以方便理解，此处不再过多讨论。我们可以将$\overline{\Delta}$理解为一个线性插值函数，可以将${0,1}^p$这种离散向量连续化，主要是为了方便后续反向传播、求梯度等等。因此我们可以通过这个线性插值函数得到$\Delta_{J_c}$的Lovász extension$\overline{\Delta_{J_c} }$。</p><p>在具有$c(c&gt;2)$个类别的语义分割任务中，我们使用Softmax函数将模型的输出映射到概率分布形式，类似传统交叉熵损失函数所进行的操作：<br>$$p_i(c)=\frac{e^{F_i(c)} }{\sum_{c^{‘}\in C}e^{F_i(c^{‘})} }　　\forall i \in [1,p],\forall c \in C<br>$$<br>式中，$p_i(c)$表示了像素$i$所属类别$c$的概率。通过上式可以构建每个像素产生的误差$m(c)$：</p><p>$$m_i(c)=\left {<br>\begin{array}{c}<br>1-p_i(c),\ \ if \ \ c=y^{*}_{i} \<br>p_i(c),\ \ \ \ \ \ \ otherwise<br>\end{array}<br>\right.<br>$$</p><p>可知，对于一张图像中所有像素则误差向量为$m(c)\in {0, 1}^p$，则可以建立关于$\Delta_{J_c}$的代理损失函数：<br>$$<br>loss(p(c))=\overline{\Delta_{J_c} }(m(c))<br>$$<br>当我们考虑整个数据集是，一般会使用mIoU进行度量，因此我们对上述损失也进行平均化处理，则定义的Lovász-Softmax损失函数为：<br>$$<br>loss(\pmb{p})=\frac{1}{|C|}\sum_{c\in C}\overline{\Delta_{J_c} }(m(c))<br>$$</p><p><strong>代码实现</strong></p><p>论文作者已经给出了Lovász-Softmax实现代码，并且有pytorch和tensorflow两种版本，并提供了使用demo。此处将针对多分类任务的Lovász-Softmax源码进行展示。</p><p><a href="https://github.com/bermanmaxim/LovaszSoftmax" target="_blank" rel="noopener">Lovász-Softmax实现链接</a></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">try</span>:<br>    <span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span>  ifilterfalse<br><span class="hljs-keyword">except</span> ImportError: <span class="hljs-comment"># py3k</span><br>    <span class="hljs-keyword">from</span> itertools <span class="hljs-keyword">import</span>  filterfalse <span class="hljs-keyword">as</span> ifilterfalse<br>    <br><span class="hljs-comment"># --------------------------- MULTICLASS LOSSES ---------------------------</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lovasz_softmax</span><span class="hljs-params">(probas, labels, classes=<span class="hljs-string">'present'</span>, per_image=False, ignore=None)</span>:</span><br>    <span class="hljs-string">"""</span><br><span class="hljs-string">    Multi-class Lovasz-Softmax loss</span><br><span class="hljs-string">      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1).</span><br><span class="hljs-string">              Interpreted as binary (sigmoid) output with outputs of size [B, H, W].</span><br><span class="hljs-string">      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)</span><br><span class="hljs-string">      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.</span><br><span class="hljs-string">      per_image: compute the loss per image instead of per batch</span><br><span class="hljs-string">      ignore: void class labels</span><br><span class="hljs-string">    """</span><br>    <span class="hljs-keyword">if</span> per_image:<br>        loss = mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(<span class="hljs-number">0</span>), lab.unsqueeze(<span class="hljs-number">0</span>), ignore), classes=classes)<br>                          <span class="hljs-keyword">for</span> prob, lab <span class="hljs-keyword">in</span> zip(probas, labels))<br>    <span class="hljs-keyword">else</span>:<br>        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), classes=classes)<br>    <span class="hljs-keyword">return</span> loss<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lovasz_softmax_flat</span><span class="hljs-params">(probas, labels, classes=<span class="hljs-string">'present'</span>)</span>:</span><br>    <span class="hljs-string">"""</span><br><span class="hljs-string">    Multi-class Lovasz-Softmax loss</span><br><span class="hljs-string">      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)</span><br><span class="hljs-string">      labels: [P] Tensor, ground truth labels (between 0 and C - 1)</span><br><span class="hljs-string">      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.</span><br><span class="hljs-string">    """</span><br>    <span class="hljs-keyword">if</span> probas.numel() == <span class="hljs-number">0</span>:<br>        <span class="hljs-comment"># only void pixels, the gradients should be 0</span><br>        <span class="hljs-keyword">return</span> probas * <span class="hljs-number">0.</span><br>    C = probas.size(<span class="hljs-number">1</span>)<br>    losses = []<br>    class_to_sum = list(range(C)) <span class="hljs-keyword">if</span> classes <span class="hljs-keyword">in</span> [<span class="hljs-string">'all'</span>, <span class="hljs-string">'present'</span>] <span class="hljs-keyword">else</span> classes<br>    <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> class_to_sum:<br>        fg = (labels == c).float() <span class="hljs-comment"># foreground for class c</span><br>        <span class="hljs-keyword">if</span> (classes <span class="hljs-keyword">is</span> <span class="hljs-string">'present'</span> <span class="hljs-keyword">and</span> fg.sum() == <span class="hljs-number">0</span>):<br>            <span class="hljs-keyword">continue</span><br>        <span class="hljs-keyword">if</span> C == <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">if</span> len(classes) &gt; <span class="hljs-number">1</span>:<br>                <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">'Sigmoid output possible only with 1 class'</span>)<br>            class_pred = probas[:, <span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">else</span>:<br>            class_pred = probas[:, c]<br>        errors = (Variable(fg) - class_pred).abs()<br>        errors_sorted, perm = torch.sort(errors, <span class="hljs-number">0</span>, descending=<span class="hljs-literal">True</span>)<br>        perm = perm.data<br>        fg_sorted = fg[perm]<br>        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))<br>    <span class="hljs-keyword">return</span> mean(losses)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">flatten_probas</span><span class="hljs-params">(probas, labels, ignore=None)</span>:</span><br>    <span class="hljs-string">"""</span><br><span class="hljs-string">    Flattens predictions in the batch</span><br><span class="hljs-string">    """</span><br>    <span class="hljs-keyword">if</span> probas.dim() == <span class="hljs-number">3</span>:<br>        <span class="hljs-comment"># assumes output of a sigmoid layer</span><br>        B, H, W = probas.size()<br>        probas = probas.view(B, <span class="hljs-number">1</span>, H, W)<br>    B, C, H, W = probas.size()<br>    probas = probas.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>).contiguous().view(<span class="hljs-number">-1</span>, C)  <span class="hljs-comment"># B * H * W, C = P, C</span><br>    labels = labels.view(<span class="hljs-number">-1</span>)<br>    <span class="hljs-keyword">if</span> ignore <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-keyword">return</span> probas, labels<br>    valid = (labels != ignore)<br>    vprobas = probas[valid.nonzero().squeeze()]<br>    vlabels = labels[valid]<br>    <span class="hljs-keyword">return</span> vprobas, vlabels<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">xloss</span><span class="hljs-params">(logits, labels, ignore=None)</span>:</span><br>    <span class="hljs-string">"""</span><br><span class="hljs-string">    Cross entropy loss</span><br><span class="hljs-string">    """</span><br>    <span class="hljs-keyword">return</span> F.cross_entropy(logits, Variable(labels), ignore_index=<span class="hljs-number">255</span>)<br><br><span class="hljs-comment"># --------------------------- HELPER FUNCTIONS ---------------------------</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">isnan</span><span class="hljs-params">(x)</span>:</span><br>    <span class="hljs-keyword">return</span> x != x<br>    <br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mean</span><span class="hljs-params">(l, ignore_nan=False, empty=<span class="hljs-number">0</span>)</span>:</span><br>    <span class="hljs-string">"""</span><br><span class="hljs-string">    nanmean compatible with generators.</span><br><span class="hljs-string">    """</span><br>    l = iter(l)<br>    <span class="hljs-keyword">if</span> ignore_nan:<br>        l = ifilterfalse(isnan, l)<br>    <span class="hljs-keyword">try</span>:<br>        n = <span class="hljs-number">1</span><br>        acc = next(l)<br>    <span class="hljs-keyword">except</span> StopIteration:<br>        <span class="hljs-keyword">if</span> empty == <span class="hljs-string">'raise'</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">'Empty mean'</span>)<br>        <span class="hljs-keyword">return</span> empty<br>    <span class="hljs-keyword">for</span> n, v <span class="hljs-keyword">in</span> enumerate(l, <span class="hljs-number">2</span>):<br>        acc += v<br>    <span class="hljs-keyword">if</span> n == <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> acc<br>    <span class="hljs-keyword">return</span> acc / n<br></code></pre></td></tr></table></figure><h3 id="4-8-参考链接"><a href="#4-8-参考链接" class="headerlink" title="4.8 参考链接"></a>4.8 参考链接</h3><p><a href="https://blog.csdn.net/lingzhou33/article/details/87901365" target="_blank" rel="noopener">语义分割的评价指标IoU</a></p><p><a href="https://blog.csdn.net/Biyoner/article/details/84728417" target="_blank" rel="noopener">医学图像分割常用的损失函数</a></p><p><a href="https://www.jianshu.com/p/0998e6560288" target="_blank" rel="noopener">What is “Dice loss” for image segmentation?</a></p><p><a href="https://pytorch.org/docs/stable/nn.html#loss-functions" target="_blank" rel="noopener">pytorch loss-functions</a></p><p><a href="https://sudeepraja.github.io/Submodular/" target="_blank" rel="noopener">Submodularity and the Lovász extension</a></p><h3 id="4-9-本章小结"><a href="#4-9-本章小结" class="headerlink" title="4.9 本章小结"></a>4.9 本章小结</h3><p>本章对各类评价指标进行介绍，并进行具体代码实践。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;零基础入门语义分割-Task4-评价函数与损失函数&quot;&gt;&lt;a href=&quot;#零基础入门语义分割-Task4-评价函数与损失函数&quot; class=&quot;headerlink&quot; title=&quot;零基础入门语义分割-Task4 评价函数与损失函数&quot;&gt;&lt;/a&gt;零基础入门语义分割-Task4 评价函数与损失函数&lt;/h1&gt;&lt;p&gt;本章主要介绍语义分割的评价函数和各类损失函数。&lt;/p&gt;
&lt;h2 id=&quot;4-评价函数与损失函数&quot;&gt;&lt;a href=&quot;#4-评价函数与损失函数&quot; class=&quot;headerlink&quot; title=&quot;4 评价函数与损失函数&quot;&gt;&lt;/a&gt;4 评价函数与损失函数&lt;/h2&gt;&lt;h3 id=&quot;4-1-学习目标&quot;&gt;&lt;a href=&quot;#4-1-学习目标&quot; class=&quot;headerlink&quot; title=&quot;4.1 学习目标&quot;&gt;&lt;/a&gt;4.1 学习目标&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;掌握常见的评价函数和损失函数Dice、IoU、BCE、Focal Loss、Lovász-Softmax；&lt;/li&gt;
&lt;li&gt;掌握评价/损失函数的实践；&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>datawhale语义分割-Task3 语义分割模型发展</title>
    <link href="https://yoursite.com/2021/02/23/datawhale%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2-Task3-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95/"/>
    <id>https://yoursite.com/2021/02/23/datawhale%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2-Task3-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95/</id>
    <published>2021-02-23T05:39:00.000Z</published>
    <updated>2021-02-23T05:42:37.695Z</updated>
    
    <content type="html"><![CDATA[<h1 id="datawhale语义分割-Task3-语义分割模型发展"><a href="#datawhale语义分割-Task3-语义分割模型发展" class="headerlink" title="datawhale语义分割-Task3 语义分割模型发展"></a>datawhale语义分割-Task3 语义分割模型发展</h1><p>本章主要讲解的是语义分割网络模型的发展：FCN 、SegNet、Unet、DeepLab、RefineNet、PSPNet、GAN语义分割。</p><a id="more"></a><h2 id="3-语义分割模型发展"><a href="#3-语义分割模型发展" class="headerlink" title="3 语义分割模型发展"></a>3 语义分割模型发展</h2><p>语义分割（全像素语义分割）作为经典的计算机视觉任务（图像分类，物体识别检测，语义分割）。其结合了图像分类、目标检测和图像分割，通过一定的方法将图像分割成具有一定语义含义的区域块，并识别出每个区域块的语义类别，实现从底层到高层的语义推理过程，最终得到一幅具有逐像素语义标注的分割图像。</p><h3 id="3-1-学习目标"><a href="#3-1-学习目标" class="headerlink" title="3.1 学习目标"></a>3.1 学习目标</h3><ul><li>掌握语义分割模型的原理和训练过程；</li><li>掌握语义分割模型的发展脉络；</li><li>掌握语义分割模型的使用；</li></ul><h3 id="3-2-FCN"><a href="#3-2-FCN" class="headerlink" title="3.2 FCN"></a>3.2 FCN</h3><h4 id="FCN原理及网络结构"><a href="#FCN原理及网络结构" class="headerlink" title="FCN原理及网络结构"></a>FCN原理及网络结构</h4><p>FCN首先将一幅RGB图像输入到卷积神经网络后，经过多次卷积以及池化过程得到一系列的特征图，然后利用反卷积层对最后一个卷积层得到的特征图进行上采样，使得上采样后特征图与原图像的大小一样，从而实现对特征图上的每个像素值进行预测的同时保留其在原图像中的空间位置信息，最后对上采样特征图进行逐像素分类，逐个像素计算softmax分类损失。</p><p>主要特点：</p><ul><li><p>不含全连接层（FC）的全卷积（Fully Conv）网络。从而可适应任意尺寸输入。</p></li><li><p>引入增大数据尺寸的反卷积（Deconv）层。能够输出精细的结果。</p></li><li><p>结合不同深度层结果的跳级（skip）结构。同时确保鲁棒性和精确性。</p></li></ul><p><img src="https://img-blog.csdnimg.cn/20210223115846286.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>网络结构详解图：输入可为任意尺寸图像彩色图像；输出与输入尺寸相同，深度为20类目标+背景=21，这里的类别与数据集类别保持一致。<br><img src="https://img-blog.csdnimg.cn/20210223115913319.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p> <img src="https://img-blog.csdnimg.cn/20210223115936399.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="aa"></p><h4 id="反卷积（Deconvolutional）"><a href="#反卷积（Deconvolutional）" class="headerlink" title="反卷积（Deconvolutional）"></a>反卷积（Deconvolutional）</h4><p>unsamplingd的操作可以看成是反卷积（Deconvolutional）,卷积运算的参数和CNN的参数一样是在训练FCN模型的过程中通过bp算法学习得到。</p><p>普通的池化会缩小图片的尺寸，比如VGG16经过5次池化后图片被缩小了32倍。为了得到和原图等大小的分割图，我们需要上采样、反卷积。</p><p>反卷积和卷积类似，都是相乘相加的运算。只不过后者是多对一，前者是一对多。而反卷积的前向和反向传播，只用颠倒卷积的前后向传播即可。如下图所示：<br>图像卷积：<br><img src="https://img-blog.csdnimg.cn/20210223120011294.gif#pic_center" alt="在这里插入图片描述"><br>图像反卷积：<br><img src="https://img-blog.csdnimg.cn/20210223120030296.gif#pic_center" alt="在这里插入图片描述"></p><h4 id="跳跃结构"><a href="#跳跃结构" class="headerlink" title="跳跃结构"></a>跳跃结构</h4><p>经过全卷积后的结果进行反卷积，基本上就能实现语义分割了，但是得到的结果通常是比较粗糙的。</p><p><img src="https://img-blog.csdnimg.cn/20210223120142894.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>如上图所示，对原图像进行卷积conv1、pool1后原图像缩小为1/2；之后对图像进行第二次conv2、pool2后图像缩小为1/4；接着继续对图像进行第三次卷积操作conv3、pool3缩小为原图像的1/8，<strong>此时保留pool3的featureMap</strong>；接着继续对图像进行第四次卷积操作conv4、pool4，缩小为原图像的1/16，<strong>保留pool4的featureMap</strong>；最后对图像进行第五次卷积操作conv5、pool5，缩小为原图像的1/32，然后把原来CNN操作中的全连接变成卷积操作conv6、conv7，图像的featureMap数量改变但是图像大小依然为原图的1/32，<strong>此时图像不再叫featureMap而是叫heatMap</strong>。</p><p>现在我们有1/32尺寸的heatMap，1/16尺寸的featureMap和1/8尺寸的featureMap，1/32尺寸的heatMap进行upsampling操作之后，因为这样的操作还原的图片仅仅是conv5中的卷积核中的特征，限于精度问题不能够很好地还原图像当中的特征。因此在这里向前迭代，把conv4中的卷积核对上一次upsampling之后的图进行反卷积补充细节（相当于一个插值过程），最后把conv3中的卷积核对刚才upsampling之后的图像进行再次反卷积补充细节，最后就完成了整个图像的还原。</p><p>具体来说，就是将不同池化层的结果进行上采样，然后结合这些结果来优化输出，分为FCN-32s,FCN-16s,FCN-8s三种，第一行对应FCN-32s，第二行对应FCN-16s，第三行对应FCN-8s。 具体结构如下:</p><p><img src="https://img-blog.csdnimg.cn/20210223120220102.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>图中，image是原图像，conv1,conv2..,conv5为卷积操作，pool1,pool2,..pool5为pool操作（pool就是使得图片变为原图的1/2），注意con6-7是最后的卷积层，最右边一列是upsample后的end to end结果。<strong>必须说明的是图中nx是指对应的特征图上采样n倍（即变大n倍），并不是指有n个特征图，如32x upsampled 中的32x是图像只变大32倍，不是有32个上采样图像，又如2x conv7是指conv7的特征图变大2倍。</strong></p><p><strong>（1）FCN-32s过程</strong></p><p>只需要留意第一行，网络里面有5个pool，所以conv7的特征图是原始图像1/32，可以发现最左边image的是32x32（假设以倍数计），<strong>同时我们知道在FCN中的卷积是不会改变图像大小</strong>（或者只有少量像素的减少，特征图大小基本不会小很多）。看到pool1是16x16，pool2是8x8，pool3是4x4，pool4是2x2，pool5是1x1，所以conv7对应特征图大小为1x1，然后再经过32x upsampled prediction 图片变回32x32。FCN作者在这里增加一个卷积层，卷积后的大小为输入图像的<strong>32</strong>(2^5)倍，我们简单假设这个卷积核大小也为32，这样就是需要通过反馈训练32x32个权重变量即可让图像实现end to  end，完成了一个32s的upsample。FCN作者称做后卷积，他也提及可以称为反卷积。事实上在源码中卷积核的大小为64，同时没有偏置bias。还有一点就是FCN论文中最后结果都是21×*，这里的21是指FCN使用的数据集分类，总共有21类。 </p><p><strong>（2）FCN-16s过程</strong></p><p>现在我们把1,2两行一起看，忽略32x upsampled prediction，说明FCN-16s的upsample过程。FCN作者在conv7先进行一个2x conv7操作，其实这里也只是增加1个卷积层，这次卷积后特征图的大小为conv7的<strong>2</strong>倍，可以从pool5与2x conv7中看出来。此时2x conv7与pool4的大小是一样的，FCN作者提出对pool4与2x conv7进行一个fuse操作（<strong>事实上就是将pool4与2x conv7相加，另一篇博客说是拼接，个人认为是拼接</strong>）。fuse结果进行16x upsampled prediction，与FCN-32s一样，也是增加一个卷积层，卷积后的大小为输入图像的<strong>16</strong>(2^4)倍。我们知道pool4的大小是2x2，放大16倍，就是32x32，这样最后图像大小也变为原来的大小，至此完成了一个16s的upsample。现在我们可以知道，FCN中的upsample实际是通过增加卷积层，通过bp反馈的训练方法训练卷积层达到end to end，这时<strong>卷积层的作用可以看作是pool的逆过程</strong>。 </p><p><strong>（3）FCN-8s过程</strong></p><p>这是我们看第1行与第3行，忽略32x upsampled prediction。conv7经过一次4x  upsample，即使用一个卷积层，特征图输出大小为conv7的4倍，所得4x conv7的大小为4x4。然后pool4需要一次2x  upsample，变成2x pool4，大小也为4x4。再把4x conv7，2x  pool4与pool3进行fuse，得到求和后的特征图。最后增加一个卷积层，使得输出图片大小为pool3的8倍，也就是8x upsampled  prediction的过程，得到一个end to end的图像。实验表明<strong>FCN-8s优于FCN-16s，FCN-32s</strong>。<br>我们可以发现，如果继续仿照FCN作者的步骤，我们可以对pool2，pool1实现同样的方法，可以有FCN-4s，FCN-2s，最后得到end to end的输出。这里作者给出了明确的结论，超过FCN-8s之后，结果并不能继续优化。</p><p>结合上述的FCN的全卷积与upsample，在upsample最后加上softmax，就可以对不同类别的大小概率进行估计，实现end to end。最后输出的图是一个概率估计，对应像素点的值越大，其像素为该类的结果也越大。<strong>FCN的核心贡献在于提出使用卷积层通过学习让图片实现end to end分类。</strong></p><p><strong>事实上，FCN有一些短处</strong>，例如使用了较浅层的特征，因为fuse操作会加上较上层的pool特征值，导致高维特征不能很好得以使用，同时也因为使用较上层的pool特征值，导致FCN对图像大小变化有所要求，如果测试集的图像远大于或小于训练集的图像，FCN的效果就会变差。</p><h4 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h4><p>FCN训练过程分为四个阶段：</p><ul><li>第1阶段</li></ul><p><img src="https://img-blog.csdnimg.cn/20210223120248918.png#pic_center" alt="在这里插入图片描述"></p><p>以经典的分类网络为初始化，最后两级是全连接（红色），参数舍弃不用。</p><ul><li>第2阶段</li></ul><p><img src="https://img-blog.csdnimg.cn/20210223120258781.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>从特征图（16x16x4096）预测分割小图（ 16x16x21），之后直接升采样为大图。反卷积（橙色）的步长为32，这个网络称为FCN-32s。</p><ul><li>第3阶段</li></ul><p><img src="https://img-blog.csdnimg.cn/20210223120307854.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>升采样分为两次完成（橙色×2）。 在第二次升采样前，把第4个pooling层（绿色）的预测结果（蓝色）融合进来。使用跳级结构提升精确性。 第二次反卷积步长为16，这个网络称为FCN-16s。 </p><ul><li>第4阶段<br><img src="https://img-blog.csdnimg.cn/20210223120317246.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></li></ul><p>升采样分为三次完成（橙色×3）。 进一步融合了第3个pooling层的预测结果。 第三次反卷积步长为8，记为FCN-8s。 这一阶段使用单GPU训练约需1天。</p><p>较浅层的预测结果包含了更多细节信息。比较2,3,4阶段可以看出，<strong>跳级结构利用浅层信息辅助逐步升采样</strong>，有更精细的结果。 </p><p><img src="https://img-blog.csdnimg.cn/20210223120336300.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>FCN原理参考连接：</p><ul><li><a href="https://blog.csdn.net/qinghuaci666/article/details/80863032" target="_blank" rel="noopener">https://blog.csdn.net/qinghuaci666/article/details/80863032</a></li><li><a href="https://openaccess.thecvf.com/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf" target="_blank" rel="noopener">https://openaccess.thecvf.com/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf</a></li></ul><h3 id="3-3-SegNet"><a href="#3-3-SegNet" class="headerlink" title="3.3 SegNet"></a>3.3 SegNet</h3><p>Segnet是用于进行像素级别图像分割的全卷积网络，分割的核心组件是一个encoder  网络，及其相对应的decoder网络，后接一个象素级别的分类网络。</p><p>encoder网络：其结构与VGG16网络的前13层卷积层的结构相似。decoder网络：作用是将由encoder的到的低分辨率的feature maps  进行映射得到与输入图像featuremap相同的分辨率进而进行像素级别的分类。</p><p>Segnet的亮点：decoder进行上采样的方式，直接利用与之对应的encoder阶段中进行max-pooling时的polling index 进行非线性上采样，这样做的好处是上采样阶段就不需要进行学习。 上采样后得到的feature maps  是非常稀疏的，因此，需要进一步选择合适的卷积核进行卷积得到dense featuremaps 。</p><p><img src="https://img-blog.csdnimg.cn/20210223120403533.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>SegNet的思路和FCN十分相似，只是Encoder，Decoder（Unsampling）使用的技术不一样。SegNet的编码器部分使用的是VGG16的前13层卷积网络，每个编码器层都对应一个解码器层，最终解码器的输出被送入soft-max分类器以独立的为每个像素产生类别概率。</p><p>左边是卷积提取特征，通过pooling增大感受野，同时图片变小，该过程称为Encoder，右边是反卷积（在这里反卷积与卷积没有区别）与unsampling，通过反卷积使得图像分类后特征得以重现，upsampling还原到原图想尺寸，该过程称为Decoder，最后通过Softmax，输出不同分类的最大值，得到最终分割图。</p><p><strong>Encoder编码器</strong></p><ul><li>在编码器处，执行卷积和最大池化。</li><li>VGG-16有13个卷积层。 （不用全连接的层）</li><li>在进行2×2最大池化时，存储相应的最大池化索引（位置）。</li></ul><p><strong>Decoder解码器</strong><br><img src="https://img-blog.csdnimg.cn/20210223120423533.png#pic_center" alt="在这里插入图片描述"></p><p>使用最大池化的索引进行上采样</p><ul><li>在解码器处，执行上采样和卷积。最后，每个像素送到softmax分类器。</li><li>在上采样期间，如上所示，调用相应编码器层处的最大池化索引以进行上采样。</li><li>最后，使用K类softmax分类器来预测每个像素的类别。</li></ul><h3 id="3-4-Unet"><a href="#3-4-Unet" class="headerlink" title="3.4 Unet"></a>3.4 Unet</h3><p>U-net对称语义分割模型，该网络模型主要由一个收缩路径和一个对称扩张路径组成，收缩路径用来获得上下文信息，对称扩张路径用来精确定位分割边界。U-net使用图像切块进行训练，所以训练数据量远远大于训练图像的数量，这使得网络在少量样本的情况下也能获得不变性和鲁棒性。<br><img src="https://img-blog.csdnimg.cn/2021022312045215.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><ul><li><p>Encoder：左半部分，由两个3x3的卷积层（RELU）+2x2的max pooling层（stride=2）反复组成，每经过一次下采样，通道数翻倍；</p></li><li><p>Decoder：右半部分，由一个2x2的上采样卷积层（RELU）+Concatenation（crop对应的Encoder层的输出feature map然后与Decoder层的上采样结果相加）+2个3x3的卷积层（RELU）反复构成；</p></li><li><p>最后一层通过一个1x1卷积将通道数变成期望的类别数。</p></li></ul><h3 id="3-5-DeepLab"><a href="#3-5-DeepLab" class="headerlink" title="3.5 DeepLab"></a>3.5 DeepLab</h3><p>基于全卷积对称语义分割模型得到的分割结果比较粗糙，忽略了像素与像素之间的空间一致性关系。于是Google提出了一种新的扩张卷积语义分割模型，考虑了像素与像素之间的空间一致性关系，可以在不增加数量的情况下增加感受野。</p><ul><li>Deeplabv1是由深度卷积网路和概率图模型级联而成的语义分割模型，由于深度卷积网路在重复最大池化和下采样的过程中会丢失很多的细节信息，所以采用扩张卷积算法增加感受野以获得更多上下文信息。考虑到深度卷积网路在图像标记任务中的空间不敏感性限制了它的定位精度，采用了完全连接条件随机场（Conditional Random Field， CRF）来提高模型捕获细节的能力。</li><li>Deeplabv2予以分割模型增加了ASPP（Atrous spatial pyramid pooling）结构，利用多个不同采样率的扩张卷积提取特征，再将特征融合以捕获不同大小的上下文信息。</li><li>Deeplabv3语义分割模型，在ASPP中加入了全局平均池化，同时在平行扩张卷积后添加批量归一化，有效地捕获了全局语义信息。</li><li>DeepLabV3+语义分割模型在Deeplabv3的基础上增加了编-解码模块和Xception主干网路，增加编解码模块主要是为了恢复原始的像素信息，使得分割的细节信息能够更好的保留，同时编码丰富的上下文信息。增加Xception主干网络是为了采用深度卷积进一步提高算法的精度和速度。在inception结构中，先对输入进行1<em>1卷积，之后将通道分组，分别使用不同的3</em>3卷积提取特征，最后将各组结果串联在一起作为输出。</li></ul><p><img src="https://img-blog.csdnimg.cn/20210223120513639.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>主要特点：</p><ul><li>在多尺度上为分割对象进行带洞空间金字塔池化（ASPP）</li><li>通过使用DCNNs（空洞卷积）提升了目标边界的定位</li><li>降低了由DCNN的不变性导致的定位准确率</li></ul><h3 id="3-6-RefineNet"><a href="#3-6-RefineNet" class="headerlink" title="3.6 RefineNet"></a>3.6 RefineNet</h3><p>RefineNet采用了通过细化中间激活映射并分层地将其链接到结合多尺度激活，同时防止锐度损失。网络由独立的RefineNet模块组成，每个模块对应于ResNet。</p><p>每个RefineNet模块由三个主要模块组成，即剩余卷积单元（RCU），多分辨率融合（MRF）和链剩余池（CRP）。RCU块由一个自适应块组成卷积集，微调预训练的ResNet权重对于分割问题。MRF层融合不同的激活物使用卷积上采样层来创建更高的分辨率地图。最后，在CRP层池中使用多种大小的内核用于从较大的图像区域捕获背景上下文。</p><p><img src="https://img-blog.csdnimg.cn/20210223120530360.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>主要特点：</p><ul><li>提出一种多路径refinement网络，称为RefineNet。这种网络可以使用各个层级的features，使得语义分割更为精准。</li><li>RefineNet中所有部分都利用resdiual connections (identity mappings)，使得梯度更容易短向或者长向前传，使端对端的训练变得更加容易和高效。 </li><li>提出了一种叫做chained residual pooling的模块，它可以从一个大的图像区域捕捉背景上下文信息。</li></ul><h3 id="3-7-PSPNet"><a href="#3-7-PSPNet" class="headerlink" title="3.7 PSPNet"></a>3.7 PSPNet</h3><p>深度卷积神经网络的每一层特征对语义分割都有影响，如何将高层特征的语义信息与底层识别的边界与轮廓信息结合起来是一个具有挑战性的问题。</p><p>金字塔场景稀疏网络语义分割模型（Pyramid Scene Parsing Network，PSP）首先结合预训练网络 ResNet和扩张网络来提取图像的特征，得到原图像 1/8 大小的特征图，然后，采用金字塔池化模块将特征图同时通过四个并行的池化层得到四个不同大小的输出，将四个不同大小的输出分别进行上采样，还原到原特征图大小，最后与之前的特征图进行连接后经过卷积层得到最后的预测分割图像。</p><ul><li>PSPNet为像素级场景解析提供了有效的全局上下文先验</li><li>金字塔池化模块可以收集具有层级的信息，比全局池化更有代表性</li><li>在计算量方面，我们的PSPNet并没有比原来的空洞卷积FCN网络有很大的增加</li><li>在端到端学习中，全局金字塔池化模块和局部FCN特征可以被同时训练</li></ul><p><img src="https://img-blog.csdnimg.cn/20210223120546554.png#pic_center" alt="在这里插入图片描述"></p><p>主要特点：</p><ul><li>金字塔场景解析网络是建立在FCN之上的基于像素级分类网络。将大小不同的内核集中在一起激活地图的不同区域创建空间池金字塔。</li><li>特性映射来自网络被转换成不同分辨率的激活，并经过多尺度处理池层，稍后向上采样并与原始层连接进行分割的feature map。</li><li>学习的过程利用辅助分类器进一步优化了像ResNet这样的深度网络。不同类型的池模块侧重于激活的不同区域地图。</li></ul><h3 id="3-8-基于全卷积的GAN语义分割模型"><a href="#3-8-基于全卷积的GAN语义分割模型" class="headerlink" title="3.8 基于全卷积的GAN语义分割模型"></a>3.8 基于全卷积的GAN语义分割模型</h3><p>生成对抗网络模型（Generative Adversarial Nets，GAN）同时训练生成器 G 和判别器 D，判别器用来预测给定样本是来自于真实数据还是来自于生成模型。</p><p>利用对抗训练方法训练语义分割模型，将传统的多类交叉熵损失与对抗网络相结合，首先对对抗网络进行预训练，然后使用对抗性损失来微调分割网络，如下图所示。左边的分割网络将 RGB 图像作为输入，并产生每个像素的类别预测。右边的对抗网络将标签图作为输入并生成类标签（1 代表真实标注，0 代表合成标签）。</p><p><img src="https://img-blog.csdnimg.cn/20210223120606384.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>参考链接：<a href="https://cloud.tencent.com/developer/article/1589733" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1589733</a></p><h3 id="3-9-具体调用"><a href="#3-9-具体调用" class="headerlink" title="3.9 具体调用"></a>3.9 具体调用</h3><p>对于常见的语义分割模型，推荐可以直接使用segmentation_models_pytorch库完成：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> segmentation_models_pytorch <span class="hljs-keyword">as</span> smp<br><br>model = smp.Unet(<br>    encoder_name=<span class="hljs-string">"resnet34"</span>,        <span class="hljs-comment"># choose encoder, e.g. mobilenet_v2 or efficientnet-b7</span><br>    encoder_weights=<span class="hljs-string">"imagenet"</span>,     <span class="hljs-comment"># use `imagenet` pre-trained weights for encoder initialization</span><br>    in_channels=<span class="hljs-number">1</span>,                  <span class="hljs-comment"># model input channels (1 for gray-scale images, 3 for RGB, etc.)</span><br>    classes=<span class="hljs-number">3</span>,                      <span class="hljs-comment"># model output channels (number of classes in your dataset)</span><br>)<br></code></pre></td></tr></table></figure><h3 id="3-9-本章小结"><a href="#3-9-本章小结" class="headerlink" title="3.9 本章小结"></a>3.9 本章小结</h3><p>本章对常见的语义分割网络模型进行介绍，并使用segmentation_models_pytorch完成具体调用。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;datawhale语义分割-Task3-语义分割模型发展&quot;&gt;&lt;a href=&quot;#datawhale语义分割-Task3-语义分割模型发展&quot; class=&quot;headerlink&quot; title=&quot;datawhale语义分割-Task3 语义分割模型发展&quot;&gt;&lt;/a&gt;datawhale语义分割-Task3 语义分割模型发展&lt;/h1&gt;&lt;p&gt;本章主要讲解的是语义分割网络模型的发展：FCN 、SegNet、Unet、DeepLab、RefineNet、PSPNet、GAN语义分割。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="datawhale" scheme="https://yoursite.com/tags/datawhale/"/>
    
      <category term="计算机视觉" scheme="https://yoursite.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>datawhale-语义分割task2数据扩增</title>
    <link href="https://yoursite.com/2021/02/22/datawhale-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2task2%E6%95%B0%E6%8D%AE%E6%89%A9%E5%A2%9E/"/>
    <id>https://yoursite.com/2021/02/22/datawhale-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2task2%E6%95%B0%E6%8D%AE%E6%89%A9%E5%A2%9E/</id>
    <published>2021-02-22T11:04:00.000Z</published>
    <updated>2021-02-22T11:10:39.045Z</updated>
    
    <content type="html"><![CDATA[<h1 id="语义分割-Task2-数据扩增"><a href="#语义分割-Task2-数据扩增" class="headerlink" title="语义分割-Task2 数据扩增"></a>语义分割-Task2 数据扩增</h1><p>本章对语义分割任务中常见的数据扩增方法进行介绍，并使用OpenCV和albumentations两个库完成具体的数据扩增操作。<br>干货链接：<br><a href="https://zhuanlan.zhihu.com/p/107399127/" target="_blank" rel="noopener">albumentations 数据增强工具的使用</a><br><a href="https://blog.csdn.net/weixin_38533896/article/details/86028509" target="_blank" rel="noopener">Pytorch：transforms的二十二个方法</a><br><a href="https://blog.csdn.net/zhangyuexiang123/article/details/107705311" target="_blank" rel="noopener">Pytorch使用albumentations实现数据增强</a></p><a id="more"></a><h2 id="2-数据扩增方法"><a href="#2-数据扩增方法" class="headerlink" title="2 数据扩增方法"></a>2 数据扩增方法</h2><p><strong>简单来说数据扩充主要分成两类，一类是基于图像处理的数据扩增，一类是基于深度学习方法的数据扩充</strong>  这里简单介绍一下<br><strong>基于图像处理的数据扩增—几何变换</strong><br>旋转，缩放，翻转，裁剪，平移，仿射变换<br>作用:几何变换可以有效地对抗数据中存在的位置偏差、视角偏差、尺寸偏差，而且易于实现，非常常用。</p><p><strong>基于图像处理的数据扩增—灰度和彩色空间变换</strong><br>·亮度调整，对比度饱和度调整，颜色空间转换，色彩调整，gamma变换<br>作用：对抗数据中存在的光照，色彩，亮度，对比度偏差</p><p><strong>基于图像处理的数据扩增——添加噪声和滤波</strong><br>添加高斯噪声，椒盐噪声<br>滤波：模糊，锐化，雾化等<br>作用：应对噪声干扰，恶劣环境，成像异常等特殊情况，帮助CNN学习更泛化的特征<br><img src="https://img-blog.csdnimg.cn/20210222185335244.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><img src="https://img-blog.csdnimg.cn/20210222185326950.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><img src="https://img-blog.csdnimg.cn/20210222184733887.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>本章主要内容为数据扩增方法、OpenCV数据扩增、albumentations数据扩增和Pytorch读取赛题数据四个部分组成。</p><h3 id="2-1-学习目标"><a href="#2-1-学习目标" class="headerlink" title="2.1 学习目标"></a>2.1 学习目标</h3><ul><li>理解基础的数据扩增方法</li><li>学习OpenCV和albumentations完成数据扩增</li><li>Pytorch完成赛题读取</li></ul><h3 id="2-2-常见的数据扩增方法"><a href="#2-2-常见的数据扩增方法" class="headerlink" title="2.2 常见的数据扩增方法"></a>2.2 常见的数据扩增方法</h3><p><img src="https://img-blog.csdnimg.cn/20210222184303792.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="v"></p><p><img src="https://img-blog.csdnimg.cn/202102221844428.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>数据扩增是一种有效的正则化方法，可以防止模型过拟合，在深度学习模型的训练过程中应用广泛。数据扩增的目的是增加数据集中样本的数据量，同时也可以有效增加样本的语义空间。</p><p>需注意：</p><ol><li><p>不同的数据，拥有不同的数据扩增方法；</p></li><li><p>数据扩增方法需要考虑合理性，不要随意使用；</p></li><li><p>数据扩增方法需要与具体任何相结合，同时要考虑到标签的变化；</p></li></ol><p>对于图像分类，数据扩增方法可以分为两类：</p><ol><li>标签不变的数据扩增方法：数据变换之后图像类别不变；</li><li>标签变化的数据扩增方法：数据变换之后图像类别变化；</li></ol><p>而对于语义分割而言，常规的数据扩增方法都会改变图像的标签。如水平翻转、垂直翻转、旋转90%、旋转和随机裁剪，这些常见的数据扩增方法都会改变图像的标签，即会导致地标建筑物的像素发生改变。</p><p><img src="https://img-blog.csdnimg.cn/20210222183636488.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><h3 id="2-3-OpenCV数据扩增"><a href="#2-3-OpenCV数据扩增" class="headerlink" title="2.3 OpenCV数据扩增"></a>2.3 OpenCV数据扩增</h3><p>OpenCV是计算机视觉必备的库，可以很方便的完成数据读取、图像变化、边缘检测和模式识别等任务。为了加深各位对数据可做的影响，这里首先介绍OpenCV完成数据扩增的操作。<br><img src="https://img-blog.csdnimg.cn/20210222183659950.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 首先读取原始图片</span><br>img = cv2.imread(train_mask[<span class="hljs-string">'name'</span>].iloc[<span class="hljs-number">0</span>])<br>mask = rle_decode(train_mask[<span class="hljs-string">'mask'</span>].iloc[<span class="hljs-number">0</span>])<br><br>plt.figure(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">8</span>))<br>plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br>plt.imshow(img)<br><br>plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>plt.imshow(mask)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 垂直翻转</span><br>plt.figure(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">8</span>))<br>plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br>plt.imshow(cv2.flip(img, <span class="hljs-number">0</span>))<br><br>plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>plt.imshow(cv2.flip(mask, <span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 水平翻转</span><br>plt.figure(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">8</span>))<br>plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br>plt.imshow(cv2.flip(img, <span class="hljs-number">0</span>))<br><br>plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>plt.imshow(cv2.flip(mask, <span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 随机裁剪</span><br>x, y = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">256</span>), np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">256</span>)<br><br>plt.figure(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">8</span>))<br>plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br>plt.imshow(img[x:x+<span class="hljs-number">256</span>, y:y+<span class="hljs-number">256</span>])<br><br>plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>plt.imshow(mask[x:x+<span class="hljs-number">256</span>, y:y+<span class="hljs-number">256</span>])<br></code></pre></td></tr></table></figure><h3 id="2-4-albumentations数据扩增"><a href="#2-4-albumentations数据扩增" class="headerlink" title="2.4 albumentations数据扩增"></a>2.4 albumentations数据扩增</h3><p>albumentations是基于OpenCV的快速训练数据增强库，拥有非常简单且强大的可以用于多种任务（分割、检测）的接口，易于定制且添加其他框架非常方便。</p><p>albumentations也是计算机视觉数据竞赛中最常用的库：</p><ul><li>GitHub： <a href="https://link.zhihu.com/?target=https://github.com/albumentations-team/albumentations">https://github.com/albumentations-team/albumentations</a></li><li>示例：<a href="https://link.zhihu.com/?target=https://github.com/albumentations-team/albumentations_examples">https://github.com/albumentations-team/albumentations_examples</a></li></ul><p>与OpenCV相比albumentations具有以下优点：</p><ul><li>albumentations支持的操作更多，使用更加方便；</li><li>albumentations可以与深度学习框架（Keras或Pytorch）配合使用；</li><li>albumentations支持各种任务（图像分流）的数据扩增操作</li></ul><p>albumentations它可以对数据集进行逐像素的转换，如模糊、下采样、高斯造点、高斯模糊、动态模糊、RGB转换、随机雾化等；也可以进行空间转换（同时也会对目标进行转换），如裁剪、翻转、随机裁剪等。</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> albumentations <span class="hljs-keyword">as</span> A<br><br><span class="hljs-comment"># 水平翻转</span><br>augments = A.HorizontalFlip(p=<span class="hljs-number">1</span>)(image=img, mask=mask)<br>img_aug, mask_aug = augments[<span class="hljs-string">'image'</span>], augments[<span class="hljs-string">'mask'</span>]<br><br><span class="hljs-comment"># 随机裁剪</span><br>augments = A.RandomCrop(p=<span class="hljs-number">1</span>, height=<span class="hljs-number">256</span>, width=<span class="hljs-number">256</span>)(image=img, mask=mask)<br>img_aug, mask_aug = augments[<span class="hljs-string">'image'</span>], augments[<span class="hljs-string">'mask'</span>]<br><br><span class="hljs-comment"># 旋转</span><br>augments = A.ShiftScaleRotate(p=<span class="hljs-number">1</span>)(image=img, mask=mask)<br>img_aug, mask_aug = augments[<span class="hljs-string">'image'</span>], augments[<span class="hljs-string">'mask'</span>]<br></code></pre></td></tr></table></figure><p>albumentations还可以组合多个数据扩增操作得到更加复杂的数据扩增操作：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">trfm = A.Compose([<br>    A.Resize(<span class="hljs-number">256</span>, <span class="hljs-number">256</span>),<br>    A.HorizontalFlip(p=<span class="hljs-number">0.5</span>),<br>    A.VerticalFlip(p=<span class="hljs-number">0.5</span>),<br>    A.RandomRotate90(),<br>])<br><br>augments = trfm(image=img, mask=mask)<br>img_aug, mask_aug = augments[<span class="hljs-string">'image'</span>], augments[<span class="hljs-string">'mask'</span>]<br>plt.figure(figsize=(<span class="hljs-number">16</span>, <span class="hljs-number">8</span>))<br>plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br>plt.imshow(augments[<span class="hljs-string">'image'</span>])<br><br>plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>plt.imshow(augments[<span class="hljs-string">'mask'</span>])aug<br></code></pre></td></tr></table></figure><p>这里是我之前打kaggle的时候用到albumentations的一组增强方法，可以参考参考</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_train_transforms</span><span class="hljs-params">()</span>:</span><br>    <span class="hljs-keyword">return</span> Compose([<br>            <span class="hljs-comment">#将给定图像随机裁剪为不同的大小和宽高比，然后缩放所裁剪得到的图像为制定的大小；（即先随机采集，然后对裁剪得到的图像缩放为同一大小）</span><br>            RandomResizedCrop(CFG[<span class="hljs-string">'img_size'</span>], CFG[<span class="hljs-string">'img_size'</span>]),<br>            <span class="hljs-comment"># 转置</span><br>            Transpose(p=<span class="hljs-number">0.5</span>),<br>            HorizontalFlip(p=<span class="hljs-number">0.5</span>), <span class="hljs-comment">#img翻转 </span><br>            VerticalFlip(p=<span class="hljs-number">0.5</span>),<span class="hljs-comment"># 依据概率p对PIL图片进行垂直翻转</span><br>            ShiftScaleRotate(p=<span class="hljs-number">0.5</span>),<span class="hljs-comment"># 随机放射变换（ShiftScaleRotate），该方法可以对图片进行平移（translate）、缩放（scale）和旋转（roatate）</span><br>            <span class="hljs-comment"># 随机改变图片的 HUE、饱和度和值</span><br>            HueSaturationValue(hue_shift_limit=<span class="hljs-number">0.2</span>, sat_shift_limit=<span class="hljs-number">0.2</span>, val_shift_limit=<span class="hljs-number">0.2</span>, p=<span class="hljs-number">0.5</span>),<br>            <span class="hljs-comment">#随机亮度对比度</span><br>            RandomBrightnessContrast(brightness_limit=(<span class="hljs-number">-0.1</span>,<span class="hljs-number">0.1</span>), contrast_limit=(<span class="hljs-number">-0.1</span>, <span class="hljs-number">0.1</span>), p=<span class="hljs-number">0.5</span>),<br>            <span class="hljs-comment">#将像素值除以255 = 2 ** 8 - 1，减去每个通道的平均值并除以每个通道的std</span><br>            Normalize(mean=[<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], std=[<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>], max_pixel_value=<span class="hljs-number">255.0</span>, p=<span class="hljs-number">1.0</span>),<br>            <span class="hljs-comment"># 在图像上生成矩形区域。</span><br>            CoarseDropout(p=<span class="hljs-number">0.5</span>),<br>            <span class="hljs-comment"># 在图像中生成正方形区域。</span><br>            Cutout(p=<span class="hljs-number">0.5</span>),<br>            ToTensorV2(p=<span class="hljs-number">1.0</span>),<br>        ], p=<span class="hljs-number">1.</span>)<br></code></pre></td></tr></table></figure><h3 id="2-7-课后作业-添加噪声"><a href="#2-7-课后作业-添加噪声" class="headerlink" title="2.7 课后作业-添加噪声"></a>2.7 课后作业-添加噪声</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> cv2<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sp_noise</span><span class="hljs-params">(image,prob)</span>:</span><br>    <span class="hljs-string">'''</span><br><span class="hljs-string">    添加椒盐噪声</span><br><span class="hljs-string">    prob:噪声比例 </span><br><span class="hljs-string">    '''</span><br>    output = np.zeros(image.shape,np.uint8)<br>    thres = <span class="hljs-number">1</span> - prob <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(image.shape[<span class="hljs-number">0</span>]):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(image.shape[<span class="hljs-number">1</span>]):<br>            rdn = random.random()<br>            <span class="hljs-keyword">if</span> rdn &lt; prob:<br>                output[i][j] = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">elif</span> rdn &gt; thres:<br>                output[i][j] = <span class="hljs-number">255</span><br>            <span class="hljs-keyword">else</span>:<br>                output[i][j] = image[i][j]<br>    <span class="hljs-keyword">return</span> output<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gasuss_noise</span><span class="hljs-params">(image, mean=<span class="hljs-number">0</span>, var=<span class="hljs-number">0.001</span>)</span>:</span><br>    <span class="hljs-string">''' </span><br><span class="hljs-string">        添加高斯噪声</span><br><span class="hljs-string">        mean : 均值 </span><br><span class="hljs-string">        var : 方差</span><br><span class="hljs-string">    '''</span><br>    image = np.array(image/<span class="hljs-number">255</span>, dtype=float)<br>    noise = np.random.normal(mean, var ** <span class="hljs-number">0.5</span>, image.shape)<br>    out = image + noise<br>    <span class="hljs-keyword">if</span> out.min() &lt; <span class="hljs-number">0</span>:<br>        low_clip = <span class="hljs-number">-1.</span><br>    <span class="hljs-keyword">else</span>:<br>        low_clip = <span class="hljs-number">0.</span><br>    out = np.clip(out, low_clip, <span class="hljs-number">1.0</span>)<br>    out = np.uint8(out*<span class="hljs-number">255</span>)<br>    <span class="hljs-comment">#cv.imshow("gasuss", out)</span><br>    <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">new_img = sp_noise(img,<span class="hljs-number">0.1</span>)<br>plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br>plt.imshow(new_img)<br>new_img = gasuss_noise(img)<br>plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br>plt.imshow(new_img)<br>plt.savefig(<span class="hljs-string">'1.png'</span>)<br></code></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210222184217813.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;语义分割-Task2-数据扩增&quot;&gt;&lt;a href=&quot;#语义分割-Task2-数据扩增&quot; class=&quot;headerlink&quot; title=&quot;语义分割-Task2 数据扩增&quot;&gt;&lt;/a&gt;语义分割-Task2 数据扩增&lt;/h1&gt;&lt;p&gt;本章对语义分割任务中常见的数据扩增方法进行介绍，并使用OpenCV和albumentations两个库完成具体的数据扩增操作。&lt;br&gt;干货链接：&lt;br&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107399127/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;albumentations 数据增强工具的使用&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_38533896/article/details/86028509&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Pytorch：transforms的二十二个方法&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://blog.csdn.net/zhangyuexiang123/article/details/107705311&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Pytorch使用albumentations实现数据增强&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="datawhale" scheme="https://yoursite.com/tags/datawhale/"/>
    
      <category term="计算机视觉" scheme="https://yoursite.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>datawhale阿里云天池语义分割比赛-Task1 赛题理解和baseline代码</title>
    <link href="https://yoursite.com/2021/02/20/datawhale%E9%98%BF%E9%87%8C%E4%BA%91%E5%A4%A9%E6%B1%A0%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%AF%94%E8%B5%9B-Task1-%E8%B5%9B%E9%A2%98%E7%90%86%E8%A7%A3%E5%92%8Cbaseline%E4%BB%A3%E7%A0%81/"/>
    <id>https://yoursite.com/2021/02/20/datawhale%E9%98%BF%E9%87%8C%E4%BA%91%E5%A4%A9%E6%B1%A0%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E6%AF%94%E8%B5%9B-Task1-%E8%B5%9B%E9%A2%98%E7%90%86%E8%A7%A3%E5%92%8Cbaseline%E4%BB%A3%E7%A0%81/</id>
    <published>2021-02-20T13:44:00.000Z</published>
    <updated>2021-02-20T13:48:48.703Z</updated>
    
    <content type="html"><![CDATA[<h1 id="datawhale阿里云天池语义分割比赛-Task1-赛题理解和baseline代码"><a href="#datawhale阿里云天池语义分割比赛-Task1-赛题理解和baseline代码" class="headerlink" title="datawhale阿里云天池语义分割比赛-Task1 赛题理解和baseline代码"></a>datawhale阿里云天池语义分割比赛-Task1 赛题理解和baseline代码</h1><p>这里给出比赛地址：<a href="https://tianchi.aliyun.com/competition/entrance/531872/introduction?spm=5176.12281949.1003.10.493e3eafj1Afqc" target="_blank" rel="noopener">比赛地址</a><br>本章将对语义分割赛题进行赛题背景讲解，对赛题数据读取进行说明，并给出解题思路。</p><h2 id="1-赛题理解"><a href="#1-赛题理解" class="headerlink" title="1 赛题理解"></a>1 赛题理解</h2><a id="more"></a><ul><li>赛题名称：零基础入门语义分割-地表建筑物识别</li><li>赛题目标：通过本次赛题可以引导大家熟练掌握语义分割任务的定义，具体的解题流程和相应的模型，并掌握语义分割任务的发展。</li><li>赛题任务：赛题以计算机视觉为背景，要求选手使用给定的航拍图像训练模型并完成地表建筑物识别任务。</li></ul><h3 id="1-1-学习目标"><a href="#1-1-学习目标" class="headerlink" title="1.1 学习目标"></a>1.1 学习目标</h3><ul><li>理解赛题背景和赛题数据</li><li>完成赛题报名和数据下载，理解赛题的解题思路</li></ul><h3 id="1-2-赛题数据"><a href="#1-2-赛题数据" class="headerlink" title="1.2 赛题数据"></a>1.2 赛题数据</h3><p>遥感技术已成为获取地表覆盖信息最为行之有效的手段，遥感技术已经成功应用于地表覆盖检测、植被面积检测和建筑物检测任务。本赛题使用航拍数据，需要参赛选手完成地表建筑物识别，将地表航拍图像素划分为有建筑物和无建筑物两类。</p><p>如下图，左边为原始航拍图，右边为对应的建筑物标注。</p><p><img src="https://img-blog.csdnimg.cn/20210220213543778.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p>赛题数据来源（Inria Aerial Image Labeling），并进行拆分处理。数据集报名后可见并可下载。赛题数据为航拍图，需要参赛选手识别图片中的地表建筑具体像素位置。</p><h3 id="1-3-数据标签"><a href="#1-3-数据标签" class="headerlink" title="1.3 数据标签"></a>1.3 数据标签</h3><p>赛题为语义分割任务，因此具体的标签为图像像素类别。在赛题数据中像素属于2类（无建筑物和有建筑物），因此标签为有建筑物的像素。赛题原始图片为jpg格式，标签为RLE编码的字符串。</p><p>RLE全称（run-length encoding），翻译为游程编码或行程长度编码，对连续的黑、白像素数以不同的码字进行编码。RLE是一种简单的非破坏性资料压缩法，经常用在在语义分割比赛中对标签进行编码。</p><p>RLE与图片之间的转换如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> cv2<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">rle_encode</span><span class="hljs-params">(im)</span>:</span><br>    <span class="hljs-string">'''</span><br><span class="hljs-string">    im: numpy array, 1 - mask, 0 - background</span><br><span class="hljs-string">    Returns run length as string formated</span><br><span class="hljs-string">    '''</span><br>    pixels = im.flatten(order = <span class="hljs-string">'F'</span>)<br>    pixels = np.concatenate([[<span class="hljs-number">0</span>], pixels, [<span class="hljs-number">0</span>]])<br>    runs = np.where(pixels[<span class="hljs-number">1</span>:] != pixels[:<span class="hljs-number">-1</span>])[<span class="hljs-number">0</span>] + <span class="hljs-number">1</span><br>    runs[<span class="hljs-number">1</span>::<span class="hljs-number">2</span>] -= runs[::<span class="hljs-number">2</span>]<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">' '</span>.join(str(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> runs)<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">rle_decode</span><span class="hljs-params">(mask_rle, shape=<span class="hljs-params">(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>)</span>)</span>:</span><br>    <span class="hljs-string">'''</span><br><span class="hljs-string">    mask_rle: run-length as string formated (start length)</span><br><span class="hljs-string">    shape: (height,width) of array to return </span><br><span class="hljs-string">    Returns numpy array, 1 - mask, 0 - background</span><br><span class="hljs-string"></span><br><span class="hljs-string">    '''</span><br>    s = mask_rle.split()<br>    starts, lengths = [np.asarray(x, dtype=int) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> (s[<span class="hljs-number">0</span>:][::<span class="hljs-number">2</span>], s[<span class="hljs-number">1</span>:][::<span class="hljs-number">2</span>])]<br>    starts -= <span class="hljs-number">1</span><br>    ends = starts + lengths<br>    img = np.zeros(shape[<span class="hljs-number">0</span>]*shape[<span class="hljs-number">1</span>], dtype=np.uint8)<br>    <span class="hljs-keyword">for</span> lo, hi <span class="hljs-keyword">in</span> zip(starts, ends):<br>        img[lo:hi] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> img.reshape(shape, order=<span class="hljs-string">'F'</span>)<br></code></pre></td></tr></table></figure><h3 id="rle-encode全过程分析"><a href="#rle-encode全过程分析" class="headerlink" title="rle_encode全过程分析"></a>rle_encode全过程分析</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">im = mask<br>pixels = im.flatten(order = <span class="hljs-string">'F'</span>)<br><br>print(pixels,len(pixels))<br>pixels = np.concatenate([[<span class="hljs-number">0</span>], pixels, [<span class="hljs-number">0</span>]])<br>print(pixels,len(pixels))<br>runs = np.where(pixels[<span class="hljs-number">1</span>:] != pixels[:<span class="hljs-number">-1</span>])[<span class="hljs-number">0</span>] + <span class="hljs-number">1</span><br>print(pixels[<span class="hljs-number">1</span>:].shape)<br>print(pixels[:<span class="hljs-number">-1</span>].shape)<br>print(runs,len(runs))<br><span class="hljs-comment">##这里其实就相当于是前后错位了一个数，</span><br><span class="hljs-comment">#然后就会找到左右不同的像素点即边界，从而将所有的感兴趣点都提取出来</span><br><span class="hljs-comment">#print(runs[::2]) #每一段的start位置</span><br><span class="hljs-comment">#print(runs[1::2]) #每一段的end位置</span><br>runs[<span class="hljs-number">1</span>::<span class="hljs-number">2</span>] -= runs[::<span class="hljs-number">2</span>] <span class="hljs-comment">#end-start即将end变成了length</span><br><span class="hljs-comment"># print(runs[1::2]) #得到每一段的长度</span><br><br>res = <span class="hljs-string">' '</span>.join(str(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> runs)<br><span class="hljs-comment"># [str(x) for x in runs]</span><br></code></pre></td></tr></table></figure><h3 id="1-4-评价指标"><a href="#1-4-评价指标" class="headerlink" title="1.4 评价指标"></a>1.4 评价指标</h3><h5 id="语义分割的相关loss介绍"><a href="#语义分割的相关loss介绍" class="headerlink" title="语义分割的相关loss介绍"></a>语义分割的相关loss介绍</h5><p><a href="https://zhuanlan.zhihu.com/p/101773544" target="_blank" rel="noopener">知乎链接</a><br>赛题使用Dice coefficient来衡量选手结果与真实标签的差异性，Dice coefficient可以按像素差异性来比较结果的差异性。Dice coefficient的具体计算方式如下：</p><p>$$<br>\frac{2 * |X \cap Y|}{|X| + |Y|}<br>$$</p><p>其中$X$是预测结果，$Y$为真实标签的结果。当$X$与$Y$完全相同时Dice coefficient为1，排行榜使用所有测试集图片的平均Dice coefficient来衡量，分数值越大越好。<br><img src="https://img-blog.csdnimg.cn/20210220213913495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="1-5-读取数据"><a href="#1-5-读取数据" class="headerlink" title="1.5 读取数据"></a>1.5 读取数据</h3><table><thead><tr><th align="left">FileName</th><th align="left">Size</th><th align="right">含义</th></tr></thead><tbody><tr><td align="left">test_a.zip</td><td align="left">314.49MB</td><td align="right">测试集A榜图片</td></tr><tr><td align="left">test_a_samplesubmit.csv</td><td align="left">46.39KB</td><td align="right">测试集A榜提交样例</td></tr><tr><td align="left">train.zip</td><td align="left">3.68GB</td><td align="right">训练集图片</td></tr><tr><td align="left">train_mask.csv.zip</td><td align="left">97.52MB</td><td align="right">训练集图片标注</td></tr></tbody></table><p>具体数据读取案例：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> cv2<br>train_mask = pd.read_csv(<span class="hljs-string">'train_mask.csv'</span>, sep=<span class="hljs-string">'\t'</span>, names=[<span class="hljs-string">'name'</span>, <span class="hljs-string">'mask'</span>])<br><br><span class="hljs-comment"># 读取第一张图，并将对于的rle解码为mask矩阵</span><br>img = cv2.imread(<span class="hljs-string">'train/'</span>+ train_mask[<span class="hljs-string">'name'</span>].iloc[<span class="hljs-number">0</span>])<br>mask = rle_decode(train_mask[<span class="hljs-string">'mask'</span>].iloc[<span class="hljs-number">0</span>])<br><br>print(rle_encode(mask) == train_mask[<span class="hljs-string">'mask'</span>].iloc[<span class="hljs-number">0</span>])<br><span class="hljs-comment"># 结果为True</span><br></code></pre></td></tr></table></figure><h3 id="1-6-解题思路"><a href="#1-6-解题思路" class="headerlink" title="1.6 解题思路"></a>1.6 解题思路</h3><p>由于本次赛题是一个典型的语义分割任务，因此可以直接使用语义分割的模型来完成：</p><ul><li>步骤1：使用FCN模型模型跑通具体模型训练过程，并对结果进行预测提交；</li><li>步骤2：在现有基础上加入数据扩增方法，并划分验证集以监督模型精度；</li><li>步骤3：使用更加强大模型结构（如Unet和PSPNet）或尺寸更大的输入完成训练；</li><li>步骤4：训练多个模型完成模型集成操作；</li></ul><h3 id="1-7-本章小结"><a href="#1-7-本章小结" class="headerlink" title="1.7 本章小结"></a>1.7 本章小结</h3><p>本章主要对赛题背景和主要任务进行讲解，并多对赛题数据和标注读取方式进行介绍，最后列举了赛题解题思路。</p><h3 id="1-8-课后作业"><a href="#1-8-课后作业" class="headerlink" title="1.8 课后作业"></a>1.8 课后作业</h3><ol><li>理解RLE编码过程，并完成赛题数据读取并可视化；</li><li>统计所有图片整图中没有任何建筑物像素占所有训练集图片的比例；</li><li>统计所有图片中建筑物像素占所有相似度的比例；</li><li>统计所有图片中建筑物区域平均区域大小；</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;datawhale阿里云天池语义分割比赛-Task1-赛题理解和baseline代码&quot;&gt;&lt;a href=&quot;#datawhale阿里云天池语义分割比赛-Task1-赛题理解和baseline代码&quot; class=&quot;headerlink&quot; title=&quot;datawhale阿里云天池语义分割比赛-Task1 赛题理解和baseline代码&quot;&gt;&lt;/a&gt;datawhale阿里云天池语义分割比赛-Task1 赛题理解和baseline代码&lt;/h1&gt;&lt;p&gt;这里给出比赛地址：&lt;a href=&quot;https://tianchi.aliyun.com/competition/entrance/531872/introduction?spm=5176.12281949.1003.10.493e3eafj1Afqc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;比赛地址&lt;/a&gt;&lt;br&gt;本章将对语义分割赛题进行赛题背景讲解，对赛题数据读取进行说明，并给出解题思路。&lt;/p&gt;
&lt;h2 id=&quot;1-赛题理解&quot;&gt;&lt;a href=&quot;#1-赛题理解&quot; class=&quot;headerlink&quot; title=&quot;1 赛题理解&quot;&gt;&lt;/a&gt;1 赛题理解&lt;/h2&gt;
    
    </summary>
    
    
    
      <category term="datawhale" scheme="https://yoursite.com/tags/datawhale/"/>
    
      <category term="计算机视觉" scheme="https://yoursite.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
  </entry>
  
  <entry>
    <title>datawhale-pandas缺失数据处理</title>
    <link href="https://yoursite.com/2021/01/20/datawhale-pandas%E7%BC%BA%E5%A4%B1%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    <id>https://yoursite.com/2021/01/20/datawhale-pandas%E7%BC%BA%E5%A4%B1%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</id>
    <published>2021-01-20T12:55:00.000Z</published>
    <updated>2021-02-20T13:45:36.799Z</updated>
    
    <content type="html"><![CDATA[<h1 id="缺失数据"><a href="#缺失数据" class="headerlink" title="缺失数据"></a>缺失数据</h1><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br></code></pre></td></tr></table></figure><h2 id="一、缺失值的统计和删除"><a href="#一、缺失值的统计和删除" class="headerlink" title="一、缺失值的统计和删除"></a>一、缺失值的统计和删除</h2><h2 id="1-缺失信息的统计"><a href="#1-缺失信息的统计" class="headerlink" title="1. 缺失信息的统计"></a>1. 缺失信息的统计</h2><p>缺失数据可以使用 <code>isna</code> 或 <code>isnull</code> （两个函数没有区别）来查看每个单元格是否缺失，结合 <code>mean</code> 可以计算出每列缺失值的比例：</p><a id="more"></a><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df =pd.read_csv(<span class="hljs-string">'data/learn_pandas.csv'</span>,<br>               usecols=[<span class="hljs-string">'Grade'</span>,<span class="hljs-string">'Name'</span>,<span class="hljs-string">'Gender'</span>,<span class="hljs-string">'Height'</span>,<span class="hljs-string">'Weight'</span>,<span class="hljs-string">'Transfer'</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df.isna().head()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df.isna().mean()<span class="hljs-comment">#查看缺失的比例</span><br></code></pre></td></tr></table></figure><p>如果想要查看某一列缺失或者非缺失的行，可以利用<code>Serires</code>上的<code>isna</code>或者<code>notna</code>进行布尔索引，例如，查看身高缺失的行：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df[df.Height.isna()].head()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">sub_set=df[[<span class="hljs-string">'Height'</span>,<span class="hljs-string">'Weight'</span>,<span class="hljs-string">'Transfer'</span>]]<br>df[sub_set.isna().all(axis=<span class="hljs-number">1</span>)]<span class="hljs-comment"># 全部缺失</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df[sub_set.isna().any(<span class="hljs-number">1</span>)].head()<br></code></pre></td></tr></table></figure><h2 id="缺失信息的删除"><a href="#缺失信息的删除" class="headerlink" title="缺失信息的删除"></a>缺失信息的删除</h2><p>数据处理中经常需要根据缺失值的大小、比例或其他特征来进行行样本或列特征的删除，<code>pandas</code>中提供了<code>dropna</code>函数来进行操作。</p><p><code>dropna</code>的主要参数为轴方向<code>axis</code>（默认为0，即删除行），删除方式<code>how</code>，删除的非缺失值格式阈值<code>thresh</code>（非缺失值没有到达这个数量的相应维度会被删除），备选的删除子集<code>subset</code>，其中<code>how</code>主要有<code>any</code>和<code>all</code>两种参数可以选择</p><p>例如，删除身高体重至少有一个缺失的行</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res=df.dropna(how=<span class="hljs-string">'any'</span>,subset=[<span class="hljs-string">'Height'</span>,<span class="hljs-string">'Weight'</span>])<br>res.shape<br></code></pre></td></tr></table></figure><p>例如删除超过15个缺失值的列</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res=df.dropna(axis=<span class="hljs-number">1</span>,thresh=df.shape[<span class="hljs-number">0</span>]<span class="hljs-number">-15</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res.head()<br></code></pre></td></tr></table></figure><p>当然，不用 <code>dropna</code> 同样是可行的，例如上述的两个操作，也可以使用布尔索引来完成：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res=df.loc[df[[<span class="hljs-string">'Height'</span>,<span class="hljs-string">'Weight'</span>]].notna().all(<span class="hljs-number">1</span>)]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res.shape<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res=df.loc[:,~(df.isna().sum()&gt;<span class="hljs-number">15</span>)]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res.head()<br></code></pre></td></tr></table></figure><h2 id="二、缺失值的填充和插值"><a href="#二、缺失值的填充和插值" class="headerlink" title="二、缺失值的填充和插值"></a>二、缺失值的填充和插值</h2><h2 id="1-利用fillna进行填充"><a href="#1-利用fillna进行填充" class="headerlink" title="1. 利用fillna进行填充"></a>1. 利用fillna进行填充</h2><p>在<code>fillna</code>中有三个参数是常用的：<code>value,method,limit</code>其中<code>value</code>为填充值，可以是标量，也可以是索引到元素的字典映射，<code>method</code>为填充方法，有用前面的元素填充<code>ffill</code>和用后面的元素填充<code>bfill</code>两种类型，<code>limit</code>参数表示连续缺失值的最大填充次数</p><p>下面构造一个简单的<code>Series</code>来说明用法</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s=pd.Series([np.nan,<span class="hljs-number">1</span>,np.nan,np.nan,<span class="hljs-number">2</span>,np.nan],<br>           list(<span class="hljs-string">'aaabcd'</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.fillna(method=<span class="hljs-string">'ffill'</span>) <span class="hljs-comment"># 用前面的值填充</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.fillna(method=<span class="hljs-string">'bfill'</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.fillna(method=<span class="hljs-string">'ffill'</span>, limit=<span class="hljs-number">1</span>) <span class="hljs-comment"># 连续出现的缺失，最多填充一次</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.fillna(s.mean())<span class="hljs-comment"># 均值填充</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.fillna(&#123;<span class="hljs-string">'a'</span>:<span class="hljs-number">100</span>,<span class="hljs-string">'d'</span>:<span class="hljs-number">200</span>&#125;)<span class="hljs-comment"># 通过索引映射填充的值</span><br></code></pre></td></tr></table></figure><p>有时为了更加合理地填充，需要先进行分组后再操作。例如，根据年级进行身高的均值填充：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df.groupby(<span class="hljs-string">'Grade'</span>)[<span class="hljs-string">'Height'</span>].transform(<br>                        <span class="hljs-keyword">lambda</span> x:x.fillna(x.mean())).head()<br></code></pre></td></tr></table></figure><h2 id="练一练"><a href="#练一练" class="headerlink" title="练一练"></a>练一练</h2><p>对一个序列以如下规则填充缺失值：如果单独出现的缺失值，就用前后均值填充，如果连续出现的缺失值就不填充，即序列[1, NaN, 3, NaN, NaN]填充后为[1, 2, 3, NaN, NaN]，请利用 fillna 函数实现。（提示：利用 limit 参数）</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s = pd.Series([<span class="hljs-number">1</span>,np.nan,<span class="hljs-number">3</span>, np.nan, np.nan])<br>s1 = s.fillna(method=<span class="hljs-string">'ffill'</span>,limit=<span class="hljs-number">1</span>)<br>s2 = s.fillna(method=<span class="hljs-string">'bfill'</span>,limit=<span class="hljs-number">1</span>)<br>s = pd.Series(list(map(<span class="hljs-keyword">lambda</span> x,y: (x+y)/<span class="hljs-number">2</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> np.isnan(x) <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> np.isnan(y) <span class="hljs-keyword">else</span> np.nan, s1,s2)))<br>s<br></code></pre></td></tr></table></figure><h2 id="2-插值函数"><a href="#2-插值函数" class="headerlink" title="2.插值函数"></a>2.插值函数</h2><p>在关于 <code>interpolate</code> 函数的 文档 描述中，列举了许多插值法，包括了大量 <code>Scipy</code> 中的方法。由于很多插值方法涉及到比较复杂的数学知识，因此这里只讨论比较常用且简单的三类情况，即线性插值、最近邻插值和索引插值。</p><p>对于 <code>interpolate</code> 而言，除了插值方法（默认为 <code>linear</code> 线性插值）之外，有与 <code>fillna</code> 类似的两个常用参数，一个是控制方向的 <code>limit_direction</code> ，另一个是控制最大连续缺失值插值个数的 <code>limit</code> 。其中，限制插值的方向默认为 <code>forward</code> ，这与 <code>fillna</code> 的 <code>method </code>中的 <code>ffill</code> 是类似的，若想要后向限制插值或者双向限制插值可以指定为 <code>backward</code> 或 <code>both</code> 。</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s = pd.Series([np.nan, np.nan, <span class="hljs-number">1</span>,<br>  ....:                np.nan, np.nan, np.nan,<br>  ....:                <span class="hljs-number">2</span>, np.nan, np.nan])<br>  ....:<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.values<br></code></pre></td></tr></table></figure><p>例如，在默认线性插值法下分别进行 <code>backward</code> 和双向限制插值，同时限制最大连续条数为1：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res=s.interpolate(limit_direction=<span class="hljs-string">'backward'</span>,limit=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res.values<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res=s.interpolate(limit_direction=<span class="hljs-string">'both'</span>,limit=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res.values<br></code></pre></td></tr></table></figure><p>第二种常见的插值是最近邻插补，即缺失值的元素和离它最近的非缺失值元素一样：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.interpolate(<span class="hljs-string">'nearest'</span>).values<br></code></pre></td></tr></table></figure><p>最后来介绍索引插值，即根据索引大小进行线性插值。例如，构造不等间距的索引进行演示：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s=pd.Series([<span class="hljs-number">0</span>,np.nan,<span class="hljs-number">10</span>],index=[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">10</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.interpolate()<span class="hljs-comment">#默认的线性插值，等价于计算中点的值</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.interpolate(method=<span class="hljs-string">'index'</span>)<span class="hljs-comment">#和索引有关的线性插值，计算相应的索引对应的值</span><br></code></pre></td></tr></table></figure><p>同时，这种方法对于时间戳索引也是可以使用的，有关时间序列的其他话题会在第十章进行讨论，这里举一个简单的例子：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s=pd.Series([<span class="hljs-number">0</span>,np.nan,<span class="hljs-number">10</span>],<br>           index=pd.to_datetime([<span class="hljs-string">'20200101'</span>,<br>                                <span class="hljs-string">'20200102'</span>,<br>                                <span class="hljs-string">'20200111'</span>]))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.interpolate()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.interpolate(method=<span class="hljs-string">'index'</span>)<br></code></pre></td></tr></table></figure><h2 id="关于polynomial和spline插值的注意事项"><a href="#关于polynomial和spline插值的注意事项" class="headerlink" title="关于polynomial和spline插值的注意事项"></a>关于polynomial和spline插值的注意事项</h2><p>在 <code>interpolate</code> 中如果选用 <code>polynomial</code> 的插值方法，它内部调用的是 <code>scipy.interpolate.interp1d(*,*,kind=order)</code> ，这个函数内部调用的是 <code>make_interp_spline</code> 方法，因此其实是样条插值而不是类似于<code> numpy</code> 中的 <code>polyfit</code> 多项式拟合插值；而当选用 <code>spline</code> 方法时， <code>pandas </code>调用的是 <code>scipy.interpolate.UnivariateSpline</code> 而不是普通的样条插值。这一部分的文档描述比较混乱，而且这种参数的设计也是不合理的，当使用这两类插值方法时，用户一定要小心谨慎地根据自己的实际需求选取恰当的插值方法。</p><h2 id="Nullable类型"><a href="#Nullable类型" class="headerlink" title="Nullable类型"></a>Nullable类型</h2><h2 id="1-缺失记号及其缺陷"><a href="#1-缺失记号及其缺陷" class="headerlink" title="1. 缺失记号及其缺陷"></a>1. 缺失记号及其缺陷</h2><p>在 <code>python</code> 中的缺失值用 <code>None</code> 表示，该元素除了等于自己本身之外，与其他任何元素不相等：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-literal">None</span>==<span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure><pre><code>True</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-literal">None</span>==<span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><pre><code>False</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-literal">None</span>==[]<br></code></pre></td></tr></table></figure><pre><code>False</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-literal">None</span>==<span class="hljs-string">''</span><br></code></pre></td></tr></table></figure><pre><code>False</code></pre><p>在<code> numpy</code> 中利用 <code>np.nan</code> 来表示缺失值，该元素除了不和其他任何元素相等之外，和自身的比较结果也返回<code> False</code> ：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.nan==np.nan<br></code></pre></td></tr></table></figure><pre><code>False</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.nan==<span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure><pre><code>False</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.nan==<span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><pre><code>False</code></pre><p>值得注意的是，虽然在对缺失序列或表格的元素进行比较操作的时候， <code>np.nan</code> 的对应位置会返回 <code>False</code><br><strong>但是在使用 <code>equals</code> 函数进行两张表或两个序列的相同性检验时，会自动跳过两侧表都是缺失值的位置，直接返回 <code>True</code> :</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s1=pd.Series([<span class="hljs-number">1</span>,np.nan])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s2=pd.Series([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s3=pd.Series([<span class="hljs-number">1</span>,np.nan])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s1==<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><pre><code>0     True1    Falsedtype: bool</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s1.equals(s2)<br></code></pre></td></tr></table></figure><pre><code>False</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s1.equals(s3)<br></code></pre></td></tr></table></figure><pre><code>True</code></pre><p>在<strong>时间序列的对象</strong>中， <code>pandas</code> 利用 <code>pd.NaT</code> 来指代缺失值，它的作用和 <code>np.nan</code> 是一致的（时间序列的对象和构造将在第十章讨论）：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.to_timedelta([<span class="hljs-string">'30s'</span>,np.nan])<span class="hljs-comment">#Timedelta 中的NaT</span><br></code></pre></td></tr></table></figure><pre><code>TimedeltaIndex([&#39;0 days 00:00:30&#39;, NaT], dtype=&#39;timedelta64[ns]&#39;, freq=None)</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.to_datetime([<span class="hljs-string">'20200101'</span>,np.nan])<span class="hljs-comment">#Datetime中的NaT</span><br></code></pre></td></tr></table></figure><pre><code>DatetimeIndex([&#39;2020-01-01&#39;, &#39;NaT&#39;], dtype=&#39;datetime64[ns]&#39;, freq=None)</code></pre><p>那么为什么要引入 <code>pd.NaT</code> 来表示时间对象中的缺失呢？仍然以 <code>np.nan</code> 的形式存放会有什么问题？在 <code>pandas</code> 中可以看到 <code>object</code> 类型的对象，而 <code>object</code> 是一种混杂对象类型，如果出现了多个类型的元素同时存储在 <code>Series</code> 中，它的类型就会变成 <code>object</code> 。例如，同时存放整数和字符串的列表：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.Series([<span class="hljs-number">1</span>,<span class="hljs-string">'two'</span>])<br></code></pre></td></tr></table></figure><pre><code>0      11    twodtype: object</code></pre><p><strong><code>NaT</code> 问题的根源来自于 <code>np.nan</code> 的本身是一种浮点类型</strong>，而如果浮点和时间类型混合存储，如果不设计新的内置缺失类型来处理，就会变成含糊不清的 <code>object </code>类型，这显然是不希望看到的</p><p><strong>同时，由于 np.nan 的浮点性质，如果在一个整数的 Series 中出现缺失，那么其类型会转变为 float64 ；</strong>  </p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.Series([<span class="hljs-number">1</span>,np.nan]).dtype<br></code></pre></td></tr></table></figure><pre><code>dtype(&#39;float64&#39;)</code></pre><p><strong>而如果在一个布尔类型的序列中出现缺失，那么其类型就会转为 object 而不是 bool ：</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.Series([<span class="hljs-literal">True</span>,<span class="hljs-literal">False</span>,np.nan]).dtype<br></code></pre></td></tr></table></figure><pre><code>dtype(&#39;O&#39;)</code></pre><p>因此，在进入 <code>1.0.0 </code>版本后， <code>pandas</code> 尝试设计了一种新的缺失类型 <code>pd.NA</code> 以及三种 <code>Nullable</code> 序列类型来应对这些缺陷，它们分别是 <code>Int, boolean</code> 和 <code>string</code> 。</p><h2 id="2-Nullable类型的性质"><a href="#2-Nullable类型的性质" class="headerlink" title="2. Nullable类型的性质"></a>2. Nullable类型的性质</h2><p>从字面意义上看 <code>Nullable</code> 就是可空的，言下之意就是序列类型不受缺失值的影响。例如，在上述三个 <code>Nullable</code> 类型中存储缺失值，都会转为 <code>pandas</code> 内置的 <code>pd.NA</code> ：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.Series([np.nan,<span class="hljs-number">1</span>],dtype=<span class="hljs-string">'Int64'</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.Series([np.nan,<span class="hljs-literal">True</span>],dtype=<span class="hljs-string">'boolean'</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.Series([np.nan,<span class="hljs-string">'my_str'</span>],dtype=<span class="hljs-string">'string'</span>)<br></code></pre></td></tr></table></figure><p>在 <code>Int</code> 的序列中，返回的结果会尽可能地成为 <code>Nullable</code> 的类型：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.Series([np.nan,<span class="hljs-number">0</span>],dtype=<span class="hljs-string">'Int64'</span>)+<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.Series([np.nan,<span class="hljs-number">0</span>],dtype=<span class="hljs-string">'Int64'</span>)==<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.Series([np.nan,<span class="hljs-number">0</span>],dtype=<span class="hljs-string">'Int64'</span>)*<span class="hljs-number">0.5</span><br></code></pre></td></tr></table></figure><p>对于<code>boolean</code>类型的序列而言，其和 <code>bool</code> 序列的行为主要有两点区别：</p><p><strong>第一点是带有缺失的布尔列表无法进行索引器中的选择，而 <code>boolean</code> 会把缺失值看作 <code>False</code> ：</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s=pd.Series([<span class="hljs-string">'a'</span>,<span class="hljs-string">'b'</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s_bool=pd.Series([<span class="hljs-literal">True</span>,np.nan])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s_boolean=pd.Series([<span class="hljs-literal">True</span>,np.nan]).astype(<span class="hljs-string">'boolean'</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s[s_bool] <span class="hljs-comment">#报错</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s[s_boolean]<br></code></pre></td></tr></table></figure><p><strong>第二点是在进行逻辑运算时， bool 类型在缺失处返回的永远是 False ，而 boolean 会根据逻辑运算是否能确定唯一结果来返回相应的值。</strong><br>那什么叫能否确定唯一结果呢？<br>举个简单例子：   </p><ul><li>True | pd.NA 中无论缺失值为什么值，必然返回 True </li><li>False | pd.NA 中的结果会根据缺失值取值的不同而变化，此时返回 pd.NA  </li><li>False &amp; pd.NA 中无论缺失值为什么值，必然返回 False 。 </li></ul><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s_boolean &amp; <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s_boolean | <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">~s_boolean<span class="hljs-comment"># 取反操作同样是无法唯一地判断缺失结果</span><br></code></pre></td></tr></table></figure><p>关于 <code>string</code> 类型的具体性质将在下一章文本数据中进行讨论。<br>一般在实际数据处理时，可以在数据集读入后，先通过 <code>convert_dtypes</code> 转为 <code>Nullable</code> 类型：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df = pd.read_csv(<span class="hljs-string">'data/learn_pandas.csv'</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df=df.convert_dtypes()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df.dtypes<br></code></pre></td></tr></table></figure><h2 id="3-缺失数据的计算和分组"><a href="#3-缺失数据的计算和分组" class="headerlink" title="3. 缺失数据的计算和分组"></a>3. 缺失数据的计算和分组</h2><p>当调用函数<code>sum,prod</code>使用加法和乘法的时候，缺失数据等价于被分别视作0和1，即不改变原来的计算结果</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s=pd.Series([<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,np.nan,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.sum(),s.prod()<br></code></pre></td></tr></table></figure><p>当使用累计函数的时候，会自动跳过缺失值所处的位置</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.cumsum()<br></code></pre></td></tr></table></figure><p>当进行单个标量运算的时候，除了 <code>np.nan ** 0 </code>和 <code>1 ** np.nan</code> 这两种情况为确定的值之外，所有运算结果全为缺失（ <code>pd.NA</code> 的行为与此一致 ），并且 <code>np.nan</code> 在比较操作时一定返回 <code>False</code> ，而 <code>pd.NA</code> 返回 <code>pd.NA</code> </p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.nan==<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.NA==<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.nan&gt;<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.NA&gt;<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.nan+<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.log(np.nan)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.add(np.nan,<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.nan**<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.NA**<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-number">1</span>**np.nan<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-number">1</span>**pd.NA<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.diff()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">s.pct_change()<br></code></pre></td></tr></table></figure><p>对于一些函数而言，<strong>缺失可以作为一个类别处理</strong>，例如在 <code>groupby, get_dummies</code> 中可以设置相应的参数来进行增加缺失类别:</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df_nan=pd.DataFrame(&#123;<span class="hljs-string">'category'</span>:[<span class="hljs-string">'a'</span>,<span class="hljs-string">'a'</span>,<span class="hljs-string">'b'</span>,np.nan,np.nan],<br>                    <span class="hljs-string">'value'</span>:[<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">7</span>,<span class="hljs-number">9</span>]&#125;)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df_nan<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df_nan.groupby(<span class="hljs-string">'category'</span>,dropna=<span class="hljs-literal">False</span>)[<span class="hljs-string">'value'</span>].mean()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pd.get_dummies(df_nan.category,dummy_na=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h2 id="Ex1：缺失值与类别的相关性检验"><a href="#Ex1：缺失值与类别的相关性检验" class="headerlink" title="Ex1：缺失值与类别的相关性检验"></a>Ex1：缺失值与类别的相关性检验</h2><p><strong>在数据处理中，含有过多缺失值的列往往会被删除，除非缺失情况与标签强相关。</strong>下面有一份关于二分类问题的数据集，其中 X_1, X_2 为特征变量， y 为二分类标签</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df=pd.read_csv(<span class="hljs-string">'data/missing_chi.csv'</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df.head()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df.isna().mean()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df.y.value_counts(normalize=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>事实上，有时缺失值出现或者不出现本身就是一种特征，并且在一些场合下可能与标签的正负是相关的。<strong>关于缺失出现与否和标签的正负性</strong>，在统计学中可以利用<strong>卡方检验</strong>来断言它们是否存在相关性。  </p><p>按照<strong>特征缺失的正例、特征缺失的负例、特征不缺失的正例、特征不缺失的负例，可以分为四种情况</strong>，设它们分别对应的样例数为 <code>n11,n10,n01,n00</code> 。</p><p>假若它们是不相关的，那么特征缺失中正例的理论值，就应该接近于特征缺失总数 × 总体正例的比例，即：</p><p>$$ E_{11} = n_{11} \approx (n_{11}+n_{10}) \times \frac{n_{11}+n_{01}}{n_{11}+n_{10}+n_{01}+n_{00}} = F_{11}$$</p><p>其他的三种情况同理，现将实际值和理论值分别记作$E_{ij},F_{ij}$,那么希望下面的统计量越小越好，即代表实际值接近不相关情况的理论值：</p><p>$$S = \sum_{i \in { 0,1} } \sum_{ j \in {0,1}} \frac{(E_{ij} - F_{ij})^2}{F_{ij}} $$</p><p>可以证明上面的统计量近似服从自由度为 1 的卡方分布，即$S\overset{\cdot}{\sim} \chi^2(1) $因此，可通过计算 $P(\chi^2(1)&gt;S)$的概率来进行相关性的判别，一般认为当此概率小于 0.05 时缺失情况与标签正负存在相关关系，即不相关条件下的理论值与实际值相差较大。</p><p>上面所说的概率即为统计学上关于 $2\times 2 $列联表检验问题的 p 值， 它可以通过 <code>scipy.stats.chi2.sf(S, 1)</code> 得到。请根据上面的材料，分别对 X_1, X_2 列进行检验。</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df=pd.read_csv(<span class="hljs-string">'data/missing_chi.csv'</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">cat_1 = df.X_1.fillna(<span class="hljs-string">'NaN'</span>).mask(df.X_1.notna()).fillna(<span class="hljs-string">"NotNaN"</span>)<br>cat_2 = df.X_2.fillna(<span class="hljs-string">'NaN'</span>).mask(df.X_2.notna()).fillna(<span class="hljs-string">"NotNaN"</span>)<br></code></pre></td></tr></table></figure><p>交叉表(crossTab)<br>交叉表是用于<strong>统计分组频率</strong>的特殊透视表</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df_1 = pd.crosstab(cat_1, df.y, margins=<span class="hljs-literal">True</span>)<br>df_2 = pd.crosstab(cat_2, df.y, margins=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compute_S</span><span class="hljs-params">(my_df)</span>:</span><br>    S = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">2</span>):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(<span class="hljs-number">2</span>):<br>            E = my_df.iat[i, j]<br>            F = my_df.iat[i, <span class="hljs-number">2</span>]*my_df.iat[<span class="hljs-number">2</span>, j]/my_df.iat[<span class="hljs-number">2</span>,<span class="hljs-number">2</span>]<br>            S.append((E-F)**<span class="hljs-number">2</span>/F)<br>    <span class="hljs-keyword">return</span> sum(S)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res1 = compute_S(df_1)<br>res2 = compute_S(df_2)<br><span class="hljs-keyword">from</span> scipy.stats <span class="hljs-keyword">import</span> chi2<br>chi2.sf(res1, <span class="hljs-number">1</span>) <span class="hljs-comment"># X_1检验的p值 # 不能认为相关，剔除</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">chi2.sf(res2,<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h2 id="Ex2：用回归模型解决分类问题"><a href="#Ex2：用回归模型解决分类问题" class="headerlink" title="Ex2：用回归模型解决分类问题"></a>Ex2：用回归模型解决分类问题</h2><p><code>KNN</code> 是一种监督式学习模型，既可以解决回归问题，又可以解决分类问题。对于分类变量，利用 <code>KNN</code> 分类模型可以实现其缺失值的插补，思路是度量缺失样本的特征与所有其他样本特征的距离，当给定了模型参数 <code>n_neighbors=n</code> 时，计算离该样本距离最近的 <code>n </code>个样本点中最多的那个类别，并把这个类别作为该样本的缺失预测类别，具体如下图所示，未知的类别被预测为黄色：</p><p><img src="http://inter.joyfulpandas.datawhale.club/_images/ch7_ex.png" alt="img"></p><p>上面有色点的特征数据提供如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df=pd.read_excel(<span class="hljs-string">'data/color.xlsx'</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df.head(<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><p>已知待预测的样本点为 $X_1=0.8,X_2=−0.2$ ，那么预测类别可以如下写出</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">clf=KNeighborsClassifier(n_neighbors=<span class="hljs-number">6</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">clf.fit(df.iloc[:,:<span class="hljs-number">2</span>],df.Color)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">clf.predict([[<span class="hljs-number">0.8</span>,<span class="hljs-number">-0.2</span>]])<br></code></pre></td></tr></table></figure><p>1.对于回归问题而言，需要得到的是一个具体的数值，因此预测值由最近的 n 个样本对应的平均值获得。请把上面的这个分类问题转化为回归问题，仅使用 KNeighborsRegressor 来完成上述的 KNeighborsClassifier 功能。</p><h2 id="标准答案"><a href="#标准答案" class="headerlink" title="标准答案"></a>标准答案</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsRegressor<br>df = pd.read_excel(<span class="hljs-string">'../data/color.xlsx'</span>)<br>df_dummies = pd.get_dummies(df.Color)<br>stack_list = []<br><span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> df_dummies.columns:<br>    clf = KNeighborsRegressor(n_neighbors=<span class="hljs-number">6</span>)<br>    clf.fit(df.iloc[:,:<span class="hljs-number">2</span>], df_dummies[col])<br>    res = clf.predict([[<span class="hljs-number">0.8</span>, <span class="hljs-number">-0.2</span>]]).reshape(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>)<br>    stack_list.append(res)<br>code_res = pd.Series(np.hstack(stack_list).argmax(<span class="hljs-number">1</span>))<br>df_dummies.columns[code_res[<span class="hljs-number">0</span>]]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsRegressor<br>df=pd.read_excel(<span class="hljs-string">'data/color.xlsx'</span>)<br>df_dummies=pd.get_dummies(df.Color)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df_dummies.head()<span class="hljs-comment">#转换成one-hot编码模式</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">stack_list = []<br><span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> df_dummies.columns:<br>    print(col)<br>    clf = KNeighborsRegressor(n_neighbors=<span class="hljs-number">6</span>)<br>    clf.fit(df.iloc[:,:<span class="hljs-number">2</span>], df_dummies[col])<br>    res = clf.predict([[<span class="hljs-number">0.8</span>, <span class="hljs-number">-0.2</span>]]).reshape(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>)<br>    print(res)<br>    stack_list.append(res)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.hstack(stack_list).argmax(<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">code_res = pd.Series(np.hstack(stack_list).argmax(<span class="hljs-number">1</span>))<br>df_dummies.columns[code_res[<span class="hljs-number">0</span>]]<br></code></pre></td></tr></table></figure><p>2.请根据第1问中的方法，对 <code>audit </code>数据集中的 <code>Employment</code> 变量进行缺失值插补。</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">df = pd.read_csv(<span class="hljs-string">'data/audit.csv'</span>)<br>pd.get_dummies(df[[<span class="hljs-string">'Marital'</span>, <span class="hljs-string">'Gender'</span>]])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsRegressor<br>df = pd.read_csv(<span class="hljs-string">'data/audit.csv'</span>)<br>res_df = df.copy()<br>res_df2 = df.copy()<br><span class="hljs-comment">#数据处理加归一化这句写的很妙</span><br>df = pd.concat([pd.get_dummies(df[[<span class="hljs-string">'Marital'</span>, <span class="hljs-string">'Gender'</span>]]), df[[<span class="hljs-string">'Age'</span>,<span class="hljs-string">'Income'</span>,<span class="hljs-string">'Hours'</span>]].apply(<span class="hljs-keyword">lambda</span> x:(x-x.min())/(x.max()-x.min())), df.Employment],<span class="hljs-number">1</span>)<br>df.head()<br></code></pre></td></tr></table></figure><h2 id="使用KNN分类法"><a href="#使用KNN分类法" class="headerlink" title="使用KNN分类法"></a>使用KNN分类法</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier<br>clf=KNeighborsClassifier(n_neighbors=<span class="hljs-number">6</span>)<br>train=df[df.Employment.notna()]<br>test=df[df.Employment.isna()]<br>clf.fit(train.iloc[:,:<span class="hljs-number">-1</span>],train.Employment)<br>predict=clf.predict(test.iloc[:,:<span class="hljs-number">-1</span>])<br>res_df2.loc[res_df.Employment.isna(), <span class="hljs-string">'Employment'</span>] = predict<br>res_df2.isna().sum()<br></code></pre></td></tr></table></figure><h2 id="使用KNN分类树"><a href="#使用KNN分类树" class="headerlink" title="使用KNN分类树"></a>使用KNN分类树</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">X_train = df[df.Employment.notna()]<br>X_test = df[df.Employment.isna()]<br>df_dummies = pd.get_dummies(X_train.Employment)<br>stack_list = []<br><span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> df_dummies.columns:<br>    clf = KNeighborsRegressor(n_neighbors=<span class="hljs-number">6</span>)<br>    clf.fit(X_train.iloc[:,:<span class="hljs-number">-1</span>], df_dummies[col])<br>    res = clf.predict(X_test.iloc[:,:<span class="hljs-number">-1</span>]).reshape(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>)<br>    stack_list.append(res)<br>code_res = pd.Series(np.hstack(stack_list).argmax(<span class="hljs-number">1</span>))<br>cat_res = code_res.replace(dict(zip(list(range(df_dummies.shape[<span class="hljs-number">0</span>])),df_dummies.columns)))<br>res_df.loc[res_df.Employment.isna(), <span class="hljs-string">'Employment'</span>] = cat_res.values<br>res_df.isna().sum()<br></code></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;缺失数据&quot;&gt;&lt;a href=&quot;#缺失数据&quot; class=&quot;headerlink&quot; title=&quot;缺失数据&quot;&gt;&lt;/a&gt;缺失数据&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;code class=&quot;hljs python&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;hljs-keyword&quot;&gt;as&lt;/span&gt; np&lt;br&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; pandas &lt;span class=&quot;hljs-keyword&quot;&gt;as&lt;/span&gt; pd&lt;br&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;h2 id=&quot;一、缺失值的统计和删除&quot;&gt;&lt;a href=&quot;#一、缺失值的统计和删除&quot; class=&quot;headerlink&quot; title=&quot;一、缺失值的统计和删除&quot;&gt;&lt;/a&gt;一、缺失值的统计和删除&lt;/h2&gt;&lt;h2 id=&quot;1-缺失信息的统计&quot;&gt;&lt;a href=&quot;#1-缺失信息的统计&quot; class=&quot;headerlink&quot; title=&quot;1. 缺失信息的统计&quot;&gt;&lt;/a&gt;1. 缺失信息的统计&lt;/h2&gt;&lt;p&gt;缺失数据可以使用 &lt;code&gt;isna&lt;/code&gt; 或 &lt;code&gt;isnull&lt;/code&gt; （两个函数没有区别）来查看每个单元格是否缺失，结合 &lt;code&gt;mean&lt;/code&gt; 可以计算出每列缺失值的比例：&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="pandas" scheme="https://yoursite.com/tags/pandas/"/>
    
      <category term="datawhale" scheme="https://yoursite.com/tags/datawhale/"/>
    
  </entry>
  
  <entry>
    <title>datawhale-pandas数据分析预备</title>
    <link href="https://yoursite.com/2020/12/21/datawhale-pandas%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E9%A2%84%E5%A4%87/"/>
    <id>https://yoursite.com/2020/12/21/datawhale-pandas%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E9%A2%84%E5%A4%87/</id>
    <published>2020-12-21T04:40:31.000Z</published>
    <updated>2021-02-20T13:45:38.203Z</updated>
    
    <content type="html"><![CDATA[<h2 id="datawhale-pandas数据分析预备"><a href="#datawhale-pandas数据分析预备" class="headerlink" title="datawhale-pandas数据分析预备"></a>datawhale-pandas数据分析预备</h2><h2 id="列表推导式"><a href="#列表推导式" class="headerlink" title="列表推导式"></a>列表推导式</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">my_func</span><span class="hljs-params">(x)</span>:</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">2</span>*x<br></code></pre></td></tr></table></figure><h2 id="for-i-in"><a href="#for-i-in" class="headerlink" title="[* for i in *]"></a>[* for i in *]</h2><p>其中，第一个 * 为映射函数，其输入为后面 i 指代的内容，第二个 * 表示迭代的对象。</p><a id="more"></a><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">[my_func(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">5</span>)]<br></code></pre></td></tr></table></figure><p>out:[0, 2, 4, 6, 8]</p><p>列表表达式支持多层嵌套</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">[m+<span class="hljs-string">'_'</span>+n <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span>[<span class="hljs-string">'a'</span>,<span class="hljs-string">'b'</span>] <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span>[<span class="hljs-string">'c'</span>,<span class="hljs-string">'d'</span>]]<br></code></pre></td></tr></table></figure><p>out:[‘a_c’, ‘a_d’, ‘b_c’, ‘b_d’]</p><h2 id="条件赋值"><a href="#条件赋值" class="headerlink" title="条件赋值"></a>条件赋值</h2><h2 id="value-a-if-condition-else-b-："><a href="#value-a-if-condition-else-b-：" class="headerlink" title="value = a if condition else b ："></a>value = a if condition else b ：</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">value = <span class="hljs-string">'cat'</span> <span class="hljs-keyword">if</span> <span class="hljs-number">2</span>&gt;<span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-string">'dog'</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">value<br></code></pre></td></tr></table></figure><p>out:’cat’</p><p>下面举一个例子，截断列表中超过5的元素，即超过5的用5代替，小于5的保留原来的值：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">L=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]<br><br>[i <span class="hljs-keyword">if</span> i&lt;=<span class="hljs-number">5</span> <span class="hljs-keyword">else</span> <span class="hljs-number">5</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> L]<br></code></pre></td></tr></table></figure><p>out:[1, 2, 3, 4, 5, 5, 5]</p><h2 id="lambda"><a href="#lambda" class="headerlink" title="lambda"></a>lambda</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">my_func=<span class="hljs-keyword">lambda</span> x:<span class="hljs-number">2</span>*x<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">my_func(<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>out:4</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">f2=<span class="hljs-keyword">lambda</span> a,b:a+b<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">f2(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>out:3</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">[ (<span class="hljs-keyword">lambda</span> i:<span class="hljs-number">2</span>*i)(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> range(<span class="hljs-number">5</span>)]<br></code></pre></td></tr></table></figure><p>out:[0, 2, 4, 6, 8]</p><p>对于上述的这种列表推导式的匿名函数映射， Python 中提供了 map 函数来完成，它返回的是一个 map 对象，需要通过 list 转为列表：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">list(map(<span class="hljs-keyword">lambda</span> x: <span class="hljs-number">2</span>*x, range(<span class="hljs-number">5</span>)))<br></code></pre></td></tr></table></figure><p>[0, 2, 4, 6, 8]</p><p>对于多个输入值的函数映射，可以通过追加迭代对象实现：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">list(map(<span class="hljs-keyword">lambda</span> x, y: str(x)+<span class="hljs-string">'_'</span>+y, range(<span class="hljs-number">5</span>), list(<span class="hljs-string">'abcde'</span>)))<br></code></pre></td></tr></table></figure><p> [‘0_a’, ‘1_b’, ‘2_c’, ‘3_d’, ‘4_e’]</p><h2 id="zip"><a href="#zip" class="headerlink" title="zip"></a>zip</h2><p>zip函数能够把多个可迭代对象打包成一个元组构成的可迭代对象，它返回了一个 zip 对象，通过 tuple, list 可以得到相应的打包结果：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">L1, L2, L3 = list(<span class="hljs-string">'abc'</span>), list(<span class="hljs-string">'def'</span>), list(<span class="hljs-string">'hij'</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">list(zip(L1, L2, L3))<br></code></pre></td></tr></table></figure><p>[(‘a’, ‘d’, ‘h’), (‘b’, ‘e’, ‘i’), (‘c’, ‘f’, ‘j’)]</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">tuple(zip(L1, L2, L3))<br></code></pre></td></tr></table></figure><p>((‘a’, ‘d’, ‘h’), (‘b’, ‘e’, ‘i’), (‘c’, ‘f’, ‘j’))</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i,j,k <span class="hljs-keyword">in</span> zip(L1,L2,L3):<br>    print(i,j,k)<br></code></pre></td></tr></table></figure><p>a d h<br>b e i<br>c f j</p><h2 id="enumerate"><a href="#enumerate" class="headerlink" title="enumerate"></a>enumerate</h2><p><code>enumerate</code> 是一种特殊的打包，它可以在迭代时绑定迭代元素的遍历序号：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">L = list(<span class="hljs-string">'abcd'</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> index, value <span class="hljs-keyword">in</span> enumerate(L):<br>    print(index, value)<br></code></pre></td></tr></table></figure><p>0 a<br>1 b<br>2 c<br>3 d</p><p>用zip实现这个功能</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">[*zip(range(len(L)),L)]<br></code></pre></td></tr></table></figure><p>[(0, ‘a’), (1, ‘b’), (2, ‘c’), (3, ‘d’)]</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> index,value <span class="hljs-keyword">in</span> zip(range(len(L)),L):<br>    print(index,value)<br></code></pre></td></tr></table></figure><p>0 a<br>1 b<br>2 c<br>3 d</p><p>当需要对两个列表建立字典映射时，可以利用 zip 对象：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">dict(zip(L1,L2))<br></code></pre></td></tr></table></figure><p>{‘a’: ‘d’, ‘b’: ‘e’, ‘c’: ‘f’}</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">zipped = list(zip(L1, L2, L3))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">zipped<br></code></pre></td></tr></table></figure><p>[(‘a’, ‘d’, ‘h’), (‘b’, ‘e’, ‘i’), (‘c’, ‘f’, ‘j’)]</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">list(zip(*zipped))<br></code></pre></td></tr></table></figure><p>[(‘a’, ‘b’, ‘c’), (‘d’, ‘e’, ‘f’), (‘h’, ‘i’, ‘j’)]</p><h2 id="numpy回顾"><a href="#numpy回顾" class="headerlink" title="numpy回顾"></a>numpy回顾</h2><h2 id="1-np数组的构造"><a href="#1-np数组的构造" class="headerlink" title="1. np数组的构造"></a>1. np数组的构造</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br></code></pre></td></tr></table></figure><p>最一般的方法是通过 array 来构造：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.array([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>])<br></code></pre></td></tr></table></figure><p>array([1, 2, 3])</p><p>等差序列： <code>np.linspace</code>, <code>np.arange</code></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.linspace(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>,<span class="hljs-number">9</span>) <span class="hljs-comment"># 起始、终止（包含）、样本个数</span><br></code></pre></td></tr></table></figure><p>array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.arange(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>,<span class="hljs-number">2</span>) <span class="hljs-comment"># 起始、终止（不包含）、步长</span><br></code></pre></td></tr></table></figure><p>array([1, 3])</p><p>特殊矩阵： <code>zeros</code>, <code>eye</code>, <code>full</code></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.zeros((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)) <span class="hljs-comment"># 传入元组表示各维度大小</span><br></code></pre></td></tr></table></figure><p>array([[0., 0., 0.],<br>      [0., 0., 0.]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.eye(<span class="hljs-number">3</span>) <span class="hljs-comment">#代表维度3*3的单位矩阵</span><br></code></pre></td></tr></table></figure><p>array([[1., 0., 0.],<br>        [0., 1., 0.],<br>        [0., 0., 1.]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.eye(<span class="hljs-number">3</span>, k=<span class="hljs-number">1</span>) <span class="hljs-comment"># 偏移主对角线1个单位的伪单位矩阵</span><br></code></pre></td></tr></table></figure><p>array([[0., 1., 0.],<br>        [0., 0., 1.],<br>        [0., 0., 0.]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.eye(<span class="hljs-number">3</span>, k=<span class="hljs-number">-1</span>) <span class="hljs-comment"># 偏移主对角线1个单位的伪单位矩阵</span><br></code></pre></td></tr></table></figure><p>array([[0., 0., 0.],<br>        [1., 0., 0.],<br>        [0., 1., 0.]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.eye(<span class="hljs-number">3</span>, k=<span class="hljs-number">2</span>) <span class="hljs-comment"># 偏移主对角线1个单位的伪单位矩阵</span><br></code></pre></td></tr></table></figure><p>array([[0., 0., 1.],<br>        [0., 0., 0.],<br>        [0., 0., 0.]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.full((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>),<span class="hljs-number">10</span>)<span class="hljs-comment"># 元组传入大小，10表示填充数值</span><br></code></pre></td></tr></table></figure><p>array([[10, 10, 10],<br>        [10, 10, 10]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.full((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>), [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]) <span class="hljs-comment"># 每行填入相同的列表</span><br></code></pre></td></tr></table></figure><p>array([[1, 2, 3],<br>        [1, 2, 3]])</p><p>随机矩阵: <code>np.random</code></p><table><thead><tr><th>函数</th><th>含义</th></tr></thead><tbody><tr><td><code>np.random.rand</code></td><td>0-1均匀分布的随机数组</td></tr><tr><td><code>np.random.randn</code></td><td>标准正态的随机数组</td></tr><tr><td><code>np.random.randint</code></td><td>随机整数组</td></tr><tr><td><code>np.random.choice</code></td><td>随机列表抽样</td></tr></tbody></table><h2 id="np-random-rand"><a href="#np-random-rand" class="headerlink" title="np.random.rand"></a><code>np.random.rand</code></h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.rand(<span class="hljs-number">3</span>)<span class="hljs-comment"># 生成服从0-1均匀分布的三个随机数</span><br></code></pre></td></tr></table></figure><p>array([0.25659368, 0.37802498, 0.62494881])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.rand(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>)<span class="hljs-comment"># 生成服从0-1均匀分布的三个随机数</span><br></code></pre></td></tr></table></figure><p>array([[0.64676496, 0.59502481, 0.61343668],<br>        [0.16019992, 0.49285208, 0.96761024],<br>        [0.94030055, 0.48943744, 0.1143115 ]])</p><p>对于服从区间 a 到 b 上的均匀分布可以如下生成：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a, b = <span class="hljs-number">5</span>, <span class="hljs-number">15</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">(b - a) * np.random.rand(<span class="hljs-number">3</span>) + a<br></code></pre></td></tr></table></figure><p>array([ 8.84499261, 10.21774591,  8.16028516])</p><p><strong>一般的，可以选择已有的库函数：</strong></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.uniform(<span class="hljs-number">5</span>, <span class="hljs-number">15</span>, <span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><p>array([8.86348101, 9.14266299, 8.60513876])</p><h2 id="np-random-randn"><a href="#np-random-randn" class="headerlink" title="np.random.randn"></a><code>np.random.randn</code></h2><p><code>randn</code> 生成了 $N(0,I)$ 的标准正态分布：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.randn(<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><p>array([ 1.41288442, -0.73967664, -0.23529916])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.randn(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>array([[ 0.85735525, -0.17674214],<br>        [-0.28607067,  1.49904315]])</p><p>对于服从$N(\mu, \sigma^2)$的一元正态分布则有</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">mu,sigma=<span class="hljs-number">3</span>,<span class="hljs-number">2.5</span><br>mu+np.random.randn(<span class="hljs-number">3</span>)*sigma<br></code></pre></td></tr></table></figure><p>array([-0.26367497,  1.87383756,  2.81701976])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.normal(<span class="hljs-number">3</span>,<span class="hljs-number">2.5</span>,<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><p>array([6.40062933, 3.28135583, 0.65048172])</p><p><code>randint</code> 可以指定生成<strong>随机整数</strong>最大值（不包含）和维度大小：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">low, high, size = <span class="hljs-number">5</span>, <span class="hljs-number">15</span>, (<span class="hljs-number">2</span>,<span class="hljs-number">2</span>) <span class="hljs-comment"># 生成5到14的随机整数</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.randint(low, high, size)<br></code></pre></td></tr></table></figure><p>array([[13, 14],<br>        [ 7, 10]])</p><p><code>choice</code> 可以从给定的列表中，以一定概率和方式抽取结果，当不指定概率时为均匀采样，默认抽取方式为有放回抽样：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">my_list = [<span class="hljs-string">'a'</span>, <span class="hljs-string">'b'</span>, <span class="hljs-string">'c'</span>, <span class="hljs-string">'d'</span>]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.choice(my_list, <span class="hljs-number">2</span>, replace=<span class="hljs-literal">False</span>, p=[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.7</span>, <span class="hljs-number">0.1</span> ,<span class="hljs-number">0.1</span>])<br></code></pre></td></tr></table></figure><p>array([‘a’, ‘b’], dtype=’&lt;U1’)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.choice(my_list, (<span class="hljs-number">2</span>,<span class="hljs-number">2</span>), replace=<span class="hljs-literal">True</span>, p=[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.7</span>, <span class="hljs-number">0.1</span> ,<span class="hljs-number">0.1</span>])<br></code></pre></td></tr></table></figure><p>array([[‘d’, ‘b’],<br>        [‘b’, ‘b’]], dtype=’&lt;U1’)</p><p><img src="https://img-blog.csdnimg.cn/20201221120439843.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-tyytLsj8-1608522933090)(attachment:image.png)]"></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.choice(my_list, (<span class="hljs-number">3</span>,<span class="hljs-number">3</span>))<br></code></pre></td></tr></table></figure><p>array([[‘d’, ‘c’, ‘c’],<br>        [‘d’, ‘a’, ‘c’],<br>        [‘d’, ‘b’, ‘b’]], dtype=’&lt;U1’)</p><p>当返回的元素个数与原列表相同时，不放回抽样等价于使用 <code>permutation</code> 函数，即打散原列表：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.permutation(my_list)<br></code></pre></td></tr></table></figure><p>array([‘d’, ‘b’, ‘c’, ‘a’], dtype=’&lt;U1’)</p><p>最后，需要提到的是随机种子，它能够固定随机数的输出结果：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.seed(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.rand()<br></code></pre></td></tr></table></figure><p>0.5488135039273248</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.rand(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.rand()<br></code></pre></td></tr></table></figure><p>0.5488135039273248</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.rand()<br></code></pre></td></tr></table></figure><p>0.6027633760716439</p><h2 id="2-np数组的变形与合并"><a href="#2-np数组的变形与合并" class="headerlink" title="2. np数组的变形与合并"></a>2. np数组的变形与合并</h2><p>转置</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.zeros((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)).T<br></code></pre></td></tr></table></figure><p>array([[0., 0.],<br>        [0., 0.],<br>        [0., 0.]])</p><p>合并操作</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.r_[np.zeros((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)),np.zeros((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>))] <span class="hljs-comment">#上下合并</span><br></code></pre></td></tr></table></figure><p>array([[0., 0., 0.],<br>        [0., 0., 0.],<br>        [0., 0., 0.],<br>        [0., 0., 0.]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.c_[np.zeros((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)),np.zeros((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>))] <span class="hljs-comment">#左右合并</span><br></code></pre></td></tr></table></figure><p>array([[0., 0., 0., 0., 0., 0.],<br>        [0., 0., 0., 0., 0., 0.]])</p><p>一维数组和二维数组进行合并时，应当把其视作列向量，在长度匹配的情况下只能够使用左右合并的 c_ 操作：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">try</span>:<br>    np.r_[np.array([<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]),np.zeros((<span class="hljs-number">2</span>,<span class="hljs-number">1</span>))]<br><span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>    Err_Msg=e<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">Err_Msg<br></code></pre></td></tr></table></figure><p>ValueError(‘all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)’)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.r_[np.array([<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]),np.zeros(<span class="hljs-number">2</span>)]<br></code></pre></td></tr></table></figure><p>array([0., 0., 0., 0.])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.c_[np.array([<span class="hljs-number">0</span>,<span class="hljs-number">0</span>]),np.zeros((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>))]<br></code></pre></td></tr></table></figure><p>array([[0., 0., 0., 0.],<br>         [0., 0., 0., 0.]])</p><p>维度变换: <code>reshape</code></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target = np.arange(<span class="hljs-number">8</span>).reshape(<span class="hljs-number">2</span>,<span class="hljs-number">4</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target<br></code></pre></td></tr></table></figure><p>array([[0, 1, 2, 3],<br>           [4, 5, 6, 7]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target.reshape((<span class="hljs-number">4</span>,<span class="hljs-number">2</span>), order=<span class="hljs-string">'C'</span>) <span class="hljs-comment"># 按照行读取和填充</span><br></code></pre></td></tr></table></figure><p>array([[0, 1],<br>           [2, 3],<br>           [4, 5],<br>           [6, 7]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target.reshape((<span class="hljs-number">4</span>,<span class="hljs-number">2</span>), order=<span class="hljs-string">'F'</span>) <span class="hljs-comment"># 按照列读取和填充</span><br></code></pre></td></tr></table></figure><p>array([[0, 2],<br>           [4, 6],<br>           [1, 3],<br>           [5, 7]])</p><p>特别地，由于被调用数组的大小是确定的， reshape 允许有一个维度存在空缺，此时只需填充-1即可：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target.reshape((<span class="hljs-number">4</span>,<span class="hljs-number">-1</span>))<br></code></pre></td></tr></table></figure><p>array([[0, 1],<br>           [2, 3],<br>           [4, 5],<br>           [6, 7]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target = np.ones((<span class="hljs-number">3</span>,<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target<br></code></pre></td></tr></table></figure><p>array([[1.],<br>           [1.],<br>           [1.]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target.reshape(<span class="hljs-number">-1</span>)<br></code></pre></td></tr></table></figure><p>array([1., 1., 1.])</p><h2 id="3-np数组的切片与索引"><a href="#3-np数组的切片与索引" class="headerlink" title="3. np数组的切片与索引"></a>3. np数组的切片与索引</h2><p>数组的切片模式支持使用 <code>slice</code> 类型的 <code>start:end:step</code> 切片，还可以直接传入列表指定某个维度的索引进行切片：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target = np.arange(<span class="hljs-number">9</span>).reshape(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target<br></code></pre></td></tr></table></figure><p>array([[0, 1, 2],<br>           [3, 4, 5],<br>           [6, 7, 8]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target[:<span class="hljs-number">-1</span>, [<span class="hljs-number">0</span>,<span class="hljs-number">2</span>]]<br></code></pre></td></tr></table></figure><p>array([[0, 2],<br>           [3, 5]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target[<span class="hljs-number">0</span>:<span class="hljs-number">1</span>,:]<br></code></pre></td></tr></table></figure><p>array([[0, 1, 2]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target[<span class="hljs-number">0</span>:<span class="hljs-number">-1</span>,[<span class="hljs-number">0</span>]]<br></code></pre></td></tr></table></figure><p>array([[0],<br>           [3]])</p><p>此外，还可以利用 <code>np.ix_</code> 在对应的维度上使用布尔索引，但此时不能使用 <code>slice</code> 切片：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target[np.ix_([<span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">True</span>], [<span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">True</span>])]<br></code></pre></td></tr></table></figure><p>array([[0, 2],<br>           [6, 8]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target[np.ix_([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>], [<span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">True</span>])]<br></code></pre></td></tr></table></figure><p>array([[3, 5],<br>           [6, 8]])</p><p>当数组维度为1维时，可以直接进行布尔索引，而无需 <code>np.ix_ </code>：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">new = target.reshape(<span class="hljs-number">-1</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">new[new%<span class="hljs-number">2</span>==<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure><p>array([0, 2, 4, 6, 8])</p><h2 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h2><p><code>where</code> 是一种条件函数，可以指定满足条件与不满足条件位置对应的填充值：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a = np.array([<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">-1</span>,<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.where(a&gt;<span class="hljs-number">0</span>, a, <span class="hljs-number">5</span>) <span class="hljs-comment"># 对应位置为True时填充a对应元素，否则填充5</span><br></code></pre></td></tr></table></figure><p>array([5, 1, 5, 5])</p><p><code>nonzero, argmax, argmin</code></p><p>这三个函数返回的都是索引， <code>nonzero</code> 返回非零数的索引， <code>argmax, argmin</code> 分别返回最大和最小数的索引：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a = np.array([<span class="hljs-number">-2</span>,<span class="hljs-number">-5</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">-1</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.nonzero(a)<br></code></pre></td></tr></table></figure><p>(array([0, 1, 3, 4, 5], dtype=int64),)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a.argmax()<br></code></pre></td></tr></table></figure><pre><code>4</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a.argmin()<br></code></pre></td></tr></table></figure><p>1</p><p>any 指当序列<strong>至少</strong> 存在一个 True 或非零元素时返回 True ，否则返回 False</p><p>all 指当序列元素 <strong>全为</strong> True 或非零元素时返回 True ，否则返回 False</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a = np.array([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a.any()<br></code></pre></td></tr></table></figure><p>True</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a.all()<br></code></pre></td></tr></table></figure><p>False</p><p><code>cumprod, cumsum</code> 分别表示累乘和累加函数，返回同长度的数组， <code>diff</code> 表示和前一个元素做差，由于第一个元素为缺失值，因此在默认参数情况下，返回长度是原数组减1</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a = np.array([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a.cumsum()<br></code></pre></td></tr></table></figure><p>array([1, 3, 6], dtype=int32)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a.cumprod()<br></code></pre></td></tr></table></figure><p>array([1, 2, 6], dtype=int32)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.diff(a)<br></code></pre></td></tr></table></figure><p>array([1, 1])</p><h2 id="统计函数"><a href="#统计函数" class="headerlink" title="统计函数"></a>统计函数</h2><p>常用的统计函数包括 <code>max, min, mean, median, std, var, sum, quantile</code> ，其中分位数计算是全局方法，因此不能通过 <code>array.quantile</code> 的方法调用：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target = np.arange(<span class="hljs-number">5</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target<br></code></pre></td></tr></table></figure><p>array([0, 1, 2, 3, 4])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target.max()<br></code></pre></td></tr></table></figure><p>4</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.quantile(target, <span class="hljs-number">0.15</span>) <span class="hljs-comment"># 0.5分位数</span><br></code></pre></td></tr></table></figure><p>0.6</p><p>但是对于含有缺失值的数组，它们返回的结果也是缺失值，如果需要略过缺失值，必须使用 <code>nan*</code> 类型的函数，上述的几个统计函数都有对应的 <code>nan*</code> 函数。</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target = np.array([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, np.nan])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target<br></code></pre></td></tr></table></figure><p>array([ 1.,  2., nan])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target.max()<br></code></pre></td></tr></table></figure><p>nan</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.nanmax(target)<br></code></pre></td></tr></table></figure><p>2.0</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.nanquantile(target, <span class="hljs-number">0.5</span>)<br></code></pre></td></tr></table></figure><p>1.5</p><p>对于协方差和相关系数分别可以利用 <code>cov, corrcoef </code>如下计算：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target1 = np.array([<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span>,<span class="hljs-number">9</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target2 = np.array([<span class="hljs-number">1</span>,<span class="hljs-number">5</span>,<span class="hljs-number">3</span>,<span class="hljs-number">-9</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.cov(target1, target2)<br></code></pre></td></tr></table></figure><p>array([[ 11.66666667, -16.66666667],<br>           [-16.66666667,  38.66666667]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.corrcoef(target1, target2)<br></code></pre></td></tr></table></figure><p>array([[ 1.        , -0.78470603],<br>           [-0.78470603,  1.        ]])</p><p>最后，需要说明二维 <code>Numpy</code> 数组中统计函数的 <code>axis</code> 参数，它能够进行某一个维度下的统计特征计算，当 <code>axis=0</code> 时结果为列的统计指标，当 <code>axis=1</code>时结果为行的统计指标：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target = np.arange(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>).reshape(<span class="hljs-number">3</span>,<span class="hljs-number">-1</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target<br></code></pre></td></tr></table></figure><p>array([[1, 2, 3],<br>           [4, 5, 6],<br>           [7, 8, 9]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target.sum(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>array([12, 15, 18])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">target.sum(<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p>array([ 6, 15, 24])</p><h2 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h2><p>标量和数组的操作<br>当一个标量和数组进行运算时，标量会自动把大小扩充为数组大小，之后进行逐元素操作：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res = <span class="hljs-number">3</span> * np.ones((<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)) + <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res<br></code></pre></td></tr></table></figure><p>array([[4., 4.],<br>           [4., 4.]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res = <span class="hljs-number">1</span> / res<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res<br></code></pre></td></tr></table></figure><p>array([[0.25, 0.25],<br>           [0.25, 0.25]])</p><p>二维数组之间的操作</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res = np.ones((<span class="hljs-number">3</span>,<span class="hljs-number">2</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res * np.array([[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]]) <span class="hljs-comment"># 第二个数组扩充第一维度为3</span><br></code></pre></td></tr></table></figure><p>array([[2., 3.],<br>           [2., 3.],<br>           [2., 3.]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res * np.array([[<span class="hljs-number">2</span>],[<span class="hljs-number">3</span>],[<span class="hljs-number">4</span>]]) <span class="hljs-comment"># 第二个数组扩充第二维度为2</span><br></code></pre></td></tr></table></figure><p>array([[2., 2.],<br>           [3., 3.],<br>           [4., 4.]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res * np.array([[<span class="hljs-number">2</span>]]) <span class="hljs-comment"># 等价于两次扩充，第二个数组两个维度分别扩充为3和2</span><br></code></pre></td></tr></table></figure><p>array([[2., 2.],<br>           [2., 2.],<br>           [2., 2.]])</p><p>一维数组与二维数组的操作</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.ones(<span class="hljs-number">3</span>) + np.ones((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>))<br></code></pre></td></tr></table></figure><p>array([[2., 2., 2.],<br>           [2., 2., 2.]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.ones(<span class="hljs-number">3</span>) + np.ones((<span class="hljs-number">2</span>,<span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><p>array([[2., 2., 2.],<br>           [2., 2., 2.]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.ones(<span class="hljs-number">1</span>) + np.ones((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>))<br></code></pre></td></tr></table></figure><p>array([[2., 2., 2.],<br>           [2., 2., 2.]])</p><h2 id="向量与矩阵的计算"><a href="#向量与矩阵的计算" class="headerlink" title="向量与矩阵的计算"></a>向量与矩阵的计算</h2><p>向量内积：<code>dot</code></p><p>$$ a · b = \Sigma_i{a_ib_i}$$</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a = np.array([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">b = np.array([<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span>])<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a.dot(b)<br></code></pre></td></tr></table></figure><p>22</p><p>向量范数和矩阵范数: <code>np.linalg.norm</code></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">matrix_target =  np.arange(<span class="hljs-number">4</span>).reshape(<span class="hljs-number">-1</span>,<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">matrix_target<br></code></pre></td></tr></table></figure><p>array([[0, 1],<br>           [2, 3]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.linalg.norm(matrix_target, <span class="hljs-string">'fro'</span>)<br></code></pre></td></tr></table></figure><p>3.7416573867739413</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.linalg.norm(matrix_target, np.inf)<br></code></pre></td></tr></table></figure><p>5.0</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.linalg.norm(matrix_target, <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>3.702459173643833</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">vector_target =  np.arange(<span class="hljs-number">4</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">vector_target<br></code></pre></td></tr></table></figure><p>array([0, 1, 2, 3])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.linalg.norm(vector_target, np.inf)<br></code></pre></td></tr></table></figure><p>3.0</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.linalg.norm(vector_target, <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>3.7416573867739413</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.linalg.norm(vector_target, <span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><p>3.3019272488946263</p><p>矩阵乘法</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a = np.arange(<span class="hljs-number">4</span>).reshape(<span class="hljs-number">-1</span>,<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">b = np.arange(<span class="hljs-number">-4</span>,<span class="hljs-number">0</span>).reshape(<span class="hljs-number">-1</span>,<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a<br></code></pre></td></tr></table></figure><p>array([[0, 1],<br>           [2, 3]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">b<br></code></pre></td></tr></table></figure><p>array([[-4, -3],<br>           [-2, -1]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a@b<br></code></pre></td></tr></table></figure><p>array([[ -2,  -1],<br>           [-14,  -9]])</p><h2 id="Ex1：利用列表推导式写矩阵乘法"><a href="#Ex1：利用列表推导式写矩阵乘法" class="headerlink" title="Ex1：利用列表推导式写矩阵乘法"></a>Ex1：利用列表推导式写矩阵乘法</h2><h2 id="方法1"><a href="#方法1" class="headerlink" title="方法1"></a>方法1</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">M1 = np.random.rand(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">M2 = np.random.rand(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res = np.zeros((M1.shape[<span class="hljs-number">0</span>],M2.shape[<span class="hljs-number">1</span>]))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res.shape<br></code></pre></td></tr></table></figure><p>(2, 4)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res<br></code></pre></td></tr></table></figure><p>array([[0., 0., 0., 0.],<br>           [0., 0., 0., 0.]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">i=<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">multifuc</span><span class="hljs-params">(i,j,k)</span>:</span><br>    res[i][j]+=M1[i][k] * M2[k][j]<br>    <span class="hljs-keyword">return</span> res[i][j]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">%timeit -n <span class="hljs-number">30</span> [ multifuc(i,j,k)  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(M1.shape[<span class="hljs-number">0</span>])  <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(M2.shape[<span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> range(M1.shape[<span class="hljs-number">1</span>])]<br></code></pre></td></tr></table></figure><p>83.3 µs ± 33.6 µs per loop (mean ± std. dev. of 7 runs, 30 loops each)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">(np.abs((M1@M2 - res) &lt; <span class="hljs-number">1e-15</span>)).all()<br></code></pre></td></tr></table></figure><p>True</p><h2 id="方法2"><a href="#方法2" class="headerlink" title="方法2"></a>方法2</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">i=<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">sum([M1[i][k] * M2[k][j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(M2.shape[<span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> range(M1.shape[<span class="hljs-number">1</span>])])<br></code></pre></td></tr></table></figure><p>3.745920492921166</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">%timeit -n <span class="hljs-number">30</span> [sum([M1[i][k] * M2[k][j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(M2.shape[<span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> range(M1.shape[<span class="hljs-number">1</span>])]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(M1.shape[<span class="hljs-number">0</span>])  <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(M2.shape[<span class="hljs-number">1</span>]) ]<br></code></pre></td></tr></table></figure><p>203 µs ± 33.3 µs per loop (mean ± std. dev. of 7 runs, 30 loops each)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">(np.abs((M1@M2 - res) &lt; <span class="hljs-number">1e-15</span>)).all()<br></code></pre></td></tr></table></figure><p>True</p><p>很明显第一种方法会比datawhale官方的要少一个循环，虽然这样确实有点取巧</p><h2 id="Ex2：更新矩阵"><a href="#Ex2：更新矩阵" class="headerlink" title="Ex2：更新矩阵"></a>Ex2：更新矩阵</h2><h3 id="Ex2：更新矩阵-1"><a href="#Ex2：更新矩阵-1" class="headerlink" title="Ex2：更新矩阵"></a>Ex2：更新矩阵</h3><p>设矩阵 $A_{m×n}$ ，现在对 $A$ 中的每一个元素进行更新生成矩阵 $B$ ，更新方法是 $B_{ij}=A_{ij}\sum_{k=1}^n\frac{1}{A_{ik}}$ ，例如下面的矩阵为 $A$ ，则 $B_{2,2}=5\times(\frac{1}{4}+\frac{1}{5}+\frac{1}{6})=\frac{37}{12}$ ，请利用 <code>Numpy</code> 高效实现。<br>$$<br> A=\left[<br> \begin{matrix}<br>   1 &amp; 2 &amp; 3 \<br>   4 &amp; 5 &amp; 6 \<br>   7 &amp; 8 &amp; 9<br>  \end{matrix}<br>  \right]<br>$$</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">A=np.arange(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>).reshape(<span class="hljs-number">3</span>,<span class="hljs-number">-1</span>)<span class="hljs-comment">#start从0开始，默认不包含end</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">A<br></code></pre></td></tr></table></figure><p>array([[1, 2, 3],<br>           [4, 5, 6],<br>           [7, 8, 9]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">A_reverse = <span class="hljs-number">1</span>/A<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">A_reverse<br></code></pre></td></tr></table></figure><p>array([[1.        , 0.5       , 0.33333333],<br>           [0.25      , 0.2       , 0.16666667],<br>           [0.14285714, 0.125     , 0.11111111]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">A_reverse.sum(axis=<span class="hljs-number">1</span>).reshape(<span class="hljs-number">3</span>,<span class="hljs-number">-1</span>)<br></code></pre></td></tr></table></figure><p>array([[1.83333333],<br>           [0.61666667],<br>           [0.37896825]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res =A*(A_reverse.sum(axis=<span class="hljs-number">1</span>).reshape(<span class="hljs-number">3</span>,<span class="hljs-number">-1</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res<br></code></pre></td></tr></table></figure><p>array([[1.83333333, 3.66666667, 5.5       ],<br>           [2.46666667, 3.08333333, 3.7       ],<br>           [2.65277778, 3.03174603, 3.41071429]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res.shape<br></code></pre></td></tr></table></figure><p>(3, 3)</p><h2 id="Ex3：卡方统计量"><a href="#Ex3：卡方统计量" class="headerlink" title="Ex3：卡方统计量"></a>Ex3：卡方统计量</h2><p>设矩阵$A_{m\times n}$，记$B_{ij} = \frac{(\sum_{i=1}^mA_{ij})\times (\sum_{j=1}^nA_{ij})}{\sum_{i=1}^m\sum_{j=1}^nA_{ij}}$，定义卡方值如下：<br>$$\chi^2 = \sum_{i=1}^m\sum_{j=1}^n\frac{(A_{ij}-B_{ij})^2}{B_{ij}}$$<br>请利用<code>Numpy</code>对给定的矩阵$A$计算$\chi^2$ </p><p>$(\sum_{i=1}^mA_{ij})\times (\sum_{j=1}^nA_{ij}) shape (8 \times 1) \times(1 \times 5)$ </p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.seed(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">A = np.random.randint(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, (<span class="hljs-number">8</span>, <span class="hljs-number">5</span>))<br></code></pre></td></tr></table></figure><p>通过分析我们可以看出其实矩阵$B$就是矩阵$A$通过对行和列求和再叉乘，然后除以所有元素的和</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">A_rowsum=A.sum(axis=<span class="hljs-number">0</span>).reshape(<span class="hljs-number">1</span>,<span class="hljs-number">-1</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">A_columnsum=A.sum(axis=<span class="hljs-number">1</span>).reshape(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">A_columnsum.shape,A_rowsum.shape<br></code></pre></td></tr></table></figure><p>((8, 1), (1, 5))</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">A_rowsum*A_columnsum <span class="hljs-comment">#有点离谱</span><br><span class="hljs-comment">#主要是*号对应数组用数组乘法，矩阵用矩阵乘法</span><br></code></pre></td></tr></table></figure><p>array([[ 8160,  7548,  8772,  7888,  6868],<br>           [ 8760,  8103,  9417,  8468,  7373],<br>           [ 9600,  8880, 10320,  9280,  8080],<br>           [ 9480,  8769, 10191,  9164,  7979],<br>           [10200,  9435, 10965,  9860,  8585],<br>           [ 7320,  6771,  7869,  7076,  6161],<br>           [ 8040,  7437,  8643,  7772,  6767],<br>           [ 7680,  7104,  8256,  7424,  6464]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">(A_rowsum*A_columnsum).shape<br></code></pre></td></tr></table></figure><p>(8, 5)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">A_columnsum@A_rowsum <span class="hljs-comment">#比较推荐这种</span><br></code></pre></td></tr></table></figure><p>array([[ 8160,  7548,  8772,  7888,  6868],<br>           [ 8760,  8103,  9417,  8468,  7373],<br>           [ 9600,  8880, 10320,  9280,  8080],<br>           [ 9480,  8769, 10191,  9164,  7979],<br>           [10200,  9435, 10965,  9860,  8585],<br>           [ 7320,  6771,  7869,  7076,  6161],<br>           [ 8040,  7437,  8643,  7772,  6767],<br>           [ 7680,  7104,  8256,  7424,  6464]])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">B=(A_columnsum@A_rowsum)/A.sum()<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">B.shape==A.shape<br></code></pre></td></tr></table></figure><p>True</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">res = ((A-B)**<span class="hljs-number">2</span>/B).sum()<br>res<br></code></pre></td></tr></table></figure><p>11.842696601945802</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.seed(<span class="hljs-number">0</span>)<br>A = np.random.randint(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, (<span class="hljs-number">8</span>, <span class="hljs-number">5</span>))<br>B = A.sum(<span class="hljs-number">0</span>)*A.sum(<span class="hljs-number">1</span>).reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>)/A.sum() <span class="hljs-comment">#个人认为这样写其实会误导初学者</span><br>res = ((A-B)**<span class="hljs-number">2</span>/B).sum()<br>res<br></code></pre></td></tr></table></figure><p>11.842696601945802</p><h2 id="Ex4：改进矩阵计算的性能"><a href="#Ex4：改进矩阵计算的性能" class="headerlink" title="Ex4：改进矩阵计算的性能"></a>Ex4：改进矩阵计算的性能</h2><h3 id="原方法"><a href="#原方法" class="headerlink" title="原方法"></a>原方法</h3><p><img src="https://img-blog.csdnimg.cn/20201221120104121.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-eDkWiRZe-1608522933099)(attachment:image.png)]"></p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.seed(<span class="hljs-number">0</span>)<br>m,n,p=<span class="hljs-number">100</span>,<span class="hljs-number">80</span>,<span class="hljs-number">50</span><br>B=np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,(m,p))<br>U=np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,(p,n))<br>Z=np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,(m,n))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solution</span><span class="hljs-params">(B=B, U=U, Z=Z)</span>:</span><br>    L_res = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(m):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(n):<br>            norm_value = ((B[i]-U[:,j])**<span class="hljs-number">2</span>).sum()<br>            L_res.append(norm_value*Z[i][j])<br>    <span class="hljs-keyword">return</span> sum(L_res)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">solution(B, U, Z)<br></code></pre></td></tr></table></figure><p>100566</p><p><img src="https://img-blog.csdnimg.cn/20201221120126404.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>从上式可以看出，第一第二项分别为$B$的行平方和与$U$的列平方和，第三项是两倍的内积。因此，$Y$矩阵可以写为三个部分，第一个部分是$m×n$的全$1$矩阵每行乘以$B$对应行的行平方和，第二个部分是相同大小的全$1$矩阵每列乘以$U$对应列的列平方和，第三个部分恰为$B$矩阵与$U$矩阵乘积的两倍。从而结果如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">B[<span class="hljs-number">1</span>].shape<br></code></pre></td></tr></table></figure><p>(50,)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">U[:,<span class="hljs-number">1</span>].shape<br></code></pre></td></tr></table></figure><p>(50,)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">(((B**<span class="hljs-number">2</span>).sum(axis=<span class="hljs-number">1</span>).reshape(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>)+(U**<span class="hljs-number">2</span>).sum(axis=<span class="hljs-number">0</span>)<span class="hljs-number">-2</span>*B@U)*Z).sum()<br></code></pre></td></tr></table></figure><p>100566</p><h2 id="连续整数的最大长度"><a href="#连续整数的最大长度" class="headerlink" title="连续整数的最大长度"></a>连续整数的最大长度</h2><p>输入一个整数的 <code>Numpy</code> 数组，返回其中严格递增连续整数子数组的最大长度。例如，输入 [1,2,5,6,7]，[5,6,7]为具有最大长度的递增连续整数子数组，因此输出3；输入[3,2,1,2,3,4,6]，[1,2,3,4]为具有最大长度的递增连续整数子数组，因此输出4。请充分利用 Numpy 的内置函数完成。（提示：考虑使用 <code>nonzero, diff</code> 函数）</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">f = <span class="hljs-keyword">lambda</span> x:np.diff(np.nonzero(np.r_[<span class="hljs-number">1</span>,np.diff(x)!=<span class="hljs-number">1</span>,<span class="hljs-number">1</span>])).max()<br>f([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>])<br>f([<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>])<br></code></pre></td></tr></table></figure><p>4</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">x=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.diff(x)<br></code></pre></td></tr></table></figure><p>array([1, 3, 1, 1])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.diff(x)!=<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>array([False,  True, False, False])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.r_[<span class="hljs-number">1</span>,np.diff(x)!=<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure><p>array([1, 0, 1, 0, 0, 1], dtype=int32)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.nonzero(np.r_[<span class="hljs-number">1</span>,np.diff(x)!=<span class="hljs-number">1</span>,<span class="hljs-number">1</span>])<br></code></pre></td></tr></table></figure><p>(array([0, 2, 5], dtype=int64),)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.diff(np.nonzero(np.r_[<span class="hljs-number">1</span>,np.diff(x)!=<span class="hljs-number">1</span>,<span class="hljs-number">1</span>])).max()<br></code></pre></td></tr></table></figure><p>3</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><br><br></code></pre></td></tr></table></figure><p>1.842696601945802</p><h2 id="Ex4：改进矩阵计算的性能-1"><a href="#Ex4：改进矩阵计算的性能-1" class="headerlink" title="Ex4：改进矩阵计算的性能"></a>Ex4：改进矩阵计算的性能</h2><h3 id="原方法-1"><a href="#原方法-1" class="headerlink" title="原方法"></a>原方法</h3><p>[外链图片转存中…(img-eDkWiRZe-1608522933099)]</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.random.seed(<span class="hljs-number">0</span>)<br>m,n,p=<span class="hljs-number">100</span>,<span class="hljs-number">80</span>,<span class="hljs-number">50</span><br>B=np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,(m,p))<br>U=np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,(p,n))<br>Z=np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,(m,n))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">solution</span><span class="hljs-params">(B=B, U=U, Z=Z)</span>:</span><br>    L_res = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(m):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(n):<br>            norm_value = ((B[i]-U[:,j])**<span class="hljs-number">2</span>).sum()<br>            L_res.append(norm_value*Z[i][j])<br>    <span class="hljs-keyword">return</span> sum(L_res)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">solution(B, U, Z)<br></code></pre></td></tr></table></figure><p>100566</p><p>改进方法：</p><p>令$Y_{ij} = |B_i-U_j|<em>2^2$，则$\displaystyle R=\sum</em>{i=1}^m\sum_{j=1}^n Y_{ij}Z_{ij}$，这在<code>Numpy</code>中可以用逐元素的乘法后求和实现，因此问题转化为了如何构造<code>Y</code>矩阵。</p><p>$$<br>\begin{split}Y_{ij} &amp;= |B_i-U_j|<em>2^2\<br>&amp;=\sum</em>{k=1}^p(B_{ik}-U_{kj})^2\<br>&amp;=\sum_{k=1}^p B_{ik}^2+\sum_{k=1}^p U_{kj}^2-2\sum_{k=1}^p B_{ik}U_{kj}\\end{split}<br>$$</p><p>从上式可以看出，第一第二项分别为$B$的行平方和与$U$的列平方和，第三项是两倍的内积。因此，$Y$矩阵可以写为三个部分，第一个部分是$m×n$的全$1$矩阵每行乘以$B$对应行的行平方和，第二个部分是相同大小的全$1$矩阵每列乘以$U$对应列的列平方和，第三个部分恰为$B$矩阵与$U$矩阵乘积的两倍。从而结果如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">B[<span class="hljs-number">1</span>].shape<br></code></pre></td></tr></table></figure><p>(50,)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">U[:,<span class="hljs-number">1</span>].shape<br></code></pre></td></tr></table></figure><p>(50,)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">(((B**<span class="hljs-number">2</span>).sum(axis=<span class="hljs-number">1</span>).reshape(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>)+(U**<span class="hljs-number">2</span>).sum(axis=<span class="hljs-number">0</span>)<span class="hljs-number">-2</span>*B@U)*Z).sum()<br></code></pre></td></tr></table></figure><p>100566</p><h2 id="连续整数的最大长度-1"><a href="#连续整数的最大长度-1" class="headerlink" title="连续整数的最大长度"></a>连续整数的最大长度</h2><p>输入一个整数的 <code>Numpy</code> 数组，返回其中严格递增连续整数子数组的最大长度。例如，输入 [1,2,5,6,7]，[5,6,7]为具有最大长度的递增连续整数子数组，因此输出3；输入[3,2,1,2,3,4,6]，[1,2,3,4]为具有最大长度的递增连续整数子数组，因此输出4。请充分利用 Numpy 的内置函数完成。（提示：考虑使用 <code>nonzero, diff</code> 函数）</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">f = <span class="hljs-keyword">lambda</span> x:np.diff(np.nonzero(np.r_[<span class="hljs-number">1</span>,np.diff(x)!=<span class="hljs-number">1</span>,<span class="hljs-number">1</span>])).max()<br>f([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>])<br>f([<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>])<br></code></pre></td></tr></table></figure><p>4</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">x=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.diff(x)<br></code></pre></td></tr></table></figure><p>array([1, 3, 1, 1])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.diff(x)!=<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>array([False,  True, False, False])</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.r_[<span class="hljs-number">1</span>,np.diff(x)!=<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure><p>array([1, 0, 1, 0, 0, 1], dtype=int32)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.nonzero(np.r_[<span class="hljs-number">1</span>,np.diff(x)!=<span class="hljs-number">1</span>,<span class="hljs-number">1</span>])<br></code></pre></td></tr></table></figure><p>(array([0, 2, 5], dtype=int64),)</p><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">np.diff(np.nonzero(np.r_[<span class="hljs-number">1</span>,np.diff(x)!=<span class="hljs-number">1</span>,<span class="hljs-number">1</span>])).max()<br></code></pre></td></tr></table></figure><p>3</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;datawhale-pandas数据分析预备&quot;&gt;&lt;a href=&quot;#datawhale-pandas数据分析预备&quot; class=&quot;headerlink&quot; title=&quot;datawhale-pandas数据分析预备&quot;&gt;&lt;/a&gt;datawhale-pandas数据分析预备&lt;/h2&gt;&lt;h2 id=&quot;列表推导式&quot;&gt;&lt;a href=&quot;#列表推导式&quot; class=&quot;headerlink&quot; title=&quot;列表推导式&quot;&gt;&lt;/a&gt;列表推导式&lt;/h2&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;code class=&quot;hljs python&quot;&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;my_func&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(x)&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;    &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt;*x&lt;br&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;h2 id=&quot;for-i-in&quot;&gt;&lt;a href=&quot;#for-i-in&quot; class=&quot;headerlink&quot; title=&quot;[* for i in *]&quot;&gt;&lt;/a&gt;[* for i in *]&lt;/h2&gt;&lt;p&gt;其中，第一个 * 为映射函数，其输入为后面 i 指代的内容，第二个 * 表示迭代的对象。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="pandas" scheme="https://yoursite.com/tags/pandas/"/>
    
      <category term="datawhale" scheme="https://yoursite.com/tags/datawhale/"/>
    
  </entry>
  
  <entry>
    <title>信号量机制经典例子</title>
    <link href="https://yoursite.com/2020/11/06/%E4%BF%A1%E5%8F%B7%E9%87%8F%E6%9C%BA%E5%88%B6%E7%BB%8F%E5%85%B8%E4%BE%8B%E5%AD%90/"/>
    <id>https://yoursite.com/2020/11/06/%E4%BF%A1%E5%8F%B7%E9%87%8F%E6%9C%BA%E5%88%B6%E7%BB%8F%E5%85%B8%E4%BE%8B%E5%AD%90/</id>
    <published>2020-11-05T16:27:36.000Z</published>
    <updated>2021-01-19T04:31:32.370Z</updated>
    
    <content type="html"><![CDATA[<h2 id="理发师问题"><a href="#理发师问题" class="headerlink" title="理发师问题"></a>理发师问题</h2><p>7.8 The Sleeping-Barber Problem. A barbershop consists of a waiting room with n chairs and the barber room containing the barber chair. If there are no customers to be served,the barber goes to sleep. If a customer enters the barbershop and all chairs are occupied, then the customer leaves the shop.If the barber is busy but chairs are available, then the customer sits in one of the free chairs. If the barber is asleep, the customer wakes up the barber. Write a program to coordinate the barber and the customers.</p><a id="more"></a><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++">semaphore:<br>    full:=<span class="hljs-number">0</span>,empty:=n,mutex:=<span class="hljs-number">1</span>;<span class="hljs-comment">//刘军的写法</span><br><span class="hljs-comment">/*</span><br><span class="hljs-comment">*full表示当前需要理发的人数</span><br><span class="hljs-comment">*empty表示当前还剩下多少空椅子</span><br><span class="hljs-comment">*mutex进程互斥控制量，理发师一次只能给一个人理发</span><br><span class="hljs-comment">*/</span><br>Parbegin:<br>    customer: repeat<br>            <span class="hljs-keyword">if</span> empty=<span class="hljs-number">0</span>:<br>                customer leaves the shop<span class="hljs-comment">//没有空位置则离开</span><br>            P(empty);<br>            P(mutex);<br>            add a customer to chair<br>            V(mutex);<br>            V(full);<br>            until <span class="hljs-literal">false</span>;<br>    <br>    barber: repeat<br>            <span class="hljs-keyword">if</span> full=<span class="hljs-number">0</span>:<br>                barber sleep;<span class="hljs-comment">//没有人需要理发则睡觉</span><br>            P(full);<br>            P(mutex);<br>            cutting hair<br>            V(mutex);<br>            V(empty);<br>            until <span class="hljs-literal">false</span>;<br>Parend;<br></code></pre></td></tr></table></figure><h2 id="生产者消费者"><a href="#生产者消费者" class="headerlink" title="生产者消费者"></a>生产者消费者</h2><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++">type item=...;<br>var <span class="hljs-built_in">buffer</span>=...;<br><br>full,empty,mutex:semaphore;<br>nextp,nextc:item;<br><span class="hljs-built_in">begin</span>:<br>    full:=<span class="hljs-number">0</span>;empty:=n;mutex:=<span class="hljs-number">1</span>;<br>Parbegin:<br>    producer:repeat<br>        ...<br>        produce an item in nextp;<br>        ...<br>        p(empty);<br>        p(mutex);<br>        add nextp to <span class="hljs-built_in">buffer</span>;<br>        V(mutex);<br>        V(full);<br>        until <span class="hljs-literal">false</span>;<br>    <br>    consumer:repeat<br>        ...<br>        p(full);<br>        p(mutex);<br>        <span class="hljs-built_in">remove</span> an item from <span class="hljs-built_in">buffer</span> to nextc;<br>        释放缓冲区<br>        V(mutex);<br>        P(empty);<br>        ...<br>        consume the item in nextc;<br>        ...<br>        until <span class="hljs-literal">false</span>;<br>Parend<br></code></pre></td></tr></table></figure><h2 id="读者写者"><a href="#读者写者" class="headerlink" title="读者写者"></a>读者写者</h2><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++">semaphore mutex:=<span class="hljs-number">1</span>,wrt:=<span class="hljs-number">1</span>;<br><span class="hljs-keyword">int</span> readcount:=<span class="hljs-number">0</span>;<br>Parbegin:<br>    Writer:repeat<br>        P(wrt);<br>        写数据<br>        V(wrt);<br>    <br>    Reader:repeat<br>        P(mutex);<br>        readcount:=readcount+<span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">if</span> readcount:=<span class="hljs-number">1</span> then P(wrt);<br>        V(mutex);<br>        读数据<br>        P(mutex);<br>        readcount:=readcount<span class="hljs-number">-1</span>;<br>        <span class="hljs-keyword">if</span> readcount=<span class="hljs-number">0</span> then V(wrt);<br>        V(mutex);<br>Parend<br></code></pre></td></tr></table></figure><h2 id="哲学家问题"><a href="#哲学家问题" class="headerlink" title="哲学家问题"></a>哲学家问题</h2><figure class="highlight c++"><table><tr><td class="code"><pre><code class="hljs c++">semaphore chopstick[<span class="hljs-number">5</span>];<span class="hljs-comment">//初始信号量都为1</span><br>第i个进程描述为(i=<span class="hljs-number">0</span>,… ,<span class="hljs-number">4</span>)<br>   repeat<br>  P(chopstick[i]);<br>  P(chopstick[(i+<span class="hljs-number">1</span>) mod <span class="hljs-number">5</span>]);<br>  吃<br>  V(chopstick[i]);<br>  V(Chopstick[(i+<span class="hljs-number">1</span>) mod <span class="hljs-number">5</span>];<br>  思考<br>   until <span class="hljs-literal">false</span>;<br></code></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;理发师问题&quot;&gt;&lt;a href=&quot;#理发师问题&quot; class=&quot;headerlink&quot; title=&quot;理发师问题&quot;&gt;&lt;/a&gt;理发师问题&lt;/h2&gt;&lt;p&gt;7.8 The Sleeping-Barber Problem. A barbershop consists of a waiting room with n chairs and the barber room containing the barber chair. If there are no customers to be served,the barber goes to sleep. If a customer enters the barbershop and all chairs are occupied, then the customer leaves the shop.If the barber is busy but chairs are available, then the customer sits in one of the free chairs. If the barber is asleep, the customer wakes up the barber. Write a program to coordinate the barber and the customers.&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="操作系统" scheme="https://yoursite.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>数据库复习题</title>
    <link href="https://yoursite.com/2020/11/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%8D%E4%B9%A0%E9%A2%98/"/>
    <id>https://yoursite.com/2020/11/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%8D%E4%B9%A0%E9%A2%98/</id>
    <published>2020-11-01T11:16:40.000Z</published>
    <updated>2021-01-19T04:31:32.146Z</updated>
    
    <content type="html"><![CDATA[<h2 id="复习题"><a href="#复习题" class="headerlink" title="复习题"></a>复习题</h2><p>Use only the INVENTORY table to answer Review Questions 2.17 through 2.40:</p><a id="more"></a><p>2.17 Write an SQL statement to display SKU and SKU_Description.</p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> SKU,SKU_Description <span class="hljs-keyword">FROM</span> INVENTORY;<br></code></pre></td></tr></table></figure><p>2.18    Write an SQL statement to display SKU_Description and SKU.</p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> SKU_Description,SKU <span class="hljs-keyword">FROM</span> INVENTORY;<br></code></pre></td></tr></table></figure><p>2.19    Write an SQL statement to display WarehouseID.</p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> WarehouseID <span class="hljs-keyword">FROM</span> INVENTORY;<br></code></pre></td></tr></table></figure><p>2.20    Write an SQL statement to display unique WarehouseIDs.</p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> <span class="hljs-keyword">DISTINCT</span> WarehouseID <span class="hljs-keyword">FROM</span> INVENTORY;<br></code></pre></td></tr></table></figure><p>2.26    Write an SQL statement to display the SKU, SKU_Description, and WarehouseID for products that have a QuantityOnHand greater than 0. Sort the results in descending order by WarehouseID and in ascending order by SKU.</p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> SKU, SKU_Description, WarehouseID<br><span class="hljs-keyword">FROM</span> INVENTORY<br><span class="hljs-keyword">WHERE</span> QuantityOnHand&gt;<span class="hljs-number">0</span><br><span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> WarehouseID <span class="hljs-keyword">DESC</span>, SKU <span class="hljs-keyword">ASC</span>;<br></code></pre></td></tr></table></figure><p>2.29 Write an SQL statement to display the SKU, SKU_Description, WarehouseID, and QuantityOnHand for all products having a QuantityOnHand greater than 1 and less than 10. Do not use the BETWEEN keyword. </p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> SKU, SKU_Description, WarehouseID, QuantityOnHand<br><span class="hljs-keyword">FROM</span> INVENTORY<br><span class="hljs-keyword">WHERE</span> QuantityOnHand&gt;<span class="hljs-number">1</span> <span class="hljs-keyword">AND</span> QuantityOnOrder&lt;<span class="hljs-number">10</span>;<br></code></pre></td></tr></table></figure><p>2.36    Write an SQL statement to display the WarehouseID and the sum of QuantityOnHand,grouped by WarehouseID. Name the sum TotalItemsOnHand and display the results in descending order of TotalItemsOnHand.</p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> WarehouseID , <span class="hljs-keyword">SUM</span> (QuantityOnHand) <span class="hljs-keyword">AS</span> TotalItamsOnHand<br><span class="hljs-keyword">FROM</span> INVENTORY<br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> WarehouseID<br><span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> TotalItemsOnHand <span class="hljs-keyword">DESC</span>;<br></code></pre></td></tr></table></figure><p><strong>2.37 Write an SQL statement to display the WarehouseID and the sum of QuantityOnHand, grouped by WarehouseID. Omit all SKU items that have 3 or more items on hand from the sum, and name the sum TotalItemsOnHandLT3 and display the results in descending order of TotalItemsOnHandLT3.</strong> </p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> WarehouseID , <span class="hljs-keyword">SUM</span> (QuantityOnHand) <span class="hljs-keyword">AS</span> TotalItamsOnHandLT3<br><span class="hljs-keyword">FROM</span> INVENTORY<br><span class="hljs-keyword">WHERE</span> QuantityOnHand&lt;<span class="hljs-number">3</span><br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> WarehouseID<br><span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> TotalItemsOnHandLT3 <span class="hljs-keyword">DESC</span>;<br></code></pre></td></tr></table></figure><p><strong>2.38 Write an SQL statement to display the WarehouseID and the sum of QuantityOnHand grouped by WarehouseID. Omit all SKU items that have 3 or more items on hand from the sum, and name the sum TotalItemsOnHandLT3. Show WarehouseID only for warehouses having fewer than 2 SKUs in their TotalItemesOnHandLT3 and display the results in descending order of TotalItemsOnHandLT3.</strong></p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> WarehouseID , <span class="hljs-keyword">SUM</span> (QuantityOnHand) <span class="hljs-keyword">AS</span> TotalItamsOnHandLT3,<br><span class="hljs-keyword">FROM</span> INVENTORY<br><span class="hljs-keyword">WHERE</span> QuantityOnHand &lt;<span class="hljs-number">3</span><br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> WarehouseID<br><span class="hljs-keyword">HAVING</span> <span class="hljs-keyword">COUNT</span>(*)&lt;<span class="hljs-number">2</span><br><span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> TotalItemsOnHandLT3 <span class="hljs-keyword">DESC</span>;<br></code></pre></td></tr></table></figure><p>Use both the INVENTORY and WAREHOUSE tables to answer Review Questions 2.40 through 2.52: </p><p>2.42 Write an SQL statement to display the SKU, SKU_Description, WarehouseID, Ware-houseCity, and WarehouseState of all items not stored in the Atlanta, Bangor, or Chicago warehouse. Do not use the NOT IN keyword. </p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> SKU, SKU_Description, INVENTORY.WarehouseID, WarehouseCity, WarehouseState<br><span class="hljs-keyword">FROM</span> INVENTORY, WAREHOUSE<br><span class="hljs-keyword">WHERE</span> INVENTORY.WarehouseID=WAREHOUSE.WarehouseID <span class="hljs-keyword">AND</span> WarehouseCity!=<span class="hljs-string">'Atlanta'</span> <span class="hljs-keyword">AND</span> WarehouseCity!=<span class="hljs-string">'Chicago'</span> <span class="hljs-keyword">AND</span> WarehouseCity!=<span class="hljs-string">'Bangor'</span>;<br></code></pre></td></tr></table></figure><p>2.44 Write an SQL statement to produce a single column called ItemLocation that combines the SKU_Description, the phrase “is in a warehouse in”, and WarehouseCity. Do not be concerned with removing leading or trailing blanks. </p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> <span class="hljs-keyword">DISTINCT</span> <span class="hljs-keyword">RTRIM</span>(SKU_Description)+ <span class="hljs-string">'is in a warehouse'</span> + <span class="hljs-keyword">RTRIM</span>(WarehouseCity) <span class="hljs-keyword">AS</span> ItemLocation<br><span class="hljs-keyword">FROM</span> INVENTORY, WAREHOUSE <span class="hljs-keyword">WHERE</span> INVENTORY.WarehouseID=WAREHOUSE.WarehouseID;<br></code></pre></td></tr></table></figure><p>2.45 Write an SQL statement to show the SKU, SKU_Description, WarehouseID for all items stored in a warehouse managed by ‘Lucille Smith’. Use a subquery.</p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> SKU, SKU_Description, WarehouseID<br><span class="hljs-keyword">FROM</span> INVENTORY<br><span class="hljs-keyword">WHERE</span> WarehouseID <span class="hljs-keyword">IN</span> (<span class="hljs-keyword">SELECT</span> WarehouseID<br><span class="hljs-keyword">FROM</span> WAREHOUSE <span class="hljs-keyword">WHERE</span> Manager=<span class="hljs-string">'Lucille Smith'</span>);<br></code></pre></td></tr></table></figure><p>2.46 Write an SQL statement to show the SKU, SKU_Description, WarehouseID for all items stored in a warehouse managed by ‘Lucille Smith’. Use a join. </p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> SKU, SKU_Description, INVENTORY.WarehouseID<br><span class="hljs-keyword">FROM</span> INVENTORY, WAREHOUSE<br><span class="hljs-keyword">WHERE</span> INVENTORY.WarehouseID=WAREHOUSE.WarehouseID <span class="hljs-keyword">AND</span> WAREHOUSE.Manager= <span class="hljs-string">'Lucille Smith'</span>;<br></code></pre></td></tr></table></figure><p>2.50 Write an SQL statement to show the WarehouseID and average QuantityOnHand of all items stored in a warehouse managed by ‘Lucille Smith’. Use a join using JOIN ON syntax.</p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> INVENTORY.WarehouseID, <span class="hljs-keyword">AVG</span>(QuantityOnHand)<br><span class="hljs-keyword">FROM</span> INVENTORY <span class="hljs-keyword">JOIN</span> WAREHOUSE<br><span class="hljs-keyword">ON</span> INVENTORY.WarehouseID=WAREHOUSE.WarehouseID <br><span class="hljs-keyword">WHERE</span> WAREHOUSE.Manager=<span class="hljs-string">'Lucille Smith'</span>;<br></code></pre></td></tr></table></figure><p>2.55 Write an SQL statement to join WAREHOUSE and INVENTORY and include all rows of WAREHOUSE in your answer, regardless of whether they have any INVENTORY. Run this statement.</p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> *<br><span class="hljs-keyword">FROM</span> WAREHOUSE <span class="hljs-keyword">LEFT</span> <span class="hljs-keyword">OUTER</span> <span class="hljs-keyword">JOIN</span> INWENTORY <br><span class="hljs-keyword">ON</span> INVENTORY.WarehouseID=WAREHOUSE.WarehouseID;<br></code></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;复习题&quot;&gt;&lt;a href=&quot;#复习题&quot; class=&quot;headerlink&quot; title=&quot;复习题&quot;&gt;&lt;/a&gt;复习题&lt;/h2&gt;&lt;p&gt;Use only the INVENTORY table to answer Review Questions 2.17 through 2.40:&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据库系统" scheme="https://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>词法分析</title>
    <link href="https://yoursite.com/2020/10/15/%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/"/>
    <id>https://yoursite.com/2020/10/15/%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90/</id>
    <published>2020-10-15T08:43:51.000Z</published>
    <updated>2021-01-19T04:31:32.997Z</updated>
    
    <content type="html"><![CDATA[<p><strong>词法分析是编译的第一个阶段，它的主要任务是从左到右逐个字符地对源程序进行扫描，产生一个个单词序列，用于语法分析。</strong><br>单词符号一般分为5类：关键字，标识符，常数，运算符，界符。</p><h2 id="正规文法"><a href="#正规文法" class="headerlink" title="正规文法"></a>正规文法</h2><p>正规文法也称三型文法$G=(V_N,V_T,S,P)$，其P中的每一条规则都有下面的形式：$A \rightarrow aB$或者$A \rightarrow a$,其中$A,B \in V_N , a \in V_T^*$关键字也是一种单词，一般关键字都是由字母构成的。</p><p>正规式又称正则表达式</p><h2 id="DFA——确定的有穷自动机"><a href="#DFA——确定的有穷自动机" class="headerlink" title="DFA——确定的有穷自动机"></a>DFA——确定的有穷自动机</h2><h2 id="NFA——不确定的有穷自动机"><a href="#NFA——不确定的有穷自动机" class="headerlink" title="NFA——不确定的有穷自动机"></a>NFA——不确定的有穷自动机</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;词法分析是编译的第一个阶段，它的主要任务是从左到右逐个字符地对源程序进行扫描，产生一个个单词序列，用于语法分析。&lt;/strong&gt;&lt;br&gt;单词符号一般分为5类：关键字，标识符，常数，运算符，界符。&lt;/p&gt;
&lt;h2 id=&quot;正规文法&quot;&gt;&lt;a href=&quot;#正规
      
    
    </summary>
    
    
    
      <category term="编译原理" scheme="https://yoursite.com/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>人人都是产品经理读后感</title>
    <link href="https://yoursite.com/2020/10/13/%E4%BA%BA%E4%BA%BA%E9%83%BD%E6%98%AF%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86%E8%AF%BB%E5%90%8E%E6%84%9F/"/>
    <id>https://yoursite.com/2020/10/13/%E4%BA%BA%E4%BA%BA%E9%83%BD%E6%98%AF%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86%E8%AF%BB%E5%90%8E%E6%84%9F/</id>
    <published>2020-10-13T09:16:09.000Z</published>
    <updated>2021-01-19T04:31:32.697Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>大三上时间也挺快的，这一晃就过了一个月了，发生的事情其实也不少，每天都被暑假自闭，综合测评，课程知识作业所干扰，有时候还出现了一些人际关系的问题，没有很沉下心去学习吧，不过好在leetcode刷题和github打卡还有更新博客的计划还是坚持了下来（虽然前天修改奖学金材料和班级体申报书断了😥，都怪dj！😡），这学期选了软件需求工程这门课，我觉得老师布置的作业和实验都十分有趣，虽然说如果要做好的话确实花一些时间，不过我还是觉得这个课程确实值得去学习和认真完成，而且也是我想要去学习的，正好布置了这样一个作业，我就当博客写写吧。</p><h2 id="人人都是产品经理读后感"><a href="#人人都是产品经理读后感" class="headerlink" title="人人都是产品经理读后感"></a>人人都是产品经理读后感</h2><p>其实说到产品经理，应该大部分的人都觉得这可能是个轻松的工作，其实我在读这本书之前我也是这么认为的，读了以后我才知道产品经理其实也是一个很考验设计和协调能力的职业，需要掌握的技能也不比技术人员简单。</p><h2 id="其实，你的灵魂深处也有一个“大卫”，而你就是自己的米开朗基罗"><a href="#其实，你的灵魂深处也有一个“大卫”，而你就是自己的米开朗基罗" class="headerlink" title="其实，你的灵魂深处也有一个“大卫”，而你就是自己的米开朗基罗"></a>其实，你的灵魂深处也有一个“大卫”，而你就是自己的米开朗基罗</h2><a id="more"></a><p>一开始我就被这句话吸引了，这也是这本书的初衷吧，人人都是产品经理，如果把每个人的一生看做一个产品，那么你已经设计了将近 20 年，一锤又一锤，在召唤着你灵魂深处的那个“大卫”——产品经理，没错，他是原先就存在的，并不是谁刻意雕琢的，所以作者一开始就表示出了每个人都有当产品经理的品质，其实我想别的专业也一样吧，主要还是事在人为，如果真的对某一样职业或者运动有自己强烈的愿望，那么不妨用你自己的方式去解读和学习将他做到极致，从而雕刻出你想要呈现的模样。</p><h2 id="人人都是产品经理-≠-人人都喜欢做产品经理"><a href="#人人都是产品经理-≠-人人都喜欢做产品经理" class="headerlink" title="人人都是产品经理 ≠ 人人都喜欢做产品经理"></a>人人都是产品经理 ≠ 人人都喜欢做产品经理</h2><p>同时作者其实谈到了一个很重要的问题，那就是自己是否真的喜欢做产品，他讲的很好：<strong>你说自己喜欢产品，到底是喜欢做用户，还是喜欢做产品经理？</strong>，作者谈到了作为用户和产品经理两者的差距，当你对一个产品感兴趣的时候，回想一下脑中萦绕的问题是站在用户的角度，还是站在产品经理的角度。</p><p>通常，用户会去想怎么用这个产品，才能带给自己更大的好处，产生更大的效用；而产品经理则习惯于绕过表象，从背后看问题的本质，思考怎么设计这个产品才能更好地平衡用户目标与商业目标。所以说这两者的区别还是很大的，作为产品经理不仅需要考虑产品的用户体验，还得在获得口碑的前提下达到商业的目标，所以说这个职业还是很难的。</p><h2 id="文档规范化处理"><a href="#文档规范化处理" class="headerlink" title="文档规范化处理"></a>文档规范化处理</h2><p>其实这一点是在我们这本书里面提到比较多的一个方面，需求获取，产品研究，然后由产品经理处理成规范详细的文档，然后交给技术人员去实现，不要小看这一步，这一步做的好的话，其实能节省很多不必要的麻烦和功能设计上的问题，减少返工的次数。<br>文档规范化处理，其实用到了很多我们上学期学到的软件工程的知识，UML建模设计，类图，用例规约，office三件套，不要小看这些内容，其实我觉得文字功底也是作为一个产品或者技术人员必备的技能。</p><p>一个好的产品经理，必然需要有很强的需求概括描述，需求可行性分析和产品修正能力，这样才能更好的和技术人员进行沟通，更高效的完成任务，<strong>同时不要以为技术人员就不必要掌握这些技能，其实这些技能对程序员也是很有用的。</strong></p><p>一个好的技术人员能够从需求中快速构建出自己的解决方案，从而写出对应的技术文档，这样才能更便于团队开发，帮助同事了解这些内容，而且成熟凝练的文字和博文，也是一种自己能力的体现，也能体现出你的技术水平，而且我也打过好几个开发比赛，大学生打比赛也经常要写技术文档，所以还是需要去了解这些方面的知识，然后把他们灵活运用到这个上面。总的来说，这一套规范其实是我们作为互联网从业人员必备的一种技能吧，也值得我们掌握。</p><h2 id="产品经理的自我修养，也是每个职业的自我修养"><a href="#产品经理的自我修养，也是每个职业的自我修养" class="headerlink" title="产品经理的自我修养，也是每个职业的自我修养"></a>产品经理的自我修养，也是每个职业的自我修养</h2><p>前面的章节主要谈论的是关于技术细节的问题，虽然这些知识和技能是我们必备的，不过相比写需求文档和产品经理的成长路线，我还是更喜欢成为一名拥有炫酷技术能力的工程师，但是在这里我更关注的是，产品经理的自我修养和调整，这个我认为不管是技术员还是产品经理，或者是其他专业，其实都是可以学习的一些生活经验吧，而且它里面提到的那几个方面，<strong>爱生活，有理想，会思考，能沟通，产品经理主义</strong>都是非常有用的。</p><p>先说<strong>爱生活</strong>好了，作为产品经理，生活经验和细节能给他带来很多的灵感，其实很多时候我们去寻找需求，就是去感受用户体验，体会生活，观察生活中的小细节，所以一个热爱生活，擅于从生活中发现奇妙，乐观积极的人会很敏锐地察觉到很多常人或者说普通用户没有感觉到的小问题。<br>正如作者所说：<br><strong>一个人只有拥有了积极、乐观、向上的人生态度，内心才会有爱，才会去积极发现生活中的美，才会有好奇心和创造力，才会愿意研究生活中的产品，才会爱上做产品这样一件改变世界的事情。</strong><br>其实其他的部门和行业也是一样，不管是什么职业，热爱生活是最重要的，如果一个人总是埋怨生活，抱怨自己遇到的各种不顺，工作上的压力，那么他肯定是不快乐的，其实这种消极的情绪很多时候会影响我们做事情的效率，尤其是对于编程这种行业，有时候真的不能急躁，一定要静下心来思考，慢慢来，一步一步踏踏实实做好。</p><p><strong>有理想</strong>这点其实对我来说的话就是有一个<strong>清晰的规划</strong>吧，这样才能使得我们在奋斗路上不会迷失方向，然后有了明确的计划和方向，我们才能更加坚定的走我们自己的道路。</p><p>其实到大三，我自己也是有一些迷茫的，虽然说目前的状况相对其他同学要好一点。不过这里先给大家提个醒，<strong>不要做很多的从0到1，要做1到100</strong>，之前做了太多的0-1的工作，其实这样是不太好了，身边的同学有一些对方向比较坚决的同学，有些已经学到了很深的水准，自己也因为比赛失误等等各种各样的原因导致自己对自己的能力开始怀疑，不过话说回来，说这些原因无非是给自己找了一些客观原因，想想自己其实还是有比较高的目标和理想的，所以慢慢的尝试和走出那些困扰就好了，<strong>正如马云说的，梦想还是要有的，万一那天就实现了呢。</strong></p><p><strong>思考和沟通</strong>，这两点其实也是我们作为技术人员比较缺乏的一点吧，其实有很多的技术员，在交流上存在一些障碍，思考的时候也经常犯一些经验性的错误，其实反观成功人士，他们在这个方面是做的很好的，说话的艺术真的很重要，不管是在我们的生活中，还是工作上，现在很多的项目都不是一个人单干能做完的任务，所以这个时候交流的作用就很重要了。</p><p>这个其实我自己也有很多体会，我也参加过各种各样的比赛，有时候虽然我们大家都觉得自己理解了对方的思路，其实有时候还是有一些偏差的，所以经常导致了接口测试的时候出现了很多的问题，而这时候如果有一个会沟通，思维能力强的产品经理，在解决这种矛盾的时候是十分得心应手的，而且能够把这种事情处理的十分合理，<strong>这就是产品经理的魅力所在，也是能力的表现。</strong></p><p>技术人员如果能掌握好这个技巧的话，就能更好的带领团队更高效的实现任务需求，其实我认为这也是一种技术人员转型做管理层和设计师的潜质，这也是我自己为什么会选择大学去当班长去锻炼这种能力的原因，<strong>从某种意义上来说，处理人与人之间的矛盾其实比修补产品bug有时候要更为重要。</strong></p><p>写到这已经差不多凌晨1点半了吧，最近真的是太累了，课程也越来越难，还有比赛，自己要学的东西，班级事务，总是想把每一件事情都安排好然后花时间去做好，但计划总赶不上变化，有时候再加上自己的一点惰性，就很难把事情处理好了，希望以后能早睡早起给，改掉这些毛病，明天又是新的开始了，希望我能继续保持作者提到的这些自我修养，然后继续前进，<strong>爱你所爱，行你所行，无问西东</strong>。</p><p><strong>附：</strong><a href="https://khany.top/file/%E4%BA%BA%E4%BA%BA%E9%83%BD%E6%98%AF%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86.pdf" target="_blank" rel="noopener">《人人都是产品经理》的书籍下载链接</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;大三上时间也挺快的，这一晃就过了一个月了，发生的事情其实也不少，每天都被暑假自闭，综合测评，课程知识作业所干扰，有时候还出现了一些人际关系的问题，没有很沉下心去学习吧，不过好在leetcode刷题和github打卡还有更新博客的计划还是坚持了下来（虽然前天修改奖学金材料和班级体申报书断了😥，都怪dj！😡），这学期选了软件需求工程这门课，我觉得老师布置的作业和实验都十分有趣，虽然说如果要做好的话确实花一些时间，不过我还是觉得这个课程确实值得去学习和认真完成，而且也是我想要去学习的，正好布置了这样一个作业，我就当博客写写吧。&lt;/p&gt;
&lt;h2 id=&quot;人人都是产品经理读后感&quot;&gt;&lt;a href=&quot;#人人都是产品经理读后感&quot; class=&quot;headerlink&quot; title=&quot;人人都是产品经理读后感&quot;&gt;&lt;/a&gt;人人都是产品经理读后感&lt;/h2&gt;&lt;p&gt;其实说到产品经理，应该大部分的人都觉得这可能是个轻松的工作，其实我在读这本书之前我也是这么认为的，读了以后我才知道产品经理其实也是一个很考验设计和协调能力的职业，需要掌握的技能也不比技术人员简单。&lt;/p&gt;
&lt;h2 id=&quot;其实，你的灵魂深处也有一个“大卫”，而你就是自己的米开朗基罗&quot;&gt;&lt;a href=&quot;#其实，你的灵魂深处也有一个“大卫”，而你就是自己的米开朗基罗&quot; class=&quot;headerlink&quot; title=&quot;其实，你的灵魂深处也有一个“大卫”，而你就是自己的米开朗基罗&quot;&gt;&lt;/a&gt;其实，你的灵魂深处也有一个“大卫”，而你就是自己的米开朗基罗&lt;/h2&gt;
    
    </summary>
    
    
    
      <category term="youth" scheme="https://yoursite.com/tags/youth/"/>
    
  </entry>
  
  <entry>
    <title>中断异常与系统调用</title>
    <link href="https://yoursite.com/2020/10/03/%E4%B8%AD%E6%96%AD%E5%BC%82%E5%B8%B8%E4%B8%8E%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/"/>
    <id>https://yoursite.com/2020/10/03/%E4%B8%AD%E6%96%AD%E5%BC%82%E5%B8%B8%E4%B8%8E%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/</id>
    <published>2020-10-03T14:51:56.000Z</published>
    <updated>2021-01-19T04:31:32.120Z</updated>
    
    <content type="html"><![CDATA[<p>通常操作系统提供的主要功能都是由内核程序实现的，处理机在运行上层程序时，能进入操作系统内核运行的<strong>唯一途径</strong>就是中断或者异常。</p><h2 id="中断和异常基本概念"><a href="#中断和异常基本概念" class="headerlink" title="中断和异常基本概念"></a>中断和异常基本概念</h2><p>中断(Interruption)：也称外中断，指来自处理机执行指令以外的事件发生。<br>异常(Exception)：也称内中断、例外、自陷(trap),指源自处理机执行指令内部的事件。</p><a id="more"></a><p>常见中断类型：<br>中断：I/O中断，时钟中断。<br>异常：系统调用（具体指系统调用当中的自陷指令），缺页异常，断点指令，其他程序性异常（如：算术溢出）</p><p>中断: 与正执行指令无关，可以屏蔽；<br>异常: 与正执行指令有关，不可屏蔽</p><p>中断屏蔽：指禁止处理机响应中断或禁止中断出现.<br>中断屏蔽有两种方法:<br>1.硬件实现(由软件置处理机优先级,硬件按系统设计时的约定,屏蔽那些低优先级中断);<br>2.软件实现(由软件按操作系统优先级约定,设置屏蔽寄存器)。<br><img src="https://img-blog.csdnimg.cn/20201003231734304.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p><img src="https://img-blog.csdnimg.cn/20201003222007777.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><h2 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h2><p>系统调用：操作系统内核程序和用户态运行程序之间的接口。<br>凡是涉及操作系统核心管理资源的操作必须由系统调用实现。<br><img src="https://img-blog.csdnimg.cn/20201003222258334.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>1.主要系统调用<br>进程管理:</p><ul><li>创建进程   pid=fork( )</li><li>终止进程   exit(status)</li><li>等待子进程结束  pid=waitpid(pid,…)</li><li>替换进程映像  s=execve(name,…)</li></ul><p>文件管理:</p><ul><li>创建文件 fd=creat(name,…)</li><li>打开文件 fd=open(name,…)</li><li>读文件  n=read(fd,buffer,nbyte)</li><li>写文件 n=write(fd,buffer,nbyte)</li><li>移动文件指针 pos=lseek(fd,offset,…)</li><li>关闭文件 s=close(fd)</li></ul><p>存储管理：动态申请/释放存储空间等；<br>其他：设置/获得时间等。</p><p>2.自陷指令(trap)<br>系统调用是一种特殊形式的转子程序方法,它导致处理机态的变化,为了方便编程，一般提供系统调用库，由其中的子程序来组织系统调用,用户程序调系统调用库的子程序。<br>参数传递的一般形式如下：<br>1）用寄存器传递参数。<br>2）Trap指令自带参数。Trap指令是一条长指令,内核通过断点pc值加偏移获得参数。</p><p><img src="https://img-blog.csdnimg.cn/20201003222258334.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><p><img src="https://img-blog.csdnimg.cn/20201003224710968.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通常操作系统提供的主要功能都是由内核程序实现的，处理机在运行上层程序时，能进入操作系统内核运行的&lt;strong&gt;唯一途径&lt;/strong&gt;就是中断或者异常。&lt;/p&gt;
&lt;h2 id=&quot;中断和异常基本概念&quot;&gt;&lt;a href=&quot;#中断和异常基本概念&quot; class=&quot;headerlink&quot; title=&quot;中断和异常基本概念&quot;&gt;&lt;/a&gt;中断和异常基本概念&lt;/h2&gt;&lt;p&gt;中断(Interruption)：也称外中断，指来自处理机执行指令以外的事件发生。&lt;br&gt;异常(Exception)：也称内中断、例外、自陷(trap),指源自处理机执行指令内部的事件。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="操作系统" scheme="https://yoursite.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>操作系统的运行机制和体系结构</title>
    <link href="https://yoursite.com/2020/10/03/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6%E5%92%8C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
    <id>https://yoursite.com/2020/10/03/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6%E5%92%8C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/</id>
    <published>2020-10-03T13:37:16.000Z</published>
    <updated>2021-01-19T04:31:33.168Z</updated>
    
    <content type="html"><![CDATA[<p>操作系统比较硬核，不过最近发现了<a href="https://www.bilibili.com/video/BV1YE411D7nH?p=6" target="_blank" rel="noopener">王道考研</a>这个比较好的课程。这里是一些学习笔记总结。</p><a id="more"></a><h2 id="主要功能模块"><a href="#主要功能模块" class="headerlink" title="主要功能模块"></a>主要功能模块</h2><p>操作系统核心的主要功能模块介绍如下：<br><strong>系统初始化模块</strong>：准备系统运行环境，最后为每个终端创建一个进程，运行命令解释程序。</p><p><strong>进程管理模块</strong>：处理进程类系统调用（如进程创建/结束等）和进程调度。</p><p><strong>存储管理模块</strong>：配合进程管理，分配进程空间；处理存储类系统调用（如动态增加进程空间）；在虚存系统缺页异常时调入页面进行处理。</p><p><strong>文件管理模块</strong>：处理文件类系统调用。</p><p><strong>外设管理模块</strong>：负责外设驱动和中断处理。</p><h2 id="两种处理机状态"><a href="#两种处理机状态" class="headerlink" title="两种处理机状态"></a>两种处理机状态</h2><p>处理机的运行状态分为核心态（管态）和用户态（目态），我们使用处理机状态字（简称PS或者PSW）寄存器内设置一个标志位，根据祺当前值为1或0表示处理机处于核心态或者用户态。<br>管态：允许特权指令执行的状态，由此状态下地址空间也比较大。<br><img src="https://img-blog.csdnimg.cn/20201003213936235.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="2"></p><h2 id="两者指令"><a href="#两者指令" class="headerlink" title="两者指令"></a>两者指令</h2><p>特权指令不允许在用户态下执行。<br>特权指令的功能：</p><ol><li>允许和禁止中断</li><li>在进程之间切换处理</li><li>存取用于内存保护的寄存器</li><li>执行I/O操作</li><li>停止一个中央处理机的工作<br><img src="https://img-blog.csdnimg.cn/20201003214212924.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="1"></li></ol><h2 id="两种程序"><a href="#两种程序" class="headerlink" title="两种程序"></a>两种程序</h2><p><img src="https://img-blog.csdnimg.cn/20201003214352505.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="3"></p><h2 id="操作系统的内核"><a href="#操作系统的内核" class="headerlink" title="操作系统的内核"></a>操作系统的内核</h2><p><strong>内核</strong>是计算机上配置的底层软件，是操作系统最基本、最核心的部分。实现操作系统内核功能的那些程序就是<strong>内核程序</strong>。<br>这里其实还确实了一种，我们常说的操作系统四大模块是指，<strong>进程管理，存储管理，设备管理和文件系统管理。</strong><br><img src="https://img-blog.csdnimg.cn/20201003214807141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="4"><br>由此引出了我们操作系统的两种内核：<strong>大内核和微内核。</strong></p><table><thead><tr><th align="center">大内核</th><th align="center">微内核</th></tr></thead><tbody><tr><td align="center">将操作系统的主要功能都作为系统内核，运行在核心态</td><td align="center">只把最基本的功能保留</td></tr><tr><td align="center">优点：高性能</td><td align="center">优点：内核功能少，结构清晰，方便维护</td></tr><tr><td align="center">缺点：内核代码庞大，结构混乱，难以维护</td><td align="center">缺点：需要频繁地在用户态和核心态之间切换，性能低</td></tr></tbody></table><p><img src="https://img-blog.csdnimg.cn/20201003215121301.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;操作系统比较硬核，不过最近发现了&lt;a href=&quot;https://www.bilibili.com/video/BV1YE411D7nH?p=6&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;王道考研&lt;/a&gt;这个比较好的课程。这里是一些学习笔记总结。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="操作系统" scheme="https://yoursite.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>js基础——关于对象</title>
    <link href="https://yoursite.com/2020/10/02/js%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%94%E5%85%B3%E4%BA%8E%E5%AF%B9%E8%B1%A1/"/>
    <id>https://yoursite.com/2020/10/02/js%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%94%E5%85%B3%E4%BA%8E%E5%AF%B9%E8%B1%A1/</id>
    <published>2020-10-02T08:03:30.000Z</published>
    <updated>2021-01-19T04:31:34.554Z</updated>
    
    <content type="html"><![CDATA[<h2 id="对象与属性"><a href="#对象与属性" class="headerlink" title="对象与属性"></a>对象与属性</h2><p>同其他语言里面所描述的对象一样，在js里，一个对象就是一系列属性的集合，一个属性包含一个名和一个值。一个属性的值可以是函数，这种情况下属性也被称为方法。一个对象的属性可以被解释成一个附加到对象上的变量。对象有时也被叫作<strong>关联数组</strong>, 因为每个属性都有一个用于访问它的<strong>字符串值</strong>。</p><a id="more"></a><p>属性的访问设置与修改主要是通过两种手段实现，一种是通过点号对变量进行调用，一种是通过方括号的方式访问，其中通过方括号的方式是一种动态判定法(属性名只有到运行时才能判定)。</p><p>一个对象的属性名可以是任何有效的 JavaScript 字符串，或者可以被转换为字符串的任何类型，<strong>包括空字符串</strong>。然而，一个属性的名称如果不是一个有效的 JavaScript 标识符（例如，一个由空格或连字符，或者以数字开头的属性名），<strong>就只能通过方括号标记访问。</strong></p><p>方括号中的所有键都将转换为字符串类型，因为JavaScript中的对象只能使用<code>String</code>类型作为键类型,如果是<code>object</code>类型的话，也可以通过方括号直接添加属性，不过他添加属性的时候会调用<code>toString()</code>方法，并将其作为新的key值。</p><p>你可以在<code>for...in</code>语句中使用方括号标记以枚举一个对象的所有属性</p><p><strong>拓展</strong>：从 ECMAScript 5 开始，有三种原生的方法用于列出或枚举对象的属性：</p><ul><li><strong>for…in循环</strong><br>该方法依次访问一个对象及其原型链中所有可枚举的属性。</li><li><strong>Object.keys(o)</strong><br>该方法返回对象 o 自身包含（不包括原型中）的所有可枚举属性的名称的数组。</li><li><strong>Object.getOwnPropertyNames(o)</strong><br>该方法返回对象 o 自身包含（不包括原型中）的所有属性(无论是否可枚举)的名称的数组。</li></ul><h2 id="创建新对象"><a href="#创建新对象" class="headerlink" title="创建新对象"></a>创建新对象</h2><p>JavaScript 拥有一系列预定义的对象，当然我们也可以自己创建对象，从  JavaScript 1.2 之后，你可以通过<strong>对象初始化器</strong>（Object Initializer）创建对象。或者你可以创建一个<strong>构造函数</strong>并使用该函数和<code>new</code>操作符初始化对象。</p><h4 id="使用对象初始化器"><a href="#使用对象初始化器" class="headerlink" title="使用对象初始化器"></a>使用对象初始化器</h4><p>使用对象初始化器也被称作通过字面值创建对象，通过对象初始化器创建对象的语法如下：</p><figure class="highlight js"><table><tr><td class="code"><pre><code class="hljs js"><span class="hljs-keyword">var</span> obj = &#123; <span class="hljs-attr">property_1</span>:   value_1,   <span class="hljs-comment">// property_# 可以是一个标识符...</span><br>            <span class="hljs-number">2</span>:            value_2,   <span class="hljs-comment">// 或一个数字...</span><br>           [<span class="hljs-string">"property"</span> +<span class="hljs-number">3</span>]: value_3,  <span class="hljs-comment">//  或一个可计算的key名... </span><br>            <span class="hljs-comment">// ...,</span><br>            <span class="hljs-string">"property n"</span>: value_n &#125;; <span class="hljs-comment">// 或一个字符串</span><br></code></pre></td></tr></table></figure><p>这里 <code>obj</code>是新对象的名称，每一个 <code>property_i</code> 是一个标识符（可以是一个名称、数字或字符串字面量），并且每个 <code>value_i</code> 是一个其值将被赋予 <code>property_i</code> 的表达式。<strong>obj 与赋值是可选的</strong>；</p><figure class="highlight js"><table><tr><td class="code"><pre><code class="hljs js"><span class="hljs-keyword">var</span> myHonda = &#123;<span class="hljs-attr">color</span>: <span class="hljs-string">"red"</span>, <span class="hljs-attr">wheels</span>: <span class="hljs-number">4</span>, <span class="hljs-attr">engine</span>: &#123;<span class="hljs-attr">cylinders</span>: <span class="hljs-number">4</span>, <span class="hljs-attr">size</span>: <span class="hljs-number">2.2</span>&#125;&#125;;<span class="hljs-comment">//这里面的engine也是一个对象</span><br></code></pre></td></tr></table></figure><h4 id="使用构造函数"><a href="#使用构造函数" class="headerlink" title="使用构造函数"></a>使用构造函数</h4><p>使用构造函数实例化对象的过程分为两步：</p><ol><li>通过创建一个构造函数来定义对象的类型。首字母大写是非常普遍而且很恰当的惯用法。</li><li>通过 <code>new</code> 创建对象实例。</li></ol><h4 id="使用-Object-create-方法"><a href="#使用-Object-create-方法" class="headerlink" title="使用 Object.create 方法"></a>使用 Object.create 方法</h4><p>对象也可以用 <code>Object.create()</code> 方法创建。该方法非常有用，因为它允许你为创建的对象选择一个原型对象，而不用定义构造函数。</p><figure class="highlight js"><table><tr><td class="code"><pre><code class="hljs js"><span class="hljs-comment">// Animal properties and method encapsulation</span><br><span class="hljs-keyword">var</span> Animal = &#123;<br>  type: <span class="hljs-string">"Invertebrates"</span>, <span class="hljs-comment">// 属性默认值</span><br>  displayType : <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>) </span>&#123;  <span class="hljs-comment">// 用于显示type属性的方法</span><br>    <span class="hljs-built_in">console</span>.log(<span class="hljs-keyword">this</span>.type);<br>  &#125;<br>&#125;<br><br><span class="hljs-comment">// 创建一种新的动物——animal1 </span><br><span class="hljs-keyword">var</span> animal1 = <span class="hljs-built_in">Object</span>.create(Animal);<br>animal1.displayType(); <span class="hljs-comment">// Output:Invertebrates</span><br><br><span class="hljs-comment">// 创建一种新的动物——Fishes</span><br><span class="hljs-keyword">var</span> fish = <span class="hljs-built_in">Object</span>.create(Animal);<br>fish.type = <span class="hljs-string">"Fishes"</span>;<br>fish.displayType(); <span class="hljs-comment">// Output:Fishes</span><br></code></pre></td></tr></table></figure><h2 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h2><p>所有的 JavaScript 对象至少继承于一个对象。<strong>被继承的对象被称作原型，并且继承的属性可通过构造函数的<code>prototype</code>对象找到。</strong></p><h2 id="为对象类型定义属性"><a href="#为对象类型定义属性" class="headerlink" title="为对象类型定义属性"></a>为对象类型定义属性</h2><p>你可以通过 prototype 属性为之前定义的对象类型增加属性。这为该类型的所有对象，而不是仅仅一个对象增加了一个属性。下面的代码为所有类型为 car 的对象增加了 color 属性，然后为对象 car1 的 color 属性赋值：</p><figure class="highlight js"><table><tr><td class="code"><pre><code class="hljs js">Car.prototype.color = <span class="hljs-literal">null</span>;<br>car1.color = <span class="hljs-string">"black"</span>;<br></code></pre></td></tr></table></figure><h2 id="通过-this-引用对象"><a href="#通过-this-引用对象" class="headerlink" title="通过 this 引用对象"></a>通过 this 引用对象</h2><p>avaScript 有一个特殊的关键字 this，它可以在方法中使用以指代当前对象。</p><h2 id="删除属性"><a href="#删除属性" class="headerlink" title="删除属性"></a>删除属性</h2><p>你可以用<code>delete</code>操作符删除一个<strong>不是继承而来</strong>的属性。下面的例子说明如何删除一个属性：</p><figure class="highlight js"><table><tr><td class="code"><pre><code class="hljs js"><span class="hljs-comment">//Creates a new object, myobj, with two properties, a and b.</span><br><span class="hljs-keyword">var</span> myobj = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Object</span>;<br>myobj.a = <span class="hljs-number">5</span>;<br>myobj.b = <span class="hljs-number">12</span>;<br><br><span class="hljs-comment">//Removes the a property, leaving myobj with only the b property.</span><br><span class="hljs-keyword">delete</span> myobj.a;<br></code></pre></td></tr></table></figure><h2 id="比较对象"><a href="#比较对象" class="headerlink" title="比较对象"></a>比较对象</h2><p><strong>在 JavaScript 中 objects 是一种引用类型。两个独立声明的对象永远也不会相等，即使他们有相同的属性，只有在比较一个对象和这个对象的引用时，才会返回true.</strong><br>这边是官方给出的例子</p><figure class="highlight js"><table><tr><td class="code"><pre><code class="hljs js"><span class="hljs-comment">// 两个变量, 两个具有同样的属性、但不相同的对象</span><br><span class="hljs-keyword">var</span> fruit = &#123;<span class="hljs-attr">name</span>: <span class="hljs-string">"apple"</span>&#125;;<br><span class="hljs-keyword">var</span> fruitbear = &#123;<span class="hljs-attr">name</span>: <span class="hljs-string">"apple"</span>&#125;;<br><br>fruit == fruitbear <span class="hljs-comment">// return false</span><br>fruit === fruitbear <span class="hljs-comment">// return false</span><br></code></pre></td></tr></table></figure><figure class="highlight js"><table><tr><td class="code"><pre><code class="hljs js"><span class="hljs-comment">// 两个变量, 同一个对象</span><br><span class="hljs-keyword">var</span> fruit = &#123;<span class="hljs-attr">name</span>: <span class="hljs-string">"apple"</span>&#125;;<br><span class="hljs-keyword">var</span> fruitbear = fruit;  <span class="hljs-comment">// 将fruit的对象引用(reference)赋值给 fruitbear</span><br>                        <span class="hljs-comment">// 也称为将fruitbear“指向”fruit对象</span><br><span class="hljs-comment">// fruit与fruitbear都指向同样的对象</span><br>fruit == fruitbear <span class="hljs-comment">// return true</span><br>fruit === fruitbear <span class="hljs-comment">// return true</span><br></code></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;对象与属性&quot;&gt;&lt;a href=&quot;#对象与属性&quot; class=&quot;headerlink&quot; title=&quot;对象与属性&quot;&gt;&lt;/a&gt;对象与属性&lt;/h2&gt;&lt;p&gt;同其他语言里面所描述的对象一样，在js里，一个对象就是一系列属性的集合，一个属性包含一个名和一个值。一个属性的值可以是函数，这种情况下属性也被称为方法。一个对象的属性可以被解释成一个附加到对象上的变量。对象有时也被叫作&lt;strong&gt;关联数组&lt;/strong&gt;, 因为每个属性都有一个用于访问它的&lt;strong&gt;字符串值&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="JavaScript" scheme="https://yoursite.com/tags/JavaScript/"/>
    
      <category term="web基础" scheme="https://yoursite.com/tags/web%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>编译原理第二章——文法分类</title>
    <link href="https://yoursite.com/2020/10/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC%E4%BA%8C%E7%AB%A0%E2%80%94%E2%80%94%E6%96%87%E6%B3%95%E5%88%86%E7%B1%BB/"/>
    <id>https://yoursite.com/2020/10/02/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E7%AC%AC%E4%BA%8C%E7%AB%A0%E2%80%94%E2%80%94%E6%96%87%E6%B3%95%E5%88%86%E7%B1%BB/</id>
    <published>2020-10-02T01:35:22.000Z</published>
    <updated>2021-01-19T04:31:33.303Z</updated>
    
    <content type="html"><![CDATA[<h1 id="语言和文法"><a href="#语言和文法" class="headerlink" title="语言和文法"></a>语言和文法</h1><p>编译原理第二章文法分类，紫书内容和mooc知识总结，重新回顾了4种文法的知识。</p><h2 id="文法分类"><a href="#文法分类" class="headerlink" title="文法分类"></a>文法分类</h2><p>乔姆斯基把语言文法分成4类，0型，1型，2型，3型，这几类文法的差别主要在于对产生式的限制不同，等级越高，限制越严格。</p><h4 id="0型文法"><a href="#0型文法" class="headerlink" title="0型文法"></a>0型文法</h4><p>0型文法是文法限制最弱的一种类型，0型文法的能力又被相当于<strong>图灵机</strong>模型，或者说<strong>任何0型文法都是递归可枚举的，反之，递归可枚举的一定是一个0型语言</strong>。</p><a id="more"></a><p><strong>定义：</strong><br>设$G=(V_N,V_T,P,S)$，如果$P$中的每一个产生式$\alpha$-&gt;$\beta$满足条件：</p><ol><li>$\alpha \in (V_N \cup V_T)^*$且至少含有一个非终结符。</li><li>$\beta \in (V_N \cup V_T)^*$</li></ol><p><strong>0型例子：</strong><br><img src="https://img-blog.csdnimg.cn/20201002110133143.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="0型实例"></p><h4 id="1型文法——上下文有关文法"><a href="#1型文法——上下文有关文法" class="headerlink" title="1型文法——上下文有关文法"></a>1型文法——上下文有关文法</h4><p>1型文法中最主要的限制条件主要是对于产生式P均满足$|\beta| \ge|\alpha|$,仅$S \rightarrow \epsilon$除外。<br><strong>等价定义：</strong><br><img src="https://img-blog.csdnimg.cn/20201002111340975.png#pic_center" alt="1型文法"></p><p><strong>1型例子：</strong><br><img src="https://img-blog.csdnimg.cn/20201002111557799.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="1型文法"></p><h4 id="2型文法——上下文无关文法"><a href="#2型文法——上下文无关文法" class="headerlink" title="2型文法——上下文无关文法"></a>2型文法——上下文无关文法</h4><p>2型文法对应的是<strong>下推自动机</strong>模型，常用于描述高级语言的<strong>语法规则</strong>。<br><strong>定义：</strong><br>设$G=(V_N,V_T,P,S)$，如果$P$中的每一个产生式$\alpha$-&gt;$\beta$满足条件：</p><ol><li>$\alpha$是<strong>一个</strong>非终结符。</li><li>$\beta \in (V_N \cup V_T)^*$</li></ol><p><strong>2型例子：</strong><br><img src="https://img-blog.csdnimg.cn/20201002141025946.png#pic_center" alt="在这里插入图片描述"></p><h4 id="3型文法——正规文法"><a href="#3型文法——正规文法" class="headerlink" title="3型文法——正规文法"></a>3型文法——正规文法</h4><p>正规文法对应的是有穷自动机，用来描述高级语言的<strong>词法规则</strong><br><strong>定义：</strong><br>设$G=(V_N,V_T,P,S)$，如果$P$中的每一个产生式$\alpha$-&gt;$\beta$都是$A-&gt;aB$或者$A-&gt;a$的形式，其中A，B都是非终结符，$a \in V_T^*$即就是，由一个非终结符推导出一个终结符或者一个终结符+一个非终结符构成的字串。</p><p><img src="https://img-blog.csdnimg.cn/20201002142059138.png#pic_center" alt="3"></p><p><strong>正规文法例子：</strong><br>这里尖括号括起来的是非终结符，其他的是终结符。<br><img src="https://img-blog.csdnimg.cn/20201002142509302.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0phY2tfX19F,size_16,color_FFFFFF,t_70#pic_center" alt="3"></p><p>4种文法的定义的限制是逐步增强的，四种文法是逐步包含的，因此每一种正规文法都是上下文无关的，每一种上下文无关文法都是上下文有关的，每一种上下文有关文法都是0型文法。</p><p><img src="https://img-blog.csdnimg.cn/20201002142911916.png#pic_center" alt="0"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;语言和文法&quot;&gt;&lt;a href=&quot;#语言和文法&quot; class=&quot;headerlink&quot; title=&quot;语言和文法&quot;&gt;&lt;/a&gt;语言和文法&lt;/h1&gt;&lt;p&gt;编译原理第二章文法分类，紫书内容和mooc知识总结，重新回顾了4种文法的知识。&lt;/p&gt;
&lt;h2 id=&quot;文法分类&quot;&gt;&lt;a href=&quot;#文法分类&quot; class=&quot;headerlink&quot; title=&quot;文法分类&quot;&gt;&lt;/a&gt;文法分类&lt;/h2&gt;&lt;p&gt;乔姆斯基把语言文法分成4类，0型，1型，2型，3型，这几类文法的差别主要在于对产生式的限制不同，等级越高，限制越严格。&lt;/p&gt;
&lt;h4 id=&quot;0型文法&quot;&gt;&lt;a href=&quot;#0型文法&quot; class=&quot;headerlink&quot; title=&quot;0型文法&quot;&gt;&lt;/a&gt;0型文法&lt;/h4&gt;&lt;p&gt;0型文法是文法限制最弱的一种类型，0型文法的能力又被相当于&lt;strong&gt;图灵机&lt;/strong&gt;模型，或者说&lt;strong&gt;任何0型文法都是递归可枚举的，反之，递归可枚举的一定是一个0型语言&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="编译原理" scheme="https://yoursite.com/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>SQL语句————数据查询</title>
    <link href="https://yoursite.com/2020/09/30/SQL%E8%AF%AD%E5%8F%A5%E2%80%94%E2%80%94%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2/"/>
    <id>https://yoursite.com/2020/09/30/SQL%E8%AF%AD%E5%8F%A5%E2%80%94%E2%80%94%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%9F%A5%E8%AF%A2/</id>
    <published>2020-09-29T16:08:03.000Z</published>
    <updated>2021-01-19T04:31:33.654Z</updated>
    
    <content type="html"><![CDATA[<p>数据查询是数据库最核心的功能，也是我们需要重点掌握的部分，该语句有很多灵活多变的操作值得我们去学习。<br>其一般格式为：（一般格式写的比较复杂，但一般不会这么复杂）</p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> [<span class="hljs-keyword">ALL</span>|<span class="hljs-keyword">DISTINCT</span>] &lt;目标列表达式&gt; [,&lt;目标列表达式&gt;] ...<br><span class="hljs-keyword">FROM</span> &lt;表名或者视图名&gt; [,&lt;表名或者视图名&gt;...] | (&lt;<span class="hljs-keyword">SELECT</span> 语句&gt; 嵌套) [<span class="hljs-keyword">AS</span>] &lt;别名&gt;<br><span class="hljs-keyword">WHERE</span> &lt;条件表达式&gt; | (&lt;<span class="hljs-keyword">SELECT</span> 语句&gt; 嵌套) <br>[<span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> &lt;列名<span class="hljs-number">1</span>&gt; [<span class="hljs-keyword">HAVING</span> &lt;条件表达式&gt;]]<br>[<span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> &lt;列名<span class="hljs-number">2</span>&gt; [,&lt;列名<span class="hljs-number">3</span>&gt;...] [<span class="hljs-keyword">ASC</span>(升序)|<span class="hljs-keyword">DESC</span>(降序)] ];<br></code></pre></td></tr></table></figure><!--mroe-->]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;数据查询是数据库最核心的功能，也是我们需要重点掌握的部分，该语句有很多灵活多变的操作值得我们去学习。&lt;br&gt;其一般格式为：（一般格式写的比较复杂，但一般不会这么复杂）&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td clas
      
    
    </summary>
    
    
    
      <category term="数据库系统" scheme="https://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>SQL语句————数据定义</title>
    <link href="https://yoursite.com/2020/09/29/SQL%E8%AF%AD%E5%8F%A5%E2%80%94%E2%80%94%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89/"/>
    <id>https://yoursite.com/2020/09/29/SQL%E8%AF%AD%E5%8F%A5%E2%80%94%E2%80%94%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89/</id>
    <published>2020-09-29T15:38:18.000Z</published>
    <updated>2021-01-19T04:31:33.636Z</updated>
    
    <content type="html"><![CDATA[<p>SQL又称结构化查询语句（Structed Query Language）是关系数据库的标准语言，也是一个通用的，功能极强的关系数据库语言。<br>SQL集<strong>数据查询、数据操纵、数据定义、数据控制</strong>功能于一体。<br><strong>目前没有一个数据库系统能支持SQL标准的所有概念和特性。但同时许多软件厂商对SQL基本命令集还进行了不同程度的扩充和修改，又可以支持标准以外的一些功能特性。</strong></p><a id="more"></a><h2 id="定义模式"><a href="#定义模式" class="headerlink" title="定义模式"></a>定义模式</h2><p>在SQL中，模式定义语句如下：</p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">SCHEMA</span> &lt;模式名&gt; AUTHORIZATION &lt;用户名&gt;<br></code></pre></td></tr></table></figure><p>如果没有指定&lt;模式名&gt;，那么&lt;模式名&gt;隐含为&lt;用户名&gt;<br>要创建模式，调用该命令的用户名必需拥有数据库管理员权限，或者获得了数据库管理员授权的CREATE SCHEMA的权限。</p><h2 id="删除模式"><a href="#删除模式" class="headerlink" title="删除模式"></a>删除模式</h2><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">DROP</span> <span class="hljs-keyword">SCHEMA</span> &lt;模式名&gt; &lt;<span class="hljs-keyword">CASCADE</span>|RESTRICT&gt;<br></code></pre></td></tr></table></figure><p>其中CASCADE|RESTRICT必须二选一，两者有不同的作用。</p><ol><li>CASCADE，级联，表示在删除模式的同时把该模式中所有的数据库对象全部删除。</li><li>选择了RESTRICT，限制，表示如果该模式中已经定义了下属的数据库对象，则拒绝该删除语句的执行。</li></ol><h2 id="基本表的定义与创建"><a href="#基本表的定义与创建" class="headerlink" title="基本表的定义与创建"></a>基本表的定义与创建</h2><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> &lt;表名&gt;(<br>    &lt;列名&gt;&lt;数据类型&gt;,[列级完整性约束条件],<br>    &lt;列名&gt;&lt;数据类型&gt;,[列级完整性约束条件],<br>    &lt;列名&gt;&lt;数据类型&gt;,[列级完整性约束条件],<br>    ...<br>);<br></code></pre></td></tr></table></figure><h2 id="修改基本表"><a href="#修改基本表" class="headerlink" title="修改基本表"></a>修改基本表</h2><p>修改语句主要是通过ALERT TABLE来操作</p><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> &lt;表名&gt;<br>[<span class="hljs-keyword">ADD</span> [<span class="hljs-keyword">COLUMN</span>] &lt;新列名&gt;&lt;数据类型&gt; [完整性约束]]<br>[<span class="hljs-keyword">ADD</span> &lt;表级完整性约束&gt;]<br>[<span class="hljs-keyword">DROP</span> [<span class="hljs-keyword">COLUMN</span>] &lt;列名&gt; [<span class="hljs-keyword">CASCADE</span>|RESTRICT] ]<br>[<span class="hljs-keyword">DROP</span> <span class="hljs-keyword">CONSTRAINT</span> &lt;完整性约束名&gt; [<span class="hljs-keyword">CASCADE</span>|RESTRICT]]<br>[ALER <span class="hljs-keyword">COLUMN</span>&lt;列名&gt;&lt;数据类型&gt;];<br></code></pre></td></tr></table></figure><h2 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h2><figure class="highlight sql"><table><tr><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">DROP</span> <span class="hljs-keyword">TABLE</span> &lt;表名&gt; [RESTRICT|<span class="hljs-keyword">CASCADE</span>]<br></code></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;SQL又称结构化查询语句（Structed Query Language）是关系数据库的标准语言，也是一个通用的，功能极强的关系数据库语言。&lt;br&gt;SQL集&lt;strong&gt;数据查询、数据操纵、数据定义、数据控制&lt;/strong&gt;功能于一体。&lt;br&gt;&lt;strong&gt;目前没有一个数据库系统能支持SQL标准的所有概念和特性。但同时许多软件厂商对SQL基本命令集还进行了不同程度的扩充和修改，又可以支持标准以外的一些功能特性。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据库系统" scheme="https://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
</feed>
